{"event_time": "2026-02-09T08:19:18.321548+00:00", "action": "add", "paper_id": "2602.06221", "paper": {"id": "2602.06221", "url": "https://arxiv.org/abs/2602.06221", "title": "BenchMarker: An Education-Inspired Toolkit for Highlighting Flaws in Multiple-Choice Benchmarks", "authors": "Nishant Balepur, Bhavya Rajasekaran, Jane Oh, Michael Xie, Atrey Desai, Vipul Gupta, Steven James Moore, Eunsol Choi, Rachel Rudinger, Jordan Lee Boyd-Graber", "category": ["cs.CL"], "summary": "提出了BenchMarker工具包，使用LLM法官检测多选题的三种常见缺陷：污染、捷径和写作错误，通过人工标注验证后对12个基准进行审计，发现缺陷会影响评估准确性，并发布工具以改进多选题基准设计。", "date": "2026-02-09", "details": "Multiple-choice question answering (MCQA) is standard in NLP, but benchmarks lack rigorous quality control. We present BenchMarker, an education-inspired toolkit using LLM judges to flag three common MCQ flaws: 1) contamination - items appearing exactly online; 2) shortcuts - cues in the choices that enable guessing; and 3) writing errors - structural/grammatical issues based on a 19-rule education rubric. We validate BenchMarker with human annotations, then run the tool to audit 12 benchmarks, revealing: 2) contaminated MCQs tend to inflate accuracy, while writing errors tend to lower it and change rankings beyond random; and 3) prior benchmark repairs address their targeted issues (i.e., lowering accuracy with LLM-written distractors), but inadvertently add new flaws (i.e. implausible distractors, many correct answers). Overall, flaws in MCQs degrade NLP evaluation, but education research offers a path forward. We release BenchMarker to bridge the fields and improve MCQA benchmark design.", "motivation": "当前NLP中的多选题基准测试缺乏严格的质量控制，存在多种缺陷影响评估有效性，需要系统化的检测工具来改进基准设计。", "method": "开发BenchMarker工具包，使用LLM法官基于19条教育规则检测三种缺陷：1)污染项-完全在线出现的题目；2)捷径-选项中的猜测线索；3)写作错误-结构/语法问题。通过人工标注验证工具有效性。", "result": "审计12个基准发现：污染项倾向于提高准确率，写作错误倾向于降低准确率并改变排名；先前的基准修复虽然解决了目标问题，但意外引入了新的缺陷（如不合理的干扰项、多个正确答案）。", "conclusion": "多选题中的缺陷会降低NLP评估质量，但教育研究提供了改进路径。发布的BenchMarker工具可连接两个领域，改进多选题基准设计。", "code_url": "", "code_stars": 0, "code_last_update": ""}}
{"event_time": "2026-02-09T08:21:16.855086+00:00", "action": "add", "paper_id": "2602.06052", "paper": {"id": "2602.06052", "url": "https://arxiv.org/abs/2602.06052", "title": "Rethinking Memory Mechanisms of Foundation Agents in the Second Half", "authors": "Wei-Chieh Huang, Weizhi Zhang, Yueqing Liang, Yuanchen Bei, Yankai Chen, Tao Feng, Xinyu Pan, Zhen Tan, Yu Wang, Tianxin Wei, Shanglin Wu, Ruiyao Xu, Liangwei Yang, Rui Yang, Wooseong Yang, Chin-Yuan Yeh, Hanrong Zhang, Haozhen Zhang, Siqi Zhu, Henry Peng Zou, Wanjia Zhao, Song Wang, Wujiang Xu, Zixuan Ke, Zheng Hui, Dawei Li, Yaozu Wu, Langzhou He, Chen Wang, Xiongxiao Xu, Baixiang Huang, Juntao Tan, Shelby Heinecke, Huan Wang, Caiming Xiong, Ahmed A. Metwally, Jun Yan, Chen-Yu Lee, Hanqing Zeng, Yinglong Xia, Xiaokai Wei, Ali Payani, Yu Wang, Haitong Ma, Wenya Wang, Chengguang Wang, Yu Zhang, Xin Wang, Yongfeng Zhang, Jiaxuan You, Hanghang Tong, Xiao Luo, Yizhou Sun, Wei Wang, Julian McAuley, James Zou, Jiawei Han, Philip S. Yu, Kai Shu", "category": ["cs.CL", "cs.AI"], "summary": "对基础智能体记忆系统的综合性调查，从记忆基质、认知机制和记忆主体三个维度构建统一框架，分析不同智能体拓扑中的记忆实现和操作策略，并评述评估基准与未来挑战。", "date": "2026-02-09", "details": "The research of artificial intelligence is undergoing a paradigm shift from prioritizing model innovations over benchmark scores towards emphasizing problem definition and rigorous real-world evaluation. As the field enters the \"second half,\" the central challenge becomes real utility in long-horizon, dynamic, and user-dependent environments, where agents face context explosion and must continuously accumulate, manage, and selectively reuse large volumes of information across extended interactions. Memory, with hundreds of papers released this year, therefore emerges as the critical solution to fill the utility gap. In this survey, we provide a unified view of foundation agent memory along three dimensions: memory substrate (internal and external), cognitive mechanism (episodic, semantic, sensory, working, and procedural), and memory subject (agent- and user-centric). We then analyze how memory is instantiated and operated under different agent topologies and highlight learning policies over memory operations. Finally, we review evaluation benchmarks and metrics for assessing memory utility, and outline various open challenges and future directions.", "motivation": "人工智能研究正从注重模型创新转向强调问题定义和真实世界评估，智能体在长周期、动态和用户依赖环境中面临上下文爆炸问题，记忆成为填补效用差距的关键解决方案。", "method": "提出三维统一框架：记忆基质（内部/外部）、认知机制（情景/语义/感知/工作/程序记忆）、记忆主体（智能体中心/用户中心），分析不同智能体拓扑中的记忆实例化和操作策略。", "result": "构建了基础智能体记忆系统的系统性分类框架，提供了记忆在不同智能体架构中的实现方法，并总结了记忆操作的学习策略。", "conclusion": "记忆是解决智能体在复杂环境中长期效用问题的核心技术，需要从多个维度系统化研究，未来需关注评估基准建设和实际应用挑战。", "code_url": "", "code_stars": 0, "code_last_update": ""}}
{"event_time": "2026-02-09T08:21:55.614498+00:00", "action": "remove", "paper_id": "2602.06052", "paper": {"id": "2602.06052", "url": "2602.06052"}}
