<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 110]
- [cs.CL](#cs.CL) [Total: 76]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [WorldVQA: Measuring Atomic World Knowledge in Multimodal Large Language Models](https://arxiv.org/abs/2602.02537)
*Runjie Zhou,Youbo Shao,Haoyu Lu,Bowei Xing,Tongtong Bai,Yujie Chen,Jie Zhao,Lin Sui,Haotian Yao,Zijia Zhao,Hao Yang,Haoning Wu,Zaida Zhou,Jinguo Zhu,Zhiqi Huang,Yiping Bao,Yangyang Liu,Y. Charles,Xinyu Zhou*

Main category: cs.CV

TL;DR: WorldVQA是一个专门评估多模态大语言模型视觉世界知识记忆能力的基准测试，通过解耦视觉知识检索与推理能力，严格测量模型对视觉实体的记忆和命名能力。


<details>
  <summary>Details</summary>
Motivation: 当前评估方法往往将视觉知识检索与推理能力混淆，无法准确衡量模型对视觉事实的记忆能力，因此需要开发一个专门评估模型视觉事实性记忆的基准。

Method: 构建分层分类体系，从常见头部类别对象到长尾稀有实体，评估模型对视觉实体的基础识别和命名能力，严格解耦知识检索与推理过程。

Result: WorldVQA提供了一个严格评估视觉事实性的基准，能够测量模型在百科全书式知识广度和幻觉率方面的表现。

Conclusion: 该基准将为当前和下一代前沿模型的视觉世界知识评估建立标准，促进模型在视觉事实性方面的改进和发展。

Abstract: We introduce WorldVQA, a benchmark designed to evaluate the atomic visual world knowledge of Multimodal Large Language Models (MLLMs). Unlike current evaluations, which often conflate visual knowledge retrieval with reasoning, WorldVQA decouples these capabilities to strictly measure "what the model memorizes." The benchmark assesses the atomic capability of grounding and naming visual entities across a stratified taxonomy, spanning from common head-class objects to long-tail rarities. We expect WorldVQA to serve as a rigorous test for visual factuality, thereby establishing a standard for assessing the encyclopedic breadth and hallucination rates of current and next-generation frontier models.

</details>


### [2] [AdaptMMBench: Benchmarking Adaptive Multimodal Reasoning for Mode Selection and Reasoning Process](https://arxiv.org/abs/2602.02676)
*Xintong Zhang,Xiaowen Zhang,Jongrong Wu,Zhi Gao,Shilin Yan,Zhenxin Diao,Kunpeng Gao,Xuanyan Chen,Yuwei Wu,Yunde Jia,Qing Li*

Main category: cs.CV

TL;DR: AdaptMMBench是一个用于评估自适应多模态推理的综合基准，通过MCC指标评估推理模式选择的合理性，并支持多维过程分析，发现模式选择能力与模型容量相关但与最终准确率解耦。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法依赖静态难度标签和简单指标，无法捕捉相对于不同模型能力的动态难度特性，掩盖了自适应模式选择与通用性能的区别，且缺乏细粒度过程分析。

Method: 提出AdaptMMBench基准，涵盖五个领域（现实世界、OCR、GUI、知识和数学），使用MCC指标评估模式选择合理性，通过动态识别基于模型能力边界的任务难度来分离元认知能力，支持关键步骤覆盖、工具有效性和计算效率的多维评估。

Result: 评估显示自适应模式选择能力随模型容量扩展，但与最终准确率显著解耦；关键步骤覆盖与性能一致，但工具有效性在不同模型架构间高度不一致。

Conclusion: AdaptMMBench提供了一个更全面的评估框架，揭示了自适应多模态推理的关键特性，为未来研究提供了重要的基准和分析工具。

Abstract: Adaptive multimodal reasoning has emerged as a promising frontier in Vision-Language Models (VLMs), aiming to dynamically modulate between tool-augmented visual reasoning and text reasoning to enhance both effectiveness and efficiency. However, existing evaluations rely on static difficulty labels and simplistic metrics, which fail to capture the dynamic nature of difficulty relative to varying model capacities. Consequently, they obscure the distinction between adaptive mode selection and general performance while neglecting fine-grained process analyses. In this paper, we propose AdaptMMBench, a comprehensive benchmark for adaptive multimodal reasoning across five domains: real-world, OCR, GUI, knowledge, and math, encompassing both direct perception and complex reasoning tasks. AdaptMMBench utilizes a Matthews Correlation Coefficient (MCC) metric to evaluate the selection rationality of different reasoning modes, isolating this meta-cognition ability by dynamically identifying task difficulties based on models' capability boundaries. Moreover, AdaptMMBench facilitates multi-dimensional process evaluation across key step coverage, tool effectiveness, and computational efficiency. Our evaluation reveals that while adaptive mode selection scales with model capacity, it notably decouples from final accuracy. Conversely, key step coverage aligns with performance, though tool effectiveness remains highly inconsistent across model architectures.

</details>


### [3] [End-to-end reconstruction of OCT optical properties and speckle-reduced structural intensity via physics-based learning](https://arxiv.org/abs/2602.02721)
*Jinglun Yu,Yaning Wang,Wenhan Guo,Yuan Gao,Yu Sun,Jin U. Kang*

Main category: cs.CV

TL;DR: 提出基于深度学习的正则化端到端框架，用于OCT逆散射问题，同时重建光学参数图和去斑结构图像，通过物理前向模型提供一致性监督，在合成角膜数据上验证了噪声鲁棒性和分辨率提升


<details>
  <summary>Details</summary>
Motivation: OCT逆散射问题在恢复组织结构图像和固有光学特性（折射率、散射系数、各向异性）时面临衰减、散斑噪声和参数强耦合等挑战

Method: 使用蒙特卡洛模拟生成训练数据，构建包含物理前向模型的端到端深度学习框架，通过从估计参数生成预测信号来提供物理一致性监督

Result: 在合成角膜OCT数据集上实现了噪声下的鲁棒光学图恢复、分辨率改进和结构保真度增强

Conclusion: 该方法实现了定量多参数组织表征，证明了物理信息建模与深度学习结合在计算OCT中的优势

Abstract: Inverse scattering in optical coherence tomography (OCT) seeks to recover both structural images and intrinsic tissue optical properties, including refractive index, scattering coefficient, and anisotropy. This inverse problem is challenging due to attenuation, speckle noise, and strong coupling among parameters. We propose a regularized end-to-end deep learning framework that jointly reconstructs optical parameter maps and speckle-reduced OCT structural intensity for layer visualization. Trained with Monte Carlo-simulated ground truth, our network incorporates a physics-based OCT forward model that generates predicted signals from the estimated parameters, providing physics-consistent supervision for parameter recovery and artifact suppression. Experiments on the synthetic corneal OCT dataset demonstrate robust optical map recovery under noise, improved resolution, and enhanced structural fidelity. This approach enables quantitative multi-parameter tissue characterization and highlights the benefit of combining physics-informed modeling with deep learning for computational OCT.

</details>


### [4] [SVD-ViT: Does SVD Make Vision Transformers Attend More to the Foreground?](https://arxiv.org/abs/2602.02765)
*Haruhiko Murata,Kazuhiro Hotta*

Main category: cs.CV

TL;DR: SVD-ViT通过奇异值分解技术增强Vision Transformer的前景特征学习能力，抑制背景噪声影响，提升分类性能


<details>
  <summary>Details</summary>
Motivation: 标准Vision Transformer缺乏明确的前景-背景区分机制，可能学习到不必要的背景特征和伪影，导致分类性能下降

Method: 提出SVD-ViT方法，包含三个核心组件：SPC模块、SSVA和ID-RSVD，通过奇异值分解提取和聚合捕获前景信息的奇异向量

Result: 实验结果表明该方法提高了分类准确率，有效学习信息丰富的前景表示，同时减少背景噪声的影响

Conclusion: SVD-ViT通过奇异值分解技术成功解决了ViT中前景-背景区分问题，为视觉Transformer提供了更有效的特征学习机制

Abstract: Vision Transformers (ViT) have been established as large-scale foundation models. However, because self-attention operates globally, they lack an explicit mechanism to distinguish foreground from background. As a result, ViT may learn unnecessary background features and artifacts, leading to degraded classification performance. To address this issue, we propose SVD-ViT, which leverages singular value decomposition (SVD) to prioritize the learning of foreground features. SVD-ViT consists of three components-\textbf{SPC module}, \textbf{SSVA}, and \textbf{ID-RSVD}-and suppresses task-irrelevant factors such as background noise and artifacts by extracting and aggregating singular vectors that capture object foreground information. Experimental results demonstrate that our method improves classification accuracy and effectively learns informative foreground representations while reducing the impact of background noise.

</details>


### [5] [LmPT: Conditional Point Transformer for Anatomical Landmark Detection on 3D Point Clouds](https://arxiv.org/abs/2602.02808)
*Matteo Bastico,Pierre Onghena,David Ryckelynck,Beatriz Marcotegui,Santiago Velasco-Forero,Laurent Corté,Caroline Robine--Decourcelle,Etienne Decencière*

Main category: cs.CV

TL;DR: Landmark Point Transformer (LmPT)是一种基于点云表示的自动解剖标志点检测方法，能够利用不同物种的同源骨骼进行跨物种学习，在人类和犬类股骨上表现出良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统手动标志点标注耗时且存在观察者间差异，基于规则的方法通常局限于特定几何形状或有限标志点集，需要开发更通用高效的自动检测方法。

Method: 提出Landmark Point Transformer (LmPT)模型，将解剖表面表示为点云，采用条件机制适应不同输入类型，实现跨物种学习。

Result: 在人类和犬类股骨标志点检测任务上验证了方法的有效性，展示了跨物种泛化能力。

Conclusion: LmPT为解剖标志点检测提供了一种有效的跨物种学习方法，代码和犬类股骨数据集将公开提供。

Abstract: Accurate identification of anatomical landmarks is crucial for various medical applications. Traditional manual landmarking is time-consuming and prone to inter-observer variability, while rule-based methods are often tailored to specific geometries or limited sets of landmarks. In recent years, anatomical surfaces have been effectively represented as point clouds, which are lightweight structures composed of spatial coordinates. Following this strategy and to overcome the limitations of existing landmarking techniques, we propose Landmark Point Transformer (LmPT), a method for automatic anatomical landmark detection on point clouds that can leverage homologous bones from different species for translational research. The LmPT model incorporates a conditioning mechanism that enables adaptability to different input types to conduct cross-species learning. We focus the evaluation of our approach on femoral landmarking using both human and newly annotated dog femurs, demonstrating its generalization and effectiveness across species. The code and dog femur dataset will be publicly available at: https://github.com/Pierreoo/LandmarkPointTransformer.

</details>


### [6] [Self-Supervised Uncalibrated Multi-View Video Anonymization in the Operating Room](https://arxiv.org/abs/2602.02850)
*Keqi Chen,Vinkle Srivastav,Armine Vardazaryan,Cindy Rolland,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: 提出无需标注和相机标定的自监督多视角手术室视频匿名化框架，通过时间与多视角上下文检索假阴性检测，实现97%以上的召回率


<details>
  <summary>Details</summary>
Motivation: 手术室视频研究需要隐私保护，现有方法存在两个可扩展性瓶颈：需要手动标注新临床站点和相机重新定位时需要标定

Method: 结合全身人体检测和姿态估计，通过低阈值检测候选框，利用跟踪和自监督多视角关联检索假阴性，作为伪标签迭代微调检测器

Result: 在模拟和真实手术数据集上达到97%以上召回率，训练出的实时检测器性能相当，具有实际应用价值

Conclusion: 该方法有效解决了手术室视频匿名化的可扩展性问题，无需人工标注和相机标定，实现了高精度隐私保护

Abstract: Privacy preservation is a prerequisite for using video data in Operating Room (OR) research. Effective anonymization relies on the exhaustive localization of every individual; even a single missed detection necessitates extensive manual correction. However, existing approaches face two critical scalability bottlenecks: (1) they usually require manual annotations of each new clinical site for high accuracy; (2) while multi-camera setups have been widely adopted to address single-view ambiguity, camera calibration is typically required whenever cameras are repositioned. To address these problems, we propose a novel self-supervised multi-view video anonymization framework consisting of whole-body person detection and whole-body pose estimation, without annotation or camera calibration. Our core strategy is to enhance the single-view detector by "retrieving" false negatives using temporal and multi-view context, and conducting self-supervised domain adaptation. We first run an off-the-shelf whole-body person detector in each view with a low-score threshold to gather candidate detections. Then, we retrieve the low-score false negatives that exhibit consistency with the high-score detections via tracking and self-supervised uncalibrated multi-view association. These recovered detections serve as pseudo labels to iteratively fine-tune the whole-body detector. Finally, we apply whole-body pose estimation on each detected person, and fine-tune the pose model using its own high-score predictions. Experiments on the 4D-OR dataset of simulated surgeries and our dataset of real surgeries show the effectiveness of our approach achieving over 97% recall. Moreover, we train a real-time whole-body detector using our pseudo labels, achieving comparable performance and highlighting our method's practical applicability. Code is available at https://github.com/CAMMA-public/OR_anonymization.

</details>


### [7] [ViThinker: Active Vision-Language Reasoning via Dynamic Perceptual Querying](https://arxiv.org/abs/2602.02873)
*Weihang You,Qingchan Zhu,David Liu,Yi Pan,Geng Yuan,Hanqi Jiang*

Main category: cs.CV

TL;DR: ViThinker是一个主动视觉推理框架，通过生成查询令牌来按需合成专家对齐的视觉特征，解决了传统视觉语言模型中视觉信息过早转换导致几何和空间信息丢失的问题。


<details>
  <summary>Details</summary>
Motivation: 传统的Chain-of-Thought推理在视觉语言模型中存在视觉信息过早转换为文本的问题，导致连续的几何和空间布局信息丢失。现有方法多为被动处理预计算输入，缺乏主动获取任务相关细节的能力。

Method: 采用两阶段课程学习：第一阶段将冻结专家的能力蒸馏到模型参数中；第二阶段通过稀疏惩罚学习任务驱动的查询机制，使模型能够为每个推理步骤发现最小充分的感知信息。

Result: 在多个视觉中心基准测试中表现出一致的改进，验证了主动查询生成在感知基础和推理准确性方面优于被动方法。

Conclusion: ViThinker框架通过模拟人类主动感知机制，实现了视觉语言模型的自主特征查询能力，显著提升了视觉推理性能，为视觉语言理解提供了新的研究方向。

Abstract: Chain-of-Thought (CoT) reasoning excels in language models but struggles in vision-language models due to premature visual-to-text conversion that discards continuous information such as geometry and spatial layout. While recent methods enhance CoT through static enumeration or attention-based selection, they remain passive, i.e., processing pre-computed inputs rather than actively seeking task-relevant details. Inspired by human active perception, we introduce ViThinker, a framework that enables vision-language models to autonomously generate decision (query) tokens triggering the synthesis of expert-aligned visual features on demand. ViThinker internalizes vision-expert capabilities during training, performing generative mental simulation during inference without external tool calls. Through a two-stage curriculum: first distilling frozen experts into model parameters, then learning task-driven querying via sparsity penalties, i.e., ViThinker discovers minimal sufficient perception for each reasoning step. Evaluations across vision-centric benchmarks demonstrate consistent improvements, validating that active query generation outperforms passive approaches in both perceptual grounding and reasoning accuracy.

</details>


### [8] [DoubleTake: Contrastive Reasoning for Faithful Decision-Making in Medical Imaging](https://arxiv.org/abs/2602.02894)
*Daivik Patel,Shrenik Patel*

Main category: cs.CV

TL;DR: 提出了一种基于对比性文档感知的医学影像参考选择框架和反事实对比推理方法，通过构建优化的证据集和结构化视觉比较，显著提升医学影像决策的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有医学影像决策方法主要依赖最近邻检索，导致证据冗余和假设单一，无法有效区分易混淆病症之间的细微视觉差异。

Method: 开发了对比性文档感知参考选择框架，使用ROCO嵌入和元数据平衡视觉相关性、嵌入多样性和来源溯源；提出反事实对比推理框架，进行结构化成对视觉比较并基于边际的决策规则聚合证据。

Result: 在MediConfusion基准测试中实现最先进性能，相对于先前方法将集合级准确率提高了近15%，同时减少了混淆并提高了个体准确性。

Conclusion: 该研究为医学影像对比推理提供了可复现的参考选择协议和精心策划的参考库，通过优化证据集构建和结构化比较显著提升了医学决策的准确性和可靠性。

Abstract: Accurate decision making in medical imaging requires reasoning over subtle visual differences between confusable conditions, yet most existing approaches rely on nearest neighbor retrieval that returns redundant evidence and reinforces a single hypothesis. We introduce a contrastive, document-aware reference selection framework that constructs compact evidence sets optimized for discrimination rather than similarity by explicitly balancing visual relevance, embedding diversity, and source-level provenance using ROCO embeddings and metadata. While ROCO provides large-scale image-caption pairs, it does not specify how references should be selected for contrastive reasoning, and naive retrieval frequently yields near-duplicate figures from the same document. To address this gap, we release a reproducible reference selection protocol and curated reference bank that enable a systematic study of contrastive retrieval in medical image reasoning. Building on these contrastive evidence sets, we propose Counterfactual-Contrastive Inference, a confidence-aware reasoning framework that performs structured pairwise visual comparisons and aggregates evidence using margin-based decision rules with faithful abstention. On the MediConfusion benchmark, our approach achieves state-of-the-art performance, improving set-level accuracy by nearly 15% relative to prior methods while reducing confusion and improving individual accuracy.

</details>


### [9] [FaceLinkGen: Rethinking Identity Leakage in Privacy-Preserving Face Recognition with Identity Extraction](https://arxiv.org/abs/2602.02914)
*Wenqi Guo,Shan Du*

Main category: cs.CV

TL;DR: FaceLinkGen攻击方法证明现有基于像素重建的隐私保护人脸识别评估方法存在结构性缺陷，能在不恢复原始像素的情况下实现高达98.5%的身份匹配精度和96%的再生成功率，揭示了视觉混淆无法有效保护身份隐私。


<details>
  <summary>Details</summary>
Motivation: 现有隐私保护人脸识别系统主要关注像素级重建抗性，使用PSNR和SSIM等指标评估隐私保护效果，但这些评估方法未能有效衡量真实的隐私保护水平。

Method: 提出FaceLinkGen攻击方法，直接从受保护的模板中执行身份链接/匹配和面部再生，无需恢复原始像素，在三种最新PPFR系统上进行测试。

Result: 攻击达到超过98.5%的匹配准确率和96%以上的再生成功率，在接近零知识设置下仍保持92%匹配和94%再生成功率，显著暴露现有评估指标的不足。

Conclusion: 像素失真度量与真实隐私保护之间存在结构性差距，视觉混淆无法有效保护身份信息免受外部入侵者和不可信服务提供商的攻击，需要重新设计隐私保护评估框架。

Abstract: Transformation-based privacy-preserving face recognition (PPFR) aims to verify identities while hiding facial data from attackers and malicious service providers. Existing evaluations mostly treat privacy as resistance to pixel-level reconstruction, measured by PSNR and SSIM. We show that this reconstruction-centric view fails. We present FaceLinkGen, an identity extraction attack that performs linkage/matching and face regeneration directly from protected templates without recovering original pixels. On three recent PPFR systems, FaceLinkGen reaches over 98.5\% matching accuracy and above 96\% regeneration success, and still exceeds 92\% matching and 94\% regeneration in a near zero knowledge setting. These results expose a structural gap between pixel distortion metrics, which are widely used in PPFR evaluation, and real privacy. We show that visual obfuscation leaves identity information broadly exposed to both external intruders and untrusted service providers.

</details>


### [10] [A Multi-scale Linear-time Encoder for Whole-Slide Image Analysis](https://arxiv.org/abs/2602.02918)
*Jagan Mohan Reddy Dwarampudi,Joshua Wong,Hien Van Nguyen,Tania Banerjee*

Main category: cs.CV

TL;DR: MARBLE是首个基于Mamba的多状态多实例学习框架，用于全切片图像分析，通过并行处理多尺度信息并在线性时间状态空间模型中实现粗到细推理，在多个数据集上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 全切片图像分析面临千兆像素分辨率和多尺度层次的挑战，现有方法通常在单一尺度操作，而基于transformer的方法存在二次注意力计算成本问题

Method: 采用并行多尺度处理结合线性时间序列建模的Mamba架构，高效捕捉跨尺度依赖关系，同时保持最小参数量开销

Result: 在五个公开数据集上实验显示，AUC提升最高6.9%，准确率提升20.3%，C-index提升2.3%

Conclusion: MARBLE为多尺度WSI分析提供了一个高效、可扩展且模块化的替代方案，相比基于注意力的架构具有显著优势

Abstract: We introduce Multi-scale Adaptive Recurrent Biomedical Linear-time Encoder (MARBLE), the first \textit{purely Mamba-based} multi-state multiple instance learning (MIL) framework for whole-slide image (WSI) analysis. MARBLE processes multiple magnification levels in parallel and integrates coarse-to-fine reasoning within a linear-time state-space model, efficiently capturing cross-scale dependencies with minimal parameter overhead. WSI analysis remains challenging due to gigapixel resolutions and hierarchical magnifications, while existing MIL methods typically operate at a single scale and transformer-based approaches suffer from quadratic attention costs. By coupling parallel multi-scale processing with linear-time sequence modeling, MARBLE provides a scalable and modular alternative to attention-based architectures. Experiments on five public datasets show improvements of up to \textbf{6.9\%} in AUC, \textbf{20.3\%} in accuracy, and \textbf{2.3\%} in C-index, establishing MARBLE as an efficient and generalizable framework for multi-scale WSI analysis.

</details>


### [11] [SRA-Seg: Synthetic to Real Alignment for Semi-Supervised Medical Image Segmentation](https://arxiv.org/abs/2602.02944)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: SRA-Seg是一个针对医学图像分割的框架，通过特征分布对齐解决合成数据与真实数据之间的域差距问题，在仅使用10%真实标注数据和90%合成数据的情况下，显著超越现有半监督方法。


<details>
  <summary>Details</summary>
Motivation: 合成医学图像虽然视觉真实，但由于与真实图像存在于不同的语义特征空间，存在域差距问题，导致无法有效提升分割性能，当前半监督学习方法无法解决这一问题。

Method: 提出SRA-Seg框架，包含：1）使用冻结DINOv2嵌入的相似性对齐损失，将合成特征拉近到语义空间中最接近的真实对应特征；2）软边缘混合技术创建平滑解剖过渡和连续标签；3）通过EMA教师模型为合成图像生成伪标签；4）应用考虑混合区域不确定性的软分割损失。

Result: 在仅使用10%真实标注数据和90%合成未标注数据的情况下，在ACDC数据集上达到89.34% Dice分数，在FIVES数据集上达到84.42% Dice分数，显著超越现有半监督方法，达到与使用真实未标注数据方法相当的性能。

Conclusion: SRA-Seg通过显式对齐合成和真实特征分布，有效解决了医学图像分割中合成数据的域适应问题，证明了合成数据在医学图像分割中的潜力，为减少对大量专家标注数据的依赖提供了有效解决方案。

Abstract: Synthetic data, an appealing alternative to extensive expert-annotated data for medical image segmentation, consistently fails to improve segmentation performance despite its visual realism. The reason being that synthetic and real medical images exist in different semantic feature spaces, creating a domain gap that current semi-supervised learning methods cannot bridge. We propose SRA-Seg, a framework explicitly designed to align synthetic and real feature distributions for medical image segmentation. SRA-Seg introduces a similarity-alignment (SA) loss using frozen DINOv2 embeddings to pull synthetic representations toward their nearest real counterparts in semantic space. We employ soft edge blending to create smooth anatomical transitions and continuous labels, eliminating the hard boundaries from traditional copy-paste augmentation. The framework generates pseudo-labels for synthetic images via an EMA teacher model and applies soft-segmentation losses that respect uncertainty in mixed regions. Our experiments demonstrate strong results: using only 10% labeled real data and 90% synthetic unlabeled data, SRA-Seg achieves 89.34% Dice on ACDC and 84.42% on FIVES, significantly outperforming existing semi-supervised methods and matching the performance of methods using real unlabeled data.

</details>


### [12] [Nüwa: Mending the Spatial Integrity Torn by VLM Token Pruning](https://arxiv.org/abs/2602.02951)
*Yihong Huang,Fei Ma,Yihua Shao,Jingcai Guo,Zitong Yu,Laizhong Cui,Qi Tian*

Main category: cs.CV

TL;DR: Nüwa是一个两阶段的视觉token剪枝框架，通过保留全局空间锚点和文本引导剪枝，在保持VQA性能的同时显著提升视觉定位任务表现


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法在VQA任务上表现良好但在视觉定位任务上性能大幅下降，原因是全局语义相似性和注意力分数方法丢失了token位置信息交互产生的全局空间参考框架

Method: 两阶段框架：第一阶段在视觉编码器后使用分离、对齐和聚合操作（受群体智能算法启发）保留信息丰富的全局空间锚点；第二阶段在LLM内进行文本引导剪枝保留任务相关的视觉token

Result: 在多个VQA基准测试中达到SOTA性能（94%到95%），在视觉定位任务上获得显著提升（7%到47%）

Conclusion: 提出的Nüwa框架通过保持空间完整性实现高效特征聚合，有效解决了现有剪枝方法在视觉定位任务上的性能退化问题

Abstract: Vision token pruning has proven to be an effective acceleration technique for the efficient Vision Language Model (VLM). However, existing pruning methods demonstrate excellent performance preservation in visual question answering (VQA) and suffer substantial degradation on visual grounding (VG) tasks. Our analysis of the VLM's processing pipeline reveals that strategies utilizing global semantic similarity and attention scores lose the global spatial reference frame, which is derived from the interactions of tokens' positional information. Motivated by these findings, we propose $\text{Nüwa}$, a two-stage token pruning framework that enables efficient feature aggregation while maintaining spatial integrity. In the first stage, after the vision encoder, we apply three operations, namely separation, alignment, and aggregation, which are inspired by swarm intelligence algorithms to retain information-rich global spatial anchors. In the second stage, within the LLM, we perform text-guided pruning to retain task-relevant visual tokens. Extensive experiments demonstrate that $\text{Nüwa}$ achieves SOTA performance on multiple VQA benchmarks (from 94% to 95%) and yields substantial improvements on visual grounding tasks (from 7% to 47%).

</details>


### [13] [TRACE: Temporal Radiology with Anatomical Change Explanation for Grounded X-ray Report Generation](https://arxiv.org/abs/2602.02963)
*OFM Riaz Rahman Aranya,Kevin Desai*

Main category: cs.CV

TL;DR: TRACE是首个同时执行时间比较、变化分类和空间定位的模型，用于胸部X光片的时间变化检测和解释，通过联合学习实现了超过90%的空间定位准确率。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在单图像报告生成和视觉定位方面有进展，但缺乏结合这些能力进行时间变化检测的方法，临床放射学需要时间比较来检测疾病进展和治疗反应。

Method: 引入TRACE模型，给定先期和当前胸部X光片，生成自然语言描述间隔变化（恶化、改善、稳定），同时用边界框坐标定位每个发现。

Result: 模型展示了超过90%的空间定位准确率，消融研究发现只有当时间比较和空间定位联合学习时才会出现变化检测能力。

Conclusion: TRACE为这一新挑战性任务奠定了基础，研究表明定位提供了时间推理所必需的空间注意力机制。

Abstract: Temporal comparison of chest X-rays is fundamental to clinical radiology, enabling detection of disease progression, treatment response, and new findings. While vision-language models have advanced single-image report generation and visual grounding, no existing method combines these capabilities for temporal change detection. We introduce Temporal Radiology with Anatomical Change Explanation (TRACE), the first model that jointly performs temporal comparison, change classification, and spatial localization. Given a prior and current chest X-ray, TRACE generates natural language descriptions of interval changes (worsened, improved, stable) while grounding each finding with bounding box coordinates. TRACE demonstrates effective spatial localization with over 90% grounding accuracy, establishing a foundation for this challenging new task. Our ablation study uncovers an emergent capability: change detection arises only when temporal comparison and spatial grounding are jointly learned, as neither alone enables meaningful change detection. This finding suggests that grounding provides a spatial attention mechanism essential for temporal reasoning.

</details>


### [14] [Dynamic High-frequency Convolution for Infrared Small Target Detection](https://arxiv.org/abs/2602.02969)
*Ruojing Li,Chao Xiao,Qian Yin,Wei An,Nuo Chen,Xinyi Ying,Miao Li,Yingqian Wang*

Main category: cs.CV

TL;DR: 提出动态高频卷积（DHiF）方法，通过生成动态局部滤波器组来区分红外小目标与其他高频成分，提升单帧红外小目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的方法依赖深度网络但忽略了各种高频成分的显式建模和判别表示学习，而红外小目标属于图像高频成分，常与亮角点、碎云等杂波混淆。

Method: 设计DHiF卷积，根据傅里叶变换特性对称调整动态滤波器参数，使其对高频成分敏感，结合标准卷积自适应处理不同高频区域并捕获灰度变化特征。

Result: 在真实场景数据集上的广泛实验表明，DHiF相比其他先进卷积操作展现出优越的检测性能且有显著提升。

Conclusion: DHiF可作为标准卷积的即插即用替代，在不显著降低计算效率的情况下提升任意SIRST检测网络的性能，有效解决了高频成分的判别表示学习问题。

Abstract: Infrared small targets are typically tiny and locally salient, which belong to high-frequency components (HFCs) in images. Single-frame infrared small target (SIRST) detection is challenging, since there are many HFCs along with targets, such as bright corners, broken clouds, and other clutters. Current learning-based methods rely on the powerful capabilities of deep networks, but neglect explicit modeling and discriminative representation learning of various HFCs, which is important to distinguish targets from other HFCs. To address the aforementioned issues, we propose a dynamic high-frequency convolution (DHiF) to translate the discriminative modeling process into the generation of a dynamic local filter bank. Especially, DHiF is sensitive to HFCs, owing to the dynamic parameters of its generated filters being symmetrically adjusted within a zero-centered range according to Fourier transformation properties. Combining with standard convolution operations, DHiF can adaptively and dynamically process different HFC regions and capture their distinctive grayscale variation characteristics for discriminative representation learning. DHiF functions as a drop-in replacement for standard convolution and can be used in arbitrary SIRST detection networks without significant decrease in computational efficiency. To validate the effectiveness of our DHiF, we conducted extensive experiments across different SIRST detection networks on real-scene datasets. Compared to other state-of-the-art convolution operations, DHiF exhibits superior detection performance with promising improvement. Codes are available at https://github.com/TinaLRJ/DHiF.

</details>


### [15] [Fisheye Stereo Vision: Depth and Range Error](https://arxiv.org/abs/2602.02973)
*Leaf Jiang,Matthew Holzel,Bernhard Kaplan,Hsiou-Yuan Liu,Sabyasachi Paul,Karen Rankin,Piotr Swierczynski*

Main category: cs.CV

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This study derives analytical expressions for the depth and range error of fisheye stereo vision systems as a function of object distance, specifically accounting for accuracy at large angles.

</details>


### [16] [SceneLinker: Compositional 3D Scene Generation via Semantic Scene Graph from RGB Sequences](https://arxiv.org/abs/2602.02974)
*Seok-Young Kim,Dooyoung Kim,Woojin Cho,Hail Song,Suji Kang,Woontack Woo*

Main category: cs.CV

TL;DR: SceneLinker是一个通过语义场景图从RGB序列生成组合式3D场景的新框架，使用图网络和graph-VAE来捕捉对象间的上下文关系并生成与真实布局一致的3D场景。


<details>
  <summary>Details</summary>
Motivation: 为了基于每个用户的空间自适应体验混合现实内容，需要生成反映真实世界布局的3D场景，但现有方法难以充分捕捉对象间的上下文关系或主要关注形状合成。

Method: 设计了带有交叉检查特征注意力的图网络进行场景图预测，构建了包含联合形状和布局块的图变分自编码器(graph-VAE)用于3D场景生成。

Result: 在3RScan/3DSSG和SG-FRONT数据集上的实验表明，该方法在定量和定性评估中都优于最先进方法，即使在复杂室内环境和挑战性场景图约束下。

Conclusion: 该工作使用户能够通过场景图从其物理环境生成一致的3D空间，从而创建空间混合现实内容。

Abstract: We introduce SceneLinker, a novel framework that generates compositional 3D scenes via semantic scene graph from RGB sequences. To adaptively experience Mixed Reality (MR) content based on each user's space, it is essential to generate a 3D scene that reflects the real-world layout by compactly capturing the semantic cues of the surroundings. Prior works struggled to fully capture the contextual relationship between objects or mainly focused on synthesizing diverse shapes, making it challenging to generate 3D scenes aligned with object arrangements. We address these challenges by designing a graph network with cross-check feature attention for scene graph prediction and constructing a graph-variational autoencoder (graph-VAE), which consists of a joint shape and layout block for 3D scene generation. Experiments on the 3RScan/3DSSG and SG-FRONT datasets demonstrate that our approach outperforms state-of-the-art methods in both quantitative and qualitative evaluations, even in complex indoor environments and under challenging scene graph constraints. Our work enables users to generate consistent 3D spaces from their physical environments via scene graphs, allowing them to create spatial MR content. Project page is https://scenelinker2026.github.io.

</details>


### [17] [Aligning Forest and Trees in Images and Long Captions for Visually Grounded Understanding](https://arxiv.org/abs/2602.02977)
*Byeongju Woo,Zilin Wang,Byeonghyun Pak,Sangwoo Mo,Stella X. Yu*

Main category: cs.CV

TL;DR: CAFT是一种分层视觉语言表示学习框架，通过跨域对齐全局和局部语义，在无需像素级监督的情况下处理长文本图像检索任务，在6个长文本检索基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（如CLIP）将图像和文本作为整体对齐，难以处理长文本描述。细粒度视觉语言理解需要同时捕获全局上下文和局部细节的分层语义，但语言和视觉的分层结构通常不匹配，纯视觉分层往往将场景分割为外观驱动的部分而缺乏语义焦点。

Method: 提出CAFT框架，耦合从细到粗的视觉编码器和分层文本Transformer，使用分层对齐损失函数：整体图像与整体文本对齐，同时偏向区域-句子对应关系，使粗粒度语义建立在细粒度证据基础上而非无锚点的聚合。在3000万图像-文本对上进行训练。

Result: 在6个长文本检索基准测试中达到最先进性能，展现出强大的扩展性能。实验表明分层跨域对齐能够在没有显式区域级监督的情况下产生细粒度的、视觉接地的图像-文本表示。

Conclusion: CAFT通过分层跨域对齐成功解决了长文本图像检索的挑战，证明了在没有像素级监督的情况下学习细粒度视觉语言表示的有效性，为视觉语言理解提供了新的技术路径。

Abstract: Large vision-language models such as CLIP struggle with long captions because they align images and texts as undifferentiated wholes. Fine-grained vision-language understanding requires hierarchical semantics capturing both global context and localized details across visual and textual domains. Yet linguistic hierarchies from syntax or semantics rarely match visual organization, and purely visual hierarchies tend to fragment scenes into appearance-driven parts without semantic focus. We propose CAFT (Cross-domain Alignment of Forests and Trees), a hierarchical image-text representation learning framework that aligns global and local semantics across images and long captions without pixel-level supervision. Coupling a fine-to-coarse visual encoder with a hierarchical text transformer, it uses a hierarchical alignment loss that matches whole images with whole captions while biasing region-sentence correspondences, so that coarse semantics are built from fine-grained evidence rather than from aggregation untethered to part-level grounding. Trained on 30M image-text pairs, CAFT achieves state-of-the-art performance on six long-text retrieval benchmarks and exhibits strong scaling behavior. Experiments show that hierarchical cross-domain alignment enables fine-grained, visually grounded image-text representations to emerge without explicit region-level supervision.

</details>


### [18] [SharpTimeGS: Sharp and Stable Dynamic Gaussian Splatting via Lifespan Modulation](https://arxiv.org/abs/2602.02989)
*Zhanfeng Liao,Jiajun Zhang,Hanzhang Tu,Zhixi Wang,Yunqi Gao,Hongwen Zhang,Yebin Liu*

Main category: cs.CV

TL;DR: SharpTimeGS是一种基于4D高斯的寿命感知框架，通过可学习的寿命参数实现静态和动态区域的时域自适应建模，支持实时4K分辨率渲染。


<details>
  <summary>Details</summary>
Motivation: 解决现有高斯表示方法在静态和动态区域表示与优化之间难以平衡的问题，特别是在长期静态和短期动态区域的建模方面。

Method: 引入可学习寿命参数，将时间可见性从高斯衰减重构为平顶分布；设计寿命-速度感知的致密化策略，根据运动程度分配优化容量；实现运动幅度与时间持续时间的解耦。

Result: 在多个基准测试中达到最先进性能，在单块RTX 4090上支持4K分辨率100FPS的实时渲染，有效改善长期稳定性同时保持动态保真度。

Conclusion: SharpTimeGS通过寿命感知的4D高斯表示成功解决了动态场景新视角合成中静态与动态区域的平衡问题，为4D重建和沉浸式视觉体验提供了高效解决方案。

Abstract: Novel view synthesis of dynamic scenes is fundamental to achieving photorealistic 4D reconstruction and immersive visual experiences. Recent progress in Gaussian-based representations has significantly improved real-time rendering quality, yet existing methods still struggle to maintain a balance between long-term static and short-term dynamic regions in both representation and optimization. To address this, we present SharpTimeGS, a lifespan-aware 4D Gaussian framework that achieves temporally adaptive modeling of both static and dynamic regions under a unified representation. Specifically, we introduce a learnable lifespan parameter that reformulates temporal visibility from a Gaussian-shaped decay into a flat-top profile, allowing primitives to remain consistently active over their intended duration and avoiding redundant densification. In addition, the learned lifespan modulates each primitives' motion, reducing drift in long-lived static points while retaining unrestricted motion for short-lived dynamic ones. This effectively decouples motion magnitude from temporal duration, improving long-term stability without compromising dynamic fidelity. Moreover, we design a lifespan-velocity-aware densification strategy that mitigates optimization imbalance between static and dynamic regions by allocating more capacity to regions with pronounced motion while keeping static areas compact and stable. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art performance while supporting real-time rendering up to 4K resolution at 100 FPS on one RTX 4090.

</details>


### [19] [Video-OPD: Efficient Post-Training of Multimodal Large Language Models for Temporal Video Grounding via On-Policy Distillation](https://arxiv.org/abs/2602.02994)
*Jiaze Li,Hao Yin,Haoran Xu,Boshen Xu,Wenhui Tan,Zewen He,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: Video-OPD是一个高效的时序视频定位后训练框架，通过策略蒸馏方法替代传统强化学习，解决了稀疏奖励和高计算成本问题，实现了更快的收敛和更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于GRPO的时序视频定位方法受到稀疏奖励信号和巨大计算开销的根本限制，需要更有效的后训练范式。

Method: 提出Video-OPD框架，直接从当前策略采样轨迹进行优化，保持训练和推理分布对齐；使用前沿教师通过反向KL散度目标提供密集的token级监督；引入教师验证分歧聚焦(TVDF)训练课程，优先处理教师可靠且对学生信息量最大的轨迹。

Result: 实验结果表明Video-OPD在性能上持续超越GRPO，同时实现了显著更快的收敛速度和更低的计算成本。

Conclusion: 策略蒸馏被确立为时序视频定位中传统强化学习的有效替代方案，Video-OPD框架成功解决了稀疏奖励和计算效率问题。

Abstract: Reinforcement learning has emerged as a principled post-training paradigm for Temporal Video Grounding (TVG) due to its on-policy optimization, yet existing GRPO-based methods remain fundamentally constrained by sparse reward signals and substantial computational overhead. We propose Video-OPD, an efficient post-training framework for TVG inspired by recent advances in on-policy distillation. Video-OPD optimizes trajectories sampled directly from the current policy, thereby preserving alignment between training and inference distributions, while a frontier teacher supplies dense, token-level supervision via a reverse KL divergence objective. This formulation preserves the on-policy property critical for mitigating distributional shift, while converting sparse, episode-level feedback into fine-grained, step-wise learning signals. Building on Video-OPD, we introduce Teacher-Validated Disagreement Focusing (TVDF), a lightweight training curriculum that iteratively prioritizes trajectories that are both teacher-reliable and maximally informative for the student, thereby improving training efficiency. Empirical results demonstrate that Video-OPD consistently outperforms GRPO while achieving substantially faster convergence and lower computational cost, establishing on-policy distillation as an effective alternative to conventional reinforcement learning for TVG.

</details>


### [20] [VOILA: Value-of-Information Guided Fidelity Selection for Cost-Aware Multimodal Question Answering](https://arxiv.org/abs/2602.03007)
*Rahul Atul Bhope,K. R. Jayaram,Vinod Muthusamy,Ritesh Kumar,Vatche Isahagian,Nalini Venkatasubramanian*

Main category: cs.CV

TL;DR: VOILA是一个基于信息价值驱动的自适应保真度选择框架，用于视觉问答任务，通过预检索保真度选择优化多模态推理成本，在保持90-95%精度的同时减少50-60%的计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态视觉语言系统通常以固定保真度运行，导致在处理高保真度视觉输入时产生显著的计算和检索成本，需要一种能够根据查询需求自适应选择信息保真度的优化方法。

Method: 采用两阶段流水线：首先使用梯度提升回归器仅基于问题特征估计每个保真度的正确性概率，然后通过等渗校准器精炼概率以进行可靠决策，选择最大化期望效用的最小成本保真度。

Result: 在三个部署场景、五个数据集和六个不同规模的视觉语言模型上评估，VOILA能够持续实现50-60%的成本降低，同时保持90-95%的全分辨率精度。

Conclusion: 预检索保真度选择对于在资源约束下优化多模态推理至关重要，VOILA框架证明了通过信息价值驱动的自适应选择可以显著提高效率而不牺牲准确性。

Abstract: Despite significant costs from retrieving and processing high-fidelity visual inputs, most multimodal vision-language systems operate at fixed fidelity levels. We introduce VOILA, a framework for Value-Of-Information-driven adaptive fidelity selection in Visual Question Answering (VQA) that optimizes what information to retrieve before model execution. Given a query, VOILA uses a two-stage pipeline: a gradient-boosted regressor estimates correctness likelihood at each fidelity from question features alone, then an isotonic calibrator refines these probabilities for reliable decision-making. The system selects the minimum-cost fidelity maximizing expected utility given predicted accuracy and retrieval costs. We evaluate VOILA across three deployment scenarios using five datasets (VQA-v2, GQA, TextVQA, LoCoMo, FloodNet) and six Vision-Language Models (VLMs) with 7B-235B parameters. VOILA consistently achieves 50-60% cost reductions while retaining 90-95% of full-resolution accuracy across diverse query types and model architectures, demonstrating that pre-retrieval fidelity selection is vital to optimize multimodal inference under resource constraints.

</details>


### [21] [Thinking inside the Convolution for Image Inpainting: Reconstructing Texture via Structure under Global and Local Side](https://arxiv.org/abs/2602.03013)
*Haipeng Liu,Yang Wang,Biao Qian,Yong Rui,Meng Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种通过统计归一化和反归一化策略来缓解卷积下采样过程中结构和纹理特征图信息损失的方法，改善了图像修复的上采样输出质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于编码器-解码器架构的图像修复方法在卷积下采样过程中会不可避免地造成结构和纹理特征图的信息损失，导致非理想的上采样恢复效果。

Method: 采用统计归一化和反归一化策略，利用结构和纹理特征图在卷积下采样过程中相互辅助进行重建指导。

Result: 实验结果表明该方法在256*256和512*512分辨率图像上均优于现有最先进方法，特别是在将所有编码器替换为本方法时效果显著。

Conclusion: 通过结构和纹理特征图的相互辅助可以有效缓解卷积下采样过程中的信息损失，提升图像修复的质量。

Abstract: Image inpainting has earned substantial progress, owing to the encoder-and-decoder pipeline, which is benefited from the Convolutional Neural Networks (CNNs) with convolutional downsampling to inpaint the masked regions semantically from the known regions within the encoder, coupled with an upsampling process from the decoder for final inpainting output. Recent studies intuitively identify the high-frequency structure and low-frequency texture to be extracted by CNNs from the encoder, and subsequently for a desirable upsampling recovery. However, the existing arts inevitably overlook the information loss for both structure and texture feature maps during the convolutional downsampling process, hence suffer from a non-ideal upsampling output. In this paper, we systematically answer whether and how the structure and texture feature map can mutually help to alleviate the information loss during the convolutional downsampling. Given the structure and texture feature maps, we adopt the statistical normalization and denormalization strategy for the reconstruction guidance during the convolutional downsampling process. The extensive experimental results validate its advantages to the state-of-the-arts over the images from low-to-high resolutions including 256*256 and 512*512, especially holds by substituting all the encoders by ours. Our code is available at https://github.com/htyjers/ConvInpaint-TSGL

</details>


### [22] [A Vision-Based Analysis of Congestion Pricing in New York City](https://arxiv.org/abs/2602.03015)
*Mehmet Kerem Turkcan,Jhonatan Tavori,Javad Ghaderi,Gil Zussman,Zoran Kostic,Andrew Smyth*

Main category: cs.CV

TL;DR: 基于900多个交通摄像头的计算机视觉分析，研究纽约市拥堵收费项目对曼哈顿交通模式的影响


<details>
  <summary>Details</summary>
Motivation: 评估纽约市拥堵收费项目的实际效果，通过客观数据量化交通模式变化

Method: 使用计算机视觉流水线处理2024年11月至2026年1月期间的交通摄像头数据，建立基线交通模式并分析车辆密度变化

Result: 研究发现拥堵收费项目实施后交通模式出现系统性变化，但具体数据未在摘要中提供

Conclusion: 自动化交通摄像头分析为评估拥堵收费政策效果提供了有效方法，但需要更详细的数据来得出具体结论

Abstract: We examine the impact of New York City's congestion pricing program through automated analysis of traffic camera data. Our computer vision pipeline processes footage from over 900 cameras distributed throughout Manhattan and New York, comparing traffic patterns from November 2024 through the program's implementation in January 2025 until January 2026. We establish baseline traffic patterns and identify systematic changes in vehicle density across the monitored region.

</details>


### [23] [MUSE: A Multi-agent Framework for Unconstrained Story Envisioning via Closed-Loop Cognitive Orchestration](https://arxiv.org/abs/2602.03028)
*Wenzhang Sun,Zhenyu Wang,Zhangchi Hu,Chunfeng Wang,Hao Li,Wei Chen*

Main category: cs.CV

TL;DR: MUSE是一个多智能体框架，通过迭代式的计划-执行-验证-修订循环来解决长格式音视频故事生成中的语义漂移和身份一致性问题，显著提升了叙事连贯性和多模态质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从简短用户提示生成长格式音视频故事时存在意图-执行差距，容易产生语义漂移和身份不一致的问题，特别是在长序列生成中。

Method: 将故事生成建模为闭环约束执行问题，通过多智能体框架协调生成过程，将叙事意图转化为对身份、空间构图和时间连续性的显式机器可执行控制，并在生成过程中应用针对性多模态反馈来纠正违规。

Result: 实验表明，MUSE相比代表性基线方法在长时域叙事连贯性、跨模态身份一致性和电影质量方面有显著提升。

Conclusion: MUSE框架通过闭环约束执行和多智能体协调，有效解决了长格式音视频故事生成中的关键挑战，为开放端故事生成提供了可靠的解决方案。

Abstract: Generating long-form audio-visual stories from a short user prompt remains challenging due to an intent-execution gap, where high-level narrative intent must be preserved across coherent, shot-level multimodal generation over long horizons. Existing approaches typically rely on feed-forward pipelines or prompt-only refinement, which often leads to semantic drift and identity inconsistency as sequences grow longer. We address this challenge by formulating storytelling as a closed-loop constraint enforcement problem and propose MUSE, a multi-agent framework that coordinates generation through an iterative plan-execute-verify-revise loop. MUSE translates narrative intent into explicit, machine-executable controls over identity, spatial composition, and temporal continuity, and applies targeted multimodal feedback to correct violations during generation. To evaluate open-ended storytelling without ground-truth references, we introduce MUSEBench, a reference-free evaluation protocol validated by human judgments. Experiments demonstrate that MUSE substantially improves long-horizon narrative coherence, cross-modal identity consistency, and cinematic quality compared with representative baselines.

</details>


### [24] [Bongards at the Boundary of Perception and Reasoning: Programs or Language?](https://arxiv.org/abs/2602.03038)
*Cassidy Langenfeld,Claas Beger,Gloria Geng,Wasu Top Piriyakulkij,Keya Hu,Yewen Pu,Kevin Ellis*

Main category: cs.CV

TL;DR: 神经符号方法解决Bongard视觉推理问题，使用LLM生成参数化程序表示并通过贝叶斯优化进行参数拟合，在规则已知和从零开始两种场景下验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在常规视觉任务中表现良好，但缺乏人类在全新情境中部署视觉推理的能力，而Bongard问题正是测试这种能力的经典挑战

Method: 提出神经符号方法：给定假设解决方案规则，利用大型语言模型生成参数化程序表示，然后使用贝叶斯优化进行参数拟合

Result: 在已知真实规则的Bongard问题图像分类和从零开始解决问题两个任务上进行了评估

Conclusion: 该方法为解决需要抽象推理的复杂视觉问题提供了一种有效的神经符号框架

Abstract: Vision-Language Models (VLMs) have made great strides in everyday visual tasks, such as captioning a natural image, or answering commonsense questions about such images. But humans possess the puzzling ability to deploy their visual reasoning abilities in radically new situations, a skill rigorously tested by the classic set of visual reasoning challenges known as the Bongard problems. We present a neurosymbolic approach to solving these problems: given a hypothesized solution rule for a Bongard problem, we leverage LLMs to generate parameterized programmatic representations for the rule and perform parameter fitting using Bayesian optimization. We evaluate our method on classifying Bongard problem images given the ground truth rule, as well as on solving the problems from scratch.

</details>


### [25] [HP-GAN: Harnessing pretrained networks for GAN improvement with FakeTwins and discriminator consistency](https://arxiv.org/abs/2602.03039)
*Geonhui Son,Jeong Ryong Lee,Dosik Hwang*

Main category: cs.CV

TL;DR: HP-GAN通过FakeTwins自监督学习和判别器一致性机制，利用预训练网络增强GAN的图像生成质量和多样性，在17个数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要利用预训练网络计算感知损失或特征空间，但未充分利用神经网络先验和不同架构判别器间的一致性潜力。

Method: 提出FakeTwins：使用预训练网络作为编码器计算自监督损失来训练生成器；引入CNN和ViT特征网络判别器间的一致性机制，提升训练鲁棒性。

Result: 在17个数据集（大规模、小规模和有限数据场景）上评估，HP-GAN在FID指标上持续优于当前最先进方法，图像多样性和质量显著提升。

Conclusion: 通过有效利用神经网络先验和判别器一致性，HP-GAN为高质量图像生成提供了新思路，在多个场景下展现出优越性能。

Abstract: Generative Adversarial Networks (GANs) have made significant progress in enhancing the quality of image synthesis. Recent methods frequently leverage pretrained networks to calculate perceptual losses or utilize pretrained feature spaces. In this paper, we extend the capabilities of pretrained networks by incorporating innovative self-supervised learning techniques and enforcing consistency between discriminators during GAN training. Our proposed method, named HP-GAN, effectively exploits neural network priors through two primary strategies: FakeTwins and discriminator consistency. FakeTwins leverages pretrained networks as encoders to compute a self-supervised loss and applies this through the generated images to train the generator, thereby enabling the generation of more diverse and high quality images. Additionally, we introduce a consistency mechanism between discriminators that evaluate feature maps extracted from Convolutional Neural Network (CNN) and Vision Transformer (ViT) feature networks. Discriminator consistency promotes coherent learning among discriminators and enhances training robustness by aligning their assessments of image quality. Our extensive evaluation across seventeen datasets-including scenarios with large, small, and limited data, and covering a variety of image domains-demonstrates that HP-GAN consistently outperforms current state-of-the-art methods in terms of Fréchet Inception Distance (FID), achieving significant improvements in image diversity and quality. Code is available at: https://github.com/higun2/HP-GAN.

</details>


### [26] [IVC-Prune: Revealing the Implicit Visual Coordinates in LVLMs for Vision Token Pruning](https://arxiv.org/abs/2602.03060)
*Zhichao Sun,Yidong Ma,Gang Liu,Yibo Chen,Xu Tang,Yao Hu,Yongchao Xu*

Main category: cs.CV

TL;DR: IVC-Prune是一种无需训练、基于提示的视觉令牌剪枝方法，通过识别旋转位置嵌入中的隐式视觉坐标令牌和语义相关前景令牌，在保持空间推理能力的同时将视觉令牌减少约50%。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型处理高分辨率视觉输入时推理成本过高，现有基于语义相关性的剪枝方法会丢弃对空间推理至关重要的令牌。

Method: 通过理论分析RoPE的数学特性识别隐式视觉坐标令牌（IVC tokens），采用两阶段过程（语义种子发现和基于值向量相似度的上下文精炼）识别前景令牌，结合两者进行剪枝。

Result: 在4个代表性LVLM和20个基准测试中，IVC-Prune减少约50%视觉令牌的同时保持≥99%的原始性能，在某些基准上甚至有所提升。

Conclusion: IVC-Prune通过理论驱动的令牌识别方法，有效解决了LVLM高分辨率处理的效率问题，同时保持了空间推理能力，为视觉令牌剪枝提供了新视角。

Abstract: Large Vision-Language Models (LVLMs) achieve impressive performance across multiple tasks. A significant challenge, however, is their prohibitive inference cost when processing high-resolution visual inputs. While visual token pruning has emerged as a promising solution, existing methods that primarily focus on semantic relevance often discard tokens that are crucial for spatial reasoning. We address this gap through a novel insight into \emph{how LVLMs process spatial reasoning}. Specifically, we reveal that LVLMs implicitly establish visual coordinate systems through Rotary Position Embeddings (RoPE), where specific token positions serve as \textbf{implicit visual coordinates} (IVC tokens) that are essential for spatial reasoning. Based on this insight, we propose \textbf{IVC-Prune}, a training-free, prompt-aware pruning strategy that retains both IVC tokens and semantically relevant foreground tokens. IVC tokens are identified by theoretically analyzing the mathematical properties of RoPE, targeting positions at which its rotation matrices approximate identity matrix or the $90^\circ$ rotation matrix. Foreground tokens are identified through a robust two-stage process: semantic seed discovery followed by contextual refinement via value-vector similarity. Extensive evaluations across four representative LVLMs and twenty diverse benchmarks show that IVC-Prune reduces visual tokens by approximately 50\% while maintaining $\geq$ 99\% of the original performance and even achieving improvements on several benchmarks. Source codes are available at https://github.com/FireRedTeam/IVC-Prune.

</details>


### [27] [JRDB-Pose3D: A Multi-person 3D Human Pose and Shape Estimation Dataset for Robotics](https://arxiv.org/abs/2602.03064)
*Sandika Biswas,Kian Izadpanah,Hamid Rezatofighi*

Main category: cs.CV

TL;DR: JRDB-Pose3D是一个从移动机器人平台采集的多人室内外3D人体姿态数据集，填补了现有数据集在真实拥挤场景中的空白，包含丰富的SMPL姿态标注、跟踪ID和社会交互信息。


<details>
  <summary>Details</summary>
Motivation: 现实世界场景本质上是拥挤的，但现有3D人体姿态估计数据集主要关注单人场景或受控实验室环境，限制了其在真实应用中的相关性。需要能够处理多人、遮挡和复杂环境的数据集。

Method: 通过移动机器人平台采集室内外多人环境数据，提供SMPL基础的3D姿态标注，包含一致的身体形状参数和随时间跟踪的个体ID，并继承JRDB数据集的所有可用标注。

Result: 数据集平均每帧包含5-10个人体姿态，某些场景同时出现多达35人，包含频繁遮挡、截断和出框等真实挑战，并提供社会分组、活动交互、语义分割等多维度标注信息。

Conclusion: JRDB-Pose3D为各种下游感知和以人为中心的理解任务提供了一个全面的数据集，能够更好地反映真实世界的复杂动态场景。

Abstract: Real-world scenes are inherently crowded. Hence, estimating 3D poses of all nearby humans, tracking their movements over time, and understanding their activities within social and environmental contexts are essential for many applications, such as autonomous driving, robot perception, robot navigation, and human-robot interaction. However, most existing 3D human pose estimation datasets primarily focus on single-person scenes or are collected in controlled laboratory environments, which restricts their relevance to real-world applications. To bridge this gap, we introduce JRDB-Pose3D, which captures multi-human indoor and outdoor environments from a mobile robotic platform. JRDB-Pose3D provides rich 3D human pose annotations for such complex and dynamic scenes, including SMPL-based pose annotations with consistent body-shape parameters and track IDs for each individual over time. JRDB-Pose3D contains, on average, 5-10 human poses per frame, with some scenes featuring up to 35 individuals simultaneously. The proposed dataset presents unique challenges, including frequent occlusions, truncated bodies, and out-of-frame body parts, which closely reflect real-world environments. Moreover, JRDB-Pose3D inherits all available annotations from the JRDB dataset, such as 2D pose, information about social grouping, activities, and interactions, full-scene semantic masks with consistent human- and object-level tracking, and detailed annotations for each individual, such as age, gender, and race, making it a holistic dataset for a wide range of downstream perception and human-centric understanding tasks.

</details>


### [28] [Finding Optimal Video Moment without Training: Gaussian Boundary Optimization for Weakly Supervised Video Grounding](https://arxiv.org/abs/2602.03071)
*Sunoh Kim,Kimin Yun,Daeho Um*

Main category: cs.CV

TL;DR: GBO是一种新颖的推理框架，通过求解平衡提案覆盖度和片段紧凑性的优化问题来预测片段边界，无需训练即可显著提升弱监督视频时序定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯提案的方法依赖启发式映射从高斯参数推导片段边界，导致定位性能欠佳，需要更优的边界推断策略。

Method: 提出高斯边界优化(GBO)框架，推导出封闭形式的优化问题解，在不同惩罚机制下分析最优性条件，兼容单高斯和混合提案架构。

Result: GBO在标准基准测试中显著提升定位性能，达到最先进结果，实验证明其高效性和对不同提案方案的泛化能力。

Conclusion: GBO提供了理论严谨且实用的边界优化解决方案，为弱监督视频时序定位任务提供了有效的推理框架。

Abstract: Weakly supervised temporal video grounding aims to localize query-relevant segments in untrimmed videos using only video-sentence pairs, without requiring ground-truth segment annotations that specify exact temporal boundaries. Recent approaches tackle this task by utilizing Gaussian-based temporal proposals to represent query-relevant segments. However, their inference strategies rely on heuristic mappings from Gaussian parameters to segment boundaries, resulting in suboptimal localization performance. To address this issue, we propose Gaussian Boundary Optimization (GBO), a novel inference framework that predicts segment boundaries by solving a principled optimization problem that balances proposal coverage and segment compactness. We derive a closed-form solution for this problem and rigorously analyze the optimality conditions under varying penalty regimes. Beyond its theoretical foundations, GBO offers several practical advantages: it is training-free and compatible with both single-Gaussian and mixture-based proposal architectures. Our experiments show that GBO significantly improves localization, achieving state-of-the-art results across standard benchmarks. Extensive experiments demonstrate the efficiency and generalizability of GBO across various proposal schemes. The code is available at \href{https://github.com/sunoh-kim/gbo}{https://github.com/sunoh-kim/gbo}.

</details>


### [29] [A generalizable large-scale foundation model for musculoskeletal radiographs](https://arxiv.org/abs/2602.03076)
*Shinn Kim,Soobin Lee,Kyoungseob Shin,Han-Soo Kim,Yongsung Kim,Minsu Kim,Juhong Nam,Somang Ko,Daeheon Kwon,Wook Huh,Ilkyu Han,Sunghoon Kwon*

Main category: cs.CV

TL;DR: SKELEX是一个基于120万张肌肉骨骼X光片训练的大规模基础模型，通过自监督学习实现跨疾病和解剖区域的通用性，在骨折检测、骨关节炎分级和骨肿瘤分类等12项任务中表现优异，并具备零样本异常定位能力。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型在肌肉骨骼疾病检测中存在任务特定性、标注依赖性和泛化性不足的问题，临床需要能够在不同疾病和解剖区域间通用的基础模型，但公开数据集规模有限且缺乏多样性。

Method: 采用自监督学习方法，在120万张多样化的肌肉骨骼X光片上进行训练，开发了SKELEX基础模型，并基于其零样本异常定位能力构建了可解释的区域引导骨肿瘤预测模型。

Result: 在12个下游诊断任务中普遍优于基线模型，展示了零样本异常定位能力，开发的骨肿瘤预测模型在独立外部数据集上保持稳健性能，并已部署为公开可访问的Web应用。

Conclusion: SKELEX提供了一个可扩展、标签高效且可泛化的肌肉骨骼成像AI框架，为临床转化和数据高效研究奠定了基础。

Abstract: Artificial intelligence (AI) has shown promise in detecting and characterizing musculoskeletal diseases from radiographs. However, most existing models remain task-specific, annotation-dependent, and limited in generalizability across diseases and anatomical regions. Although a generalizable foundation model trained on large-scale musculoskeletal radiographs is clinically needed, publicly available datasets remain limited in size and lack sufficient diversity to enable training across a wide range of musculoskeletal conditions and anatomical sites. Here, we present SKELEX, a large-scale foundation model for musculoskeletal radiographs, trained using self-supervised learning on 1.2 million diverse, condition-rich images. The model was evaluated on 12 downstream diagnostic tasks and generally outperformed baselines in fracture detection, osteoarthritis grading, and bone tumor classification. Furthermore, SKELEX demonstrated zero-shot abnormality localization, producing error maps that identified pathologic regions without task-specific training. Building on this capability, we developed an interpretable, region-guided model for predicting bone tumors, which maintained robust performance on independent external datasets and was deployed as a publicly accessible web application. Overall, SKELEX provides a scalable, label-efficient, and generalizable AI framework for musculoskeletal imaging, establishing a foundation for both clinical translation and data-efficient research in musculoskeletal radiology.

</details>


### [30] [Gromov Wasserstein Optimal Transport for Semantic Correspondences](https://arxiv.org/abs/2602.03105)
*Francis Snelgar,Stephen Gould,Ming Xu,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: 提出了一种基于最优传输算法的语义匹配方法，用Gromov Wasserstein空间平滑先验替代传统最近邻匹配，在保持DINOv2特征准确性的同时提升空间一致性，性能媲美或超越现有融合DINOv2和Stable Diffusion特征的方法，且计算效率提升5-10倍。


<details>
  <summary>Details</summary>
Motivation: 当前语义对应任务中，融合DINOv2和Stable Diffusion特征的方法虽然性能优异但计算成本高昂。DINOv2特征准确但稀疏，Stable Diffusion特征空间一致但需要额外计算。需要寻找更高效的方法来获得空间一致的对应关系。

Method: 采用最优传输算法替代标准最近邻匹配，引入Gromov Wasserstein空间平滑先验来增强空间一致性。该方法仅使用DINOv2特征，避免了计算昂贵的Stable Diffusion特征提取。

Result: 新方法显著提升了DINOv2基线的性能，与使用Stable Diffusion特征的最先进方法竞争甚至超越，同时计算效率提高了5-10倍。

Conclusion: 通过引入最优传输算法和空间平滑先验，可以在不使用Stable Diffusion特征的情况下获得高质量的语义对应关系，为语义匹配任务提供了更高效且性能优异的解决方案。

Abstract: Establishing correspondences between image pairs is a long studied problem in computer vision. With recent large-scale foundation models showing strong zero-shot performance on downstream tasks including classification and segmentation, there has been interest in using the internal feature maps of these models for the semantic correspondence task. Recent works observe that features from DINOv2 and Stable Diffusion (SD) are complementary, the former producing accurate but sparse correspondences, while the latter produces spatially consistent correspondences. As a result, current state-of-the-art methods for semantic correspondence involve combining features from both models in an ensemble. While the performance of these methods is impressive, they are computationally expensive, requiring evaluating feature maps from large-scale foundation models. In this work we take a different approach, instead replacing SD features with a superior matching algorithm which is imbued with the desirable spatial consistency property. Specifically, we replace the standard nearest neighbours matching with an optimal transport algorithm that includes a Gromov Wasserstein spatial smoothness prior. We show that we can significantly boost the performance of the DINOv2 baseline, and be competitive and sometimes surpassing state-of-the-art methods using Stable Diffusion features, while being 5--10x more efficient. We make code available at https://github.com/fsnelgar/semantic_matching_gwot .

</details>


### [31] [Beyond Cropping and Rotation: Automated Evolution of Powerful Task-Specific Augmentations with Generative Models](https://arxiv.org/abs/2602.03123)
*Judah Goldfeder,Shreyes Kaliyur,Vaibhav Sourirajan,Patrick Minwan Puma,Philippe Martin Wyder,Yuhang Hu,Jiong Lin,Hod Lipson*

Main category: cs.CV

TL;DR: EvoAug是一个自动化数据增强学习框架，利用生成模型和进化算法学习任务特定的分层增强策略，在细粒度分类和少样本学习中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统数据增强方法多样性有限，而生成模型虽能提供更真实多样的数据，但若与任务不匹配可能降低性能，需要自动化方法来优化增强策略。

Method: 提出EvoAug框架，结合条件扩散模型和少样本NeRF等生成模型，使用高效进化算法学习随机增强树，实现分层组合的结构化自适应变换。

Result: 在细粒度分类和少样本学习任务中取得强劲性能，即使在低数据设置下也能发现符合领域知识的增强策略。

Conclusion: 学习型生成增强方法具有巨大潜力，为鲁棒模型训练开辟了新可能性，EvoAug框架成功实现了任务特定增强的自动化学习。

Abstract: Data augmentation has long been a cornerstone for reducing overfitting in vision models, with methods like AutoAugment automating the design of task-specific augmentations. Recent advances in generative models, such as conditional diffusion and few-shot NeRFs, offer a new paradigm for data augmentation by synthesizing data with significantly greater diversity and realism. However, unlike traditional augmentations like cropping or rotation, these methods introduce substantial changes that enhance robustness but also risk degrading performance if the augmentations are poorly matched to the task. In this work, we present EvoAug, an automated augmentation learning pipeline, which leverages these generative models alongside an efficient evolutionary algorithm to learn optimal task-specific augmentations. Our pipeline introduces a novel approach to image augmentation that learns stochastic augmentation trees that hierarchically compose augmentations, enabling more structured and adaptive transformations. We demonstrate strong performance across fine-grained classification and few-shot learning tasks. Notably, our pipeline discovers augmentations that align with domain knowledge, even in low-data settings. These results highlight the potential of learned generative augmentations, unlocking new possibilities for robust model training.

</details>


### [32] [Feature, Alignment, and Supervision in Category Learning: A Comparative Approach with Children and Neural Networks](https://arxiv.org/abs/2602.03124)
*Fanxiao Wani Qiu,Oscar Leong*

Main category: cs.CV

TL;DR: 人类儿童和卷积神经网络在少样本半监督分类学习中的比较研究，发现两者在监督程度、特征结构和感知对齐方面表现出不同的学习模式。


<details>
  <summary>Details</summary>
Motivation: 理解人类和机器如何从稀疏数据中学习是认知科学和机器学习领域的核心问题，需要通过物种公平设计来比较两者的学习机制。

Method: 采用物种公平设计，在相同条件下比较儿童和CNN在少样本半监督分类任务中的表现，通过变化监督程度（1/3/6个标签）、目标特征（大小、形状、图案）和感知对齐（高/低）来评估学习效果。

Result: 儿童能够从最少标签中快速泛化，但表现出强烈的特征特异性偏差和对对齐的敏感性；CNN则显示监督增加能改善性能，但对齐和特征结构调节了额外监督对学习的影响。

Conclusion: 人类与模型比较必须在适当条件下进行，应重点关注监督、特征结构和对齐之间的相互作用，而非单纯的整体准确率比较。

Abstract: Understanding how humans and machines learn from sparse data is central to cognitive science and machine learning. Using a species-fair design, we compare children and convolutional neural networks (CNNs) in a few-shot semi-supervised category learning task. Both learners are exposed to novel object categories under identical conditions. Learners receive mixtures of labeled and unlabeled exemplars while we vary supervision (1/3/6 labels), target feature (size, shape, pattern), and perceptual alignment (high/low). We find that children generalize rapidly from minimal labels but show strong feature-specific biases and sensitivity to alignment. CNNs show a different interaction profile: added supervision improves performance, but both alignment and feature structure moderate the impact additional supervision has on learning. These results show that human-model comparisons must be drawn under the right conditions, emphasizing interactions among supervision, feature structure, and alignment rather than overall accuracy.

</details>


### [33] [Flexible Geometric Guidance for Probabilistic Human Pose Estimation with Diffusion Models](https://arxiv.org/abs/2602.03126)
*Francis Snelgar,Ming Xu,Stephen Gould,Liang Zheng,Akshay Asthana*

Main category: cs.CV

TL;DR: 提出基于扩散模型的3D人体姿态估计框架，通过无条件的3D扩散模型和2D关键点检测器的热图梯度引导，从单一2D图像生成多个合理的3D姿态样本，无需配对的2D-3D训练数据。


<details>
  <summary>Details</summary>
Motivation: 解决3D姿态估计中的深度模糊和遮挡问题，传统方法假设确定性映射且需要大量配对数据，存在泛化问题。

Method: 使用条件生成引导框架，在仅使用3D数据训练的无条件扩散模型基础上，通过2D关键点检测器的热图梯度进行采样引导。

Result: 在Human 3.6M数据集上达到无需配对数据方法的最优性能，在MPI-INF-3DHP和3DPW数据集上展现良好泛化能力，并能用于姿态生成和补全等新任务。

Conclusion: 扩散模型框架有效解决了3D姿态估计的不确定性问题，提供了概率分布采样方法，无需配对训练数据且具有良好泛化性和任务灵活性。

Abstract: 3D human pose estimation from 2D images is a challenging problem due to depth ambiguity and occlusion. Because of these challenges the task is underdetermined, where there exists multiple -- possibly infinite -- poses that are plausible given the image. Despite this, many prior works assume the existence of a deterministic mapping and estimate a single pose given an image. Furthermore, methods based on machine learning require a large amount of paired 2D-3D data to train and suffer from generalization issues to unseen scenarios. To address both of these issues, we propose a framework for pose estimation using diffusion models, which enables sampling from a probability distribution over plausible poses which are consistent with a 2D image. Our approach falls under the guidance framework for conditional generation, and guides samples from an unconditional diffusion model, trained only on 3D data, using the gradients of the heatmaps from a 2D keypoint detector. We evaluate our method on the Human 3.6M dataset under best-of-$m$ multiple hypothesis evaluation, showing state-of-the-art performance among methods which do not require paired 2D-3D data for training. We additionally evaluate the generalization ability using the MPI-INF-3DHP and 3DPW datasets and demonstrate competitive performance. Finally, we demonstrate the flexibility of our framework by using it for novel tasks including pose generation and pose completion, without the need to train bespoke conditional models. We make code available at https://github.com/fsnelgar/diffusion_pose .

</details>


### [34] [FinMTM: A Multi-Turn Multimodal Benchmark for Financial Reasoning and Agent Evaluation](https://arxiv.org/abs/2602.03130)
*Chenxi Zhang,Ziliang Gan,Liyun Zhu,Youwei Pang,Qing Zhang,Rongjunchen Zhang*

Main category: cs.CV

TL;DR: FinMTM是一个多轮多模态金融基准测试，包含11,133个中英双语QA对，涵盖多种图表类型和任务格式，用于全面评估视觉语言模型在金融领域的表现。


<details>
  <summary>Details</summary>
Motivation: 金融领域对视觉语言模型提出特殊挑战，但现有基准测试多为单轮且问题格式单一，无法全面评估实际应用场景中的表现。

Method: 构建包含蜡烛图、统计图和报表图等多种金融图表的多轮多模态数据集，设计多种任务类型（单选、多选、多轮对话、智能体任务）及相应的评估协议。

Result: 对22个视觉语言模型的评估显示，它们在细粒度视觉感知、长上下文推理和复杂智能体工作流程方面存在明显局限。

Conclusion: FinMTM基准测试揭示了当前VLMs在金融领域的不足，为未来模型改进提供了重要参考依据。

Abstract: The financial domain poses substantial challenges for vision-language models (VLMs) due to specialized chart formats and knowledge-intensive reasoning requirements. However, existing financial benchmarks are largely single-turn and rely on a narrow set of question formats, limiting comprehensive evaluation in realistic application scenarios. To address this gap, we propose FinMTM, a multi-turn multimodal benchmark that expands diversity along both data and task dimensions. On the data side, we curate and annotate 11{,}133 bilingual (Chinese and English) financial QA pairs grounded in financial visuals, including candlestick charts, statistical plots, and report figures. On the task side, FinMTM covers single- and multiple-choice questions, multi-turn open-ended dialogues, and agent-based tasks. We further design task-specific evaluation protocols, including a set-overlap scoring rule for multiple-choice questions, a weighted combination of turn-level and session-level scores for multi-turn dialogues, and a composite metric that integrates planning quality with final outcomes for agent tasks. Extensive experimental evaluation of 22 VLMs reveal their limitations in fine-grained visual perception, long-context reasoning, and complex agent workflows.

</details>


### [35] [SwiftVLM: Efficient Vision-Language Model Inference via Cross-Layer Token Bypass](https://arxiv.org/abs/2602.03134)
*Chen Qian,Xinran Yu,Danyang Li,Guoxuan Chi,Zheng Yang,Qiang Ma,Xin Miao*

Main category: cs.CV

TL;DR: SwiftVLM是一种无需训练的视觉语言模型剪枝方法，通过bypass机制保留被早期剪枝的视觉token以供后续重新评估，解决了现有方法在细粒度视觉任务中因过早剪枝导致的关键信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 现有视觉token剪枝方法在粗粒度推理任务中有效，但在需要细粒度视觉细节的任务中存在显著性能下降。研究发现不同层级的视觉token重要性存在显著差异，浅层被认为不重要的token可能在后续文本条件推理中变得至关重要。

Method: 提出bypass剪枝范式，保留未被选择的视觉token并将其传递到后续剪枝阶段进行重新评估。SwiftVLM在具有强视觉token选择能力的模型特定层级执行剪枝，同时支持跨层级的独立剪枝决策。

Result: 在多个视觉语言模型和基准测试中，SwiftVLM始终优于现有剪枝策略，实现了更优的准确率-效率权衡和更可靠的视觉token选择行为。

Conclusion: 通过避免过早剪枝造成的关键信息不可逆损失，SwiftVLM提供了一种简单有效的训练免费剪枝方法，显著提升了视觉语言模型在保持效率的同时处理细粒度视觉任务的能力。

Abstract: Visual token pruning is a promising approach for reducing the computational cost of vision-language models (VLMs), and existing methods often rely on early pruning decisions to improve efficiency. While effective on coarse-grained reasoning tasks, they suffer from significant performance degradation on tasks requiring fine-grained visual details. Through layer-wise analysis, we reveal substantial discrepancies in visual token importance across layers, showing that tokens deemed unimportant at shallow layers can later become highly relevant for text-conditioned reasoning. To avoid irreversible critical information loss caused by premature pruning, we introduce a new pruning paradigm, termed bypass, which preserves unselected visual tokens and forwards them to subsequent pruning stages for re-evaluation. Building on this paradigm, we propose SwiftVLM, a simple and training-free method that performs pruning at model-specific layers with strong visual token selection capability, while enabling independent pruning decisions across layers. Experiments across multiple VLMs and benchmarks demonstrate that SwiftVLM consistently outperforms existing pruning strategies, achieving superior accuracy-efficiency trade-offs and more faithful visual token selection behavior.

</details>


### [36] [FSOD-VFM: Few-Shot Object Detection with Vision Foundation Models and Graph Diffusion](https://arxiv.org/abs/2602.03137)
*Chen-Bin Feng,Youyang Sha,Longfei Liu,Yongjun Yu,Chi Man Vong,Xuanlong Yu,Xi Shen*

Main category: cs.CV

TL;DR: FSOD-VFM是一个利用视觉基础模型进行小样本目标检测的框架，通过通用建议网络、SAM2掩码提取和DINOv2特征，结合图置信度重加权方法解决基础模型生成边界框的碎片化问题，在多个数据集上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然基础模型具有强大的泛化能力，但通用建议网络生成的边界框往往存在过度碎片化问题，仅覆盖部分物体区域，导致大量小尺寸假阳性建议而非完整准确的目标检测。

Method: 框架包含三个核心组件：通用建议网络(UPN)进行类别无关边界框生成，SAM2进行精确掩码提取，DINOv2特征用于新类别高效适应。引入基于图的置信度重加权方法，将预测边界框建模为有向图节点，通过图扩散操作传播置信度分数，提升完整物体的置信度并降低局部碎片部分的置信度。

Result: 在Pascal-5^i、COCO-20^i和CD-FSOD数据集上的实验表明，该方法显著优于现有方法，无需额外训练即可实现优异性能。在具有挑战性的CD-FSOD数据集10-shot设置中达到31.6 AP，远超之前仅达到21.4 AP的无训练方法。

Conclusion: FSOD-VFM通过整合视觉基础模型和图置信度重加权方法，有效解决了小样本目标检测中的边界框碎片化问题，实现了卓越的性能表现，为小样本目标检测提供了有效的无训练解决方案。

Abstract: In this paper, we present FSOD-VFM: Few-Shot Object Detectors with Vision Foundation Models, a framework that leverages vision foundation models to tackle the challenge of few-shot object detection. FSOD-VFM integrates three key components: a universal proposal network (UPN) for category-agnostic bounding box generation, SAM2 for accurate mask extraction, and DINOv2 features for efficient adaptation to new object categories. Despite the strong generalization capabilities of foundation models, the bounding boxes generated by UPN often suffer from overfragmentation, covering only partial object regions and leading to numerous small, false-positive proposals rather than accurate, complete object detections. To address this issue, we introduce a novel graph-based confidence reweighting method. In our approach, predicted bounding boxes are modeled as nodes in a directed graph, with graph diffusion operations applied to propagate confidence scores across the network. This reweighting process refines the scores of proposals, assigning higher confidence to whole objects and lower confidence to local, fragmented parts. This strategy improves detection granularity and effectively reduces the occurrence of false-positive bounding box proposals. Through extensive experiments on Pascal-5$^i$, COCO-20$^i$, and CD-FSOD datasets, we demonstrate that our method substantially outperforms existing approaches, achieving superior performance without requiring additional training. Notably, on the challenging CD-FSOD dataset, which spans multiple datasets and domains, our FSOD-VFM achieves 31.6 AP in the 10-shot setting, substantially outperforming previous training-free methods that reach only 21.4 AP. Code is available at: https://intellindust-ai-lab.github.io/projects/FSOD-VFM.

</details>


### [37] [Diversity-Preserved Distribution Matching Distillation for Fast Visual Synthesis](https://arxiv.org/abs/2602.03139)
*Tianhe Wu,Ruibin Li,Lei Zhang,Kede Ma*

Main category: cs.CV

TL;DR: DP-DMD：通过角色分离蒸馏框架解决DMD中的模式崩塌问题，第一步骤用v-prediction保持多样性，后续步骤用DMD损失提升质量，无需额外网络或正则化。


<details>
  <summary>Details</summary>
Motivation: 传统DMD方法因反向KL散度的模式寻求特性导致模式崩塌，现有解决方案依赖感知或对抗正则化，带来计算开销和训练不稳定问题。

Method: 提出角色分离蒸馏框架：第一步使用目标预测（如v-prediction）目标保持样本多样性，后续步骤使用标准DMD损失进行质量精炼，并在第一步阻断DMD目标梯度。

Result: 在文本到图像生成任务中，DP-DMD在保持视觉质量的同时有效保持了样本多样性，性能与最先进方法相当，且无需额外网络或真实图像。

Conclusion: DP-DMD通过简单的角色分离策略成功解决了DMD的模式崩塌问题，实现了高质量和多样性的平衡，为高效生成模型提供了新思路。

Abstract: Distribution matching distillation (DMD) aligns a multi-step generator with its few-step counterpart to enable high-quality generation under low inference cost. However, DMD tends to suffer from mode collapse, as its reverse-KL formulation inherently encourages mode-seeking behavior, for which existing remedies typically rely on perceptual or adversarial regularization, thereby incurring substantial computational overhead and training instability. In this work, we propose a role-separated distillation framework that explicitly disentangles the roles of distilled steps: the first step is dedicated to preserving sample diversity via a target-prediction (e.g., v-prediction) objective, while subsequent steps focus on quality refinement under the standard DMD loss, with gradients from the DMD objective blocked at the first step. We term this approach Diversity-Preserved DMD (DP-DMD), which, despite its simplicity -- no perceptual backbone, no discriminator, no auxiliary networks, and no additional ground-truth images -- preserves sample diversity while maintaining visual quality on par with state-of-the-art methods in extensive text-to-image experiments.

</details>


### [38] [Fully Kolmogorov-Arnold Deep Model in Medical Image Segmentation](https://arxiv.org/abs/2602.03156)
*Xingyu Qiu,Xinghua Ma,Dong Liang,Gongning Luo,Wei Wang,Kuanquan Wang,Shuo Li*

Main category: cs.CV

TL;DR: 本研究提出了首个完全基于Kolmogorov-Arnold (KA)表示的深度模型ALL U-KAN，通过Share-activation KAN和Grad-Free Spline两项创新解决了深度KAN网络训练困难和内存消耗大的问题，在医学图像分割任务中展现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度堆叠KAN网络由于训练困难和高内存需求而无法实现，限制了KAN架构的深度探索。本研究旨在克服这些限制，证明KA层可以完全替代传统深度学习架构。

Method: 1) 提出Share-activation KAN (SaKAN)，基于Sprecher变体的Kolmogorov-Arnold表示定理，简化参数化并增加训练样本密度；2) 提出Grad-Free Spline技术，消除样条梯度计算以减少内存使用；3) 构建ALL U-KAN，用KA和KAonv层完全替代FC和Conv层。

Result: 在三个医学图像分割任务中，完全KA架构相比部分KA架构和传统架构均获得更高的分割精度。相比直接深度堆叠KAN，ALL U-KAN参数量减少10倍，内存消耗降低20倍以上。

Conclusion: 本研究成功实现了首个完全KA基础的深度模型，证明了KA层可以完全替代传统深度学习架构，为深度KAN架构的探索开辟了新途径，在医学图像分割等任务中展现出优越的学习能力。

Abstract: Deeply stacked KANs are practically impossible due to high training difficulties and substantial memory requirements. Consequently, existing studies can only incorporate few KAN layers, hindering the comprehensive exploration of KANs. This study overcomes these limitations and introduces the first fully KA-based deep model, demonstrating that KA-based layers can entirely replace traditional architectures in deep learning and achieve superior learning capacity. Specifically, (1) the proposed Share-activation KAN (SaKAN) reformulates Sprecher's variant of Kolmogorov-Arnold representation theorem, which achieves better optimization due to its simplified parameterization and denser training samples, to ease training difficulty, (2) this paper indicates that spline gradients contribute negligibly to training while consuming huge GPU memory, thus proposes the Grad-Free Spline to significantly reduce memory usage and computational overhead. (3) Building on these two innovations, our ALL U-KAN is the first representative implementation of fully KA-based deep model, where the proposed KA and KAonv layers completely replace FC and Conv layers. Extensive evaluations on three medical image segmentation tasks confirm the superiority of the full KA-based architecture compared to partial KA-based and traditional architectures, achieving all higher segmentation accuracy. Compared to directly deeply stacked KAN, ALL U-KAN achieves 10 times reduction in parameter count and reduces memory consumption by more than 20 times, unlocking the new explorations into deep KAN architectures.

</details>


### [39] [Human-in-the-loop Adaptation in Group Activity Feature Learning for Team Sports Video Retrieval](https://arxiv.org/abs/2602.03157)
*Chihiro Nakatani,Hiroaki Kawashima,Norimichi Ukita*

Main category: cs.CV

TL;DR: 提出无需群体活动标注的人类参与循环自适应方法，通过自监督预训练和交互式微调改进群体活动视频检索性能，使用对比学习优化特征空间。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要预定义的群体活动类别和监督学习，而本文旨在开发无需群体活动标注的检索系统，通过人类参与循环适应来提升检索效果。

Method: 1. 自监督预训练群体活动特征空间；2. 交互式微调过程：通过数据高效视频选择向用户提供视频进行正负标注；3. 使用对比学习更新特征空间，使正负样本分别靠近和远离查询视频。

Result: 在两个团队运动数据集上的实验验证了方法显著提升检索性能，消融研究表明人类参与循环适应的多个组件对性能改进有贡献。

Conclusion: 该方法成功实现了无需群体活动标注的有效视频检索，人类参与循环适应和对比学习机制是关键创新，为群体活动分析提供了新思路。

Abstract: This paper proposes human-in-the-loop adaptation for Group Activity Feature Learning (GAFL) without group activity annotations. This human-in-the-loop adaptation is employed in a group-activity video retrieval framework to improve its retrieval performance. Our method initially pre-trains the GAF space based on the similarity of group activities in a self-supervised manner, unlike prior work that classifies videos into pre-defined group activity classes in a supervised learning manner. Our interactive fine-tuning process updates the GAF space to allow a user to better retrieve videos similar to query videos given by the user. In this fine-tuning, our proposed data-efficient video selection process provides several videos, which are selected from a video database, to the user in order to manually label these videos as positive or negative. These labeled videos are used to update (i.e., fine-tune) the GAF space, so that the positive and negative videos move closer to and farther away from the query videos through contrastive learning. Our comprehensive experimental results on two team sports datasets validate that our method significantly improves the retrieval performance. Ablation studies also demonstrate that several components in our human-in-the-loop adaptation contribute to the improvement of the retrieval performance. Code: https://github.com/chihina/GAFL-FINE-CVIU.

</details>


### [40] [BinaryDemoire: Moiré-Aware Binarization for Image Demoiréing](https://arxiv.org/abs/2602.03176)
*Zheng Chen,Zhi Yang,Xiaoyang Liu,Weihang Zhang,Mengfan Wang,Yifan Fu,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: BinaryDemoire是一个二值化去摩尔纹框架，通过频率感知的二进制门和分组残差适配器，在保持高压缩率的同时有效去除图像中的结构化摩尔纹伪影。


<details>
  <summary>Details</summary>
Motivation: 图像去摩尔纹需要处理频率相关的结构化伪影，但现有深度网络计算成本高。二值化虽然提供极致压缩，但直接应用于去摩尔纹任务效果不佳。

Method: 提出MABG门提取频率描述符和激活统计信息，预测通道级门控系数；设计SGRA进行结构化稀疏捷径对齐，通过交错混合促进跨通道信息交换。

Result: 在四个基准测试上的大量实验表明，BinaryDemoire超越了当前二值化方法。

Conclusion: 该框架成功地将二值化压缩与频率感知的摩尔纹去除相结合，为高效部署提供了可行方案。

Abstract: Image demoiréing aims to remove structured moiré artifacts in recaptured imagery, where degradations are highly frequency-dependent and vary across scales and directions. While recent deep networks achieve high-quality restoration, their full-precision designs remain costly for deployment. Binarization offers an extreme compression regime by quantizing both activations and weights to 1-bit. Yet, it has been rarely studied for demoiréing and performs poorly when naively applied. In this work, we propose BinaryDemoire, a binarized demoiréing framework that explicitly accommodates the frequency structure of moiré degradations. First, we introduce a moiré-aware binary gate (MABG) that extracts lightweight frequency descriptors together with activation statistics. It predicts channel-wise gating coefficients to condition the aggregation of binary convolution responses. Second, we design a shuffle-grouped residual adapter (SGRA) that performs structured sparse shortcut alignment. It further integrates interleaved mixing to promote information exchange across different channel partitions. Extensive experiments on four benchmarks demonstrate that the proposed BinaryDemoire surpasses current binarization methods. Code: https://github.com/zhengchen1999/BinaryDemoire.

</details>


### [41] [LSGQuant: Layer-Sensitivity Guided Quantization for One-Step Diffusion Real-World Video Super-Resolution](https://arxiv.org/abs/2602.03182)
*Tianxing Wu,Zheng Chen,Cirou Xu,Bowen Chai,Yong Guo,Yutong Liu,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: LSGQuant提出了一种层敏感度引导的量化方法，通过动态范围自适应量化器、方差导向层训练策略和量化感知优化，在保持性能的同时显著压缩一步扩散视频超分辨率模型。


<details>
  <summary>Details</summary>
Motivation: 一步扩散模型在视频超分辨率中表现出色但计算成本高，传统量化方法难以处理输入潜变量的高动态范围和层间行为差异。

Method: 使用动态范围自适应量化器(DRAQ)适应视频token激活，基于层敏感度分析采用方差导向层训练策略(VOLTS)，并通过量化感知优化(QAO)联合优化量化分支和高精度分支。

Result: 实验表明该方法在保持接近全精度模型性能的同时，显著优于现有量化技术。

Conclusion: LSGQuant有效解决了一步扩散视频超分辨率模型的量化挑战，实现了高性能的模型压缩。

Abstract: One-Step Diffusion Models have demonstrated promising capability and fast inference in video super-resolution (VSR) for real-world. Nevertheless, the substantial model size and high computational cost of Diffusion Transformers (DiTs) limit downstream applications. While low-bit quantization is a common approach for model compression, the effectiveness of quantized models is challenged by the high dynamic range of input latent and diverse layer behaviors. To deal with these challenges, we introduce LSGQuant, a layer-sensitivity guided quantizing approach for one-step diffusion-based real-world VSR. Our method incorporates a Dynamic Range Adaptive Quantizer (DRAQ) to fit video token activations. Furthermore, we estimate layer sensitivity and implement a Variance-Oriented Layer Training Strategy (VOLTS) by analyzing layer-wise statistics in calibration. We also introduce Quantization-Aware Optimization (QAO) to jointly refine the quantized branch and a retained high-precision branch. Extensive experiments demonstrate that our method has nearly performance to origin model with full-precision and significantly exceeds existing quantization techniques. Code is available at: https://github.com/zhengchen1999/LSGQuant.

</details>


### [42] [From Single Scan to Sequential Consistency: A New Paradigm for LIDAR Relocalization](https://arxiv.org/abs/2602.03198)
*Minghang Zhu,Zhijing Wang,Yuxin Guo,Wen Li,Sheng Ao,Cheng Wang*

Main category: cs.CV

TL;DR: TempLoc：一种通过建模序列一致性增强鲁棒性的LiDAR重定位框架，包含全局坐标估计、先验坐标生成和不确定性引导坐标融合三个模块，在NCLT和Oxford基准上大幅超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于回归的LiDAR重定位方法在动态或模糊场景中表现不佳，主要原因是仅依赖单帧推理或忽略扫描间的时空一致性。

Method: 提出三模块框架：1)全局坐标估计模块预测点级全局坐标和不确定性；2)先验坐标生成模块通过注意力机制估计帧间点对应关系；3)不确定性引导坐标融合模块端到端整合预测结果。

Result: 在NCLT和Oxford Robot-Car基准测试中，TempLoc大幅超越最先进方法，证明了时序感知对应关系建模的有效性。

Conclusion: 通过有效建模序列一致性，TempLoc显著提升了LiDAR重定位在动态和模糊场景中的鲁棒性和准确性，为时序感知的对应关系建模提供了有效解决方案。

Abstract: LiDAR relocalization aims to estimate the global 6-DoF pose of a sensor in the environment. However, existing regression-based approaches are prone to dynamic or ambiguous scenarios, as they either solely rely on single-frame inference or neglect the spatio-temporal consistency across scans. In this paper, we propose TempLoc, a new LiDAR relocalization framework that enhances the robustness of localization by effectively modeling sequential consistency. Specifically, a Global Coordinate Estimation module is first introduced to predict point-wise global coordinates and associated uncertainties for each LiDAR scan. A Prior Coordinate Generation module is then presented to estimate inter-frame point correspondences by the attention mechanism. Lastly, an Uncertainty-Guided Coordinate Fusion module is deployed to integrate both predictions of point correspondence in an end-to-end fashion, yielding a more temporally consistent and accurate global 6-DoF pose. Experimental results on the NCLT and Oxford Robot-Car benchmarks show that our TempLoc outperforms stateof-the-art methods by a large margin, demonstrating the effectiveness of temporal-aware correspondence modeling in LiDAR relocalization. Our code will be released soon.

</details>


### [43] [Hand3R: Online 4D Hand-Scene Reconstruction in the Wild](https://arxiv.org/abs/2602.03200)
*Wendi Hu,Haonan Zhou,Wenhao Hu,Gaoang Wang*

Main category: cs.CV

TL;DR: Hand3R是首个从单目视频进行联合4D手部-场景重建的在线框架，通过场景感知视觉提示机制将预训练手部专家与4D场景基础模型结合，实现高精度手部网格和密集度量尺度场景几何的同时重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多在局部坐标系中恢复孤立的手部，忽略了周围的3D环境，而理解物理交互需要联合重建动态手部和密集场景上下文。

Method: 通过场景感知视觉提示机制，将预训练手部专家的高保真手部先验注入到持久场景记忆中，在单次前向传递中同时重建准确的手部网格和密集度量尺度场景几何。

Result: 实验表明Hand3R无需依赖离线优化，在手部局部重建和全局定位方面都表现出竞争性性能。

Conclusion: 该方法成功解决了现有方法忽略场景环境的问题，实现了手部与场景的联合4D重建，为理解物理交互提供了重要技术支撑。

Abstract: For Embodied AI, jointly reconstructing dynamic hands and the dense scene context is crucial for understanding physical interaction. However, most existing methods recover isolated hands in local coordinates, overlooking the surrounding 3D environment. To address this, we present Hand3R, the first online framework for joint 4D hand-scene reconstruction from monocular video. Hand3R synergizes a pre-trained hand expert with a 4D scene foundation model via a scene-aware visual prompting mechanism. By injecting high-fidelity hand priors into a persistent scene memory, our approach enables simultaneous reconstruction of accurate hand meshes and dense metric-scale scene geometry in a single forward pass. Experiments demonstrate that Hand3R bypasses the reliance on offline optimization and delivers competitive performance in both local hand reconstruction and global positioning.

</details>


### [44] [VIRAL: Visual In-Context Reasoning via Analogy in Diffusion Transformers](https://arxiv.org/abs/2602.03210)
*Zhiwen Li,Zhongjie Duan,Jinyan Ye,Cen Chen,Daoyuan Chen,Yaliang Li,Yingda Chen*

Main category: cs.CV

TL;DR: VIRAL是一个通过视觉类比实现视觉上下文学习的框架，利用预训练图像编辑模型进行多任务视觉推理，采用角色感知多图像条件和专家混合LoRA来适应异构任务。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉中的上下文学习(ICL)由于任务异质性而面临挑战，需要统一的视觉推理框架来处理感知、恢复和编辑等多样化任务。

Method: 将ICL重新表述为条件生成问题(x_s:x_t::x_q:y_q)，使用冻结的Diffusion Transformer(DiT)进行角色感知多图像条件处理，并引入Mixture-of-Experts LoRA来减少梯度干扰。

Result: 实验表明VIRAL在多个视觉任务上优于现有方法，能够处理包括开放域编辑在内的大多数视觉任务。

Conclusion: VIRAL验证了统一的视觉ICL范式可以有效处理视觉任务异质性，为多任务视觉推理提供了有效解决方案。

Abstract: Replicating In-Context Learning (ICL) in computer vision remains challenging due to task heterogeneity. We propose \textbf{VIRAL}, a framework that elicits visual reasoning from a pre-trained image editing model by formulating ICL as conditional generation via visual analogy ($x_s : x_t :: x_q : y_q$). We adapt a frozen Diffusion Transformer (DiT) using role-aware multi-image conditioning and introduce a Mixture-of-Experts LoRA to mitigate gradient interference across diverse tasks. Additionally, to bridge the gaps in current visual context datasets, we curate a large-scale dataset spanning perception, restoration, and editing. Experiments demonstrate that VIRAL outperforms existing methods, validating that a unified V-ICL paradigm can handle the majority of visual tasks, including open-domain editing. Our code is available at https://anonymous.4open.science/r/VIRAL-744A

</details>


### [45] [ConsisDrive: Identity-Preserving Driving World Models for Video Generation by Instance Mask](https://arxiv.org/abs/2602.03213)
*Zhuoran Yang,Yanyong Zhang*

Main category: cs.CV

TL;DR: ConsisDrive是一个身份保持的驾驶世界模型，通过实例级时间一致性约束解决身份漂移问题，在nuScenes数据集上实现了最先进的驾驶视频生成质量。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要大规模高质量多视角驾驶视频数据，但现有世界模型存在身份漂移问题，即同一对象在不同帧中出现外观或类别变化，缺乏实例级时间约束。

Method: 提出两个关键组件：1) 实例掩码注意力机制，在注意力块中应用实例身份掩码和轨迹掩码，确保视觉标记仅在空间和时间维度上与对应实例特征交互；2) 实例掩码损失函数，通过概率实例掩码自适应强调前景区域，减少背景噪声同时保持场景保真度。

Result: 在nuScenes数据集上实现了最先进的驾驶视频生成质量，并在下游自动驾驶任务中表现出显著改进。

Conclusion: ConsisDrive通过实例级时间一致性约束有效解决了身份漂移问题，为自动驾驶提供了高质量的数据生成解决方案。

Abstract: Autonomous driving relies on robust models trained on large-scale, high-quality multi-view driving videos. Although world models provide a cost-effective solution for generating realistic driving data, they often suffer from identity drift, where the same object changes its appearance or category across frames due to the absence of instance-level temporal constraints. We introduce ConsisDrive, an identity-preserving driving world model designed to enforce temporal consistency at the instance level. Our framework incorporates two key components: (1) Instance-Masked Attention, which applies instance identity masks and trajectory masks within attention blocks to ensure that visual tokens interact only with their corresponding instance features across spatial and temporal dimensions, thereby preserving object identity consistency; and (2) Instance-Masked Loss, which adaptively emphasizes foreground regions with probabilistic instance masking, reducing background noise while maintaining overall scene fidelity. By integrating these mechanisms, ConsisDrive achieves state-of-the-art driving video generation quality and demonstrates significant improvements in downstream autonomous driving tasks on the nuScenes dataset. Our project page is https://shanpoyang654.github.io/ConsisDrive/page.html.

</details>


### [46] [FARTrack: Fast Autoregressive Visual Tracking with High Performance](https://arxiv.org/abs/2602.03214)
*Guijie Wang,Tong Lin,Yifan Bai,Anjia Cao,Shiyi Liang,Wangbo Zhao,Xing Wei*

Main category: cs.CV

TL;DR: FARTrack是一个快速自回归跟踪框架，通过任务特定自蒸馏和帧间自回归稀疏化技术，在保持高性能的同时实现高效推理速度，在GPU上可达343 FPS，CPU上121 FPS。


<details>
  <summary>Details</summary>
Motivation: 高性能跟踪器通常处理速度较慢，难以在资源受限设备上部署，需要解决推理速度与跟踪性能之间的平衡问题。

Method: 引入任务特定自蒸馏（分层蒸馏任务特定令牌）和帧间自回归稀疏化（顺序压缩多个模板），分别从浅层准确蒸馏和冗余到本质令牌优化角度设计。

Result: 在GOT-10k数据集上达到70.6%的AO分数，实时性能表现，最快模型在GPU上达到343 FPS，CPU上121 FPS。

Conclusion: FARTrack框架通过自回归方法和创新优化技术，成功实现了跟踪性能与推理速度的良好平衡，为资源受限设备的视觉跟踪部署提供了有效解决方案。

Abstract: Inference speed and tracking performance are two critical evaluation metrics in the field of visual tracking. However, high-performance trackers often suffer from slow processing speeds, making them impractical for deployment on resource-constrained devices. To alleviate this issue, we propose FARTrack, a Fast Auto-Regressive Tracking framework. Since autoregression emphasizes the temporal nature of the trajectory sequence, it can maintain high performance while achieving efficient execution across various devices. FARTrack introduces Task-Specific Self-Distillation and Inter-frame Autoregressive Sparsification, designed from the perspectives of shallow-yet-accurate distillation and redundant-to-essential token optimization, respectively. Task-Specific Self-Distillation achieves model compression by distilling task-specific tokens layer by layer, enhancing the model's inference speed while avoiding suboptimal manual teacher-student layer pairs assignments. Meanwhile, Inter-frame Autoregressive Sparsification sequentially condenses multiple templates, avoiding additional runtime overhead while learning a temporally-global optimal sparsification strategy. FARTrack demonstrates outstanding speed and competitive performance. It delivers an AO of 70.6% on GOT-10k in real-time. Beyond, our fastest model achieves a speed of 343 FPS on the GPU and 121 FPS on the CPU.

</details>


### [47] [PokeFusion Attention: Enhancing Reference-Free Style-Conditioned Generation](https://arxiv.org/abs/2602.03220)
*Jingbang Tang*

Main category: cs.CV

TL;DR: PokeFusion Attention：一种轻量级解码器级交叉注意力机制，通过解耦文本和样式条件，实现无参考的样式化角色生成，保持预训练扩散主干冻结，参数高效且即插即用。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖纯文本提示（视觉样式表达不足，容易产生样式漂移和几何不一致）或基于参考的适配器（需要推理时外部图像，增加架构复杂性和限制部署灵活性），需要更好的无参考样式化生成方案。

Method: 提出PokeFusion Attention机制，在扩散解码器内部直接将文本语义与学习到的样式嵌入融合。仅训练解码器交叉注意力层和紧凑样式投影模块，保持预训练扩散主干完全冻结。

Result: 在样式化角色生成基准（Pokemon风格）上的实验表明，相比代表性基于适配器的基线方法，本方法在样式保真度、语义对齐和角色形状一致性方面持续改进，同时保持低参数开销和推理时简单性。

Conclusion: PokeFusion Attention提供了一种参数高效、即插即用的控制组件，可轻松集成到现有扩散管道中并在不同主干网络间迁移，实现了有效的无参考样式化生成。

Abstract: This paper studies reference-free style-conditioned character generation in text-to-image diffusion models, where high-quality synthesis requires both stable character structure and consistent, fine-grained style expression across diverse prompts. Existing approaches primarily rely on text-only prompting, which is often under-specified for visual style and tends to produce noticeable style drift and geometric inconsistency, or introduce reference-based adapters that depend on external images at inference time, increasing architectural complexity and limiting deployment flexibility.We propose PokeFusion Attention, a lightweight decoder-level cross-attention mechanism that fuses textual semantics with learned style embeddings directly inside the diffusion decoder. By decoupling text and style conditioning at the attention level, our method enables effective reference-free stylized generation while keeping the pretrained diffusion backbone fully frozen.PokeFusion Attention trains only decoder cross-attention layers together with a compact style projection module, resulting in a parameter-efficient and plug-and-play control component that can be easily integrated into existing diffusion pipelines and transferred across different backbones.Experiments on a stylized character generation benchmark (Pokemon-style) demonstrate that our method consistently improves style fidelity, semantic alignment, and character shape consistency compared with representative adapter-based baselines, while maintaining low parameter overhead and inference-time simplicity.

</details>


### [48] [Spiral RoPE: Rotate Your Rotary Positional Embeddings in the 2D Plane](https://arxiv.org/abs/2602.03227)
*Haoyu Liu,Sucheng Ren,Tingyu Zhu,Peng Wang,Cihang Xie,Alan Yuille,Zeyu Zheng,Feng Wang*

Main category: cs.CV

TL;DR: Spiral RoPE：一种多方向位置编码方法，通过将嵌入通道分组并沿不同方向旋转，克服了标准轴向2D RoPE只能编码轴对齐方向位置信息的限制，在视觉任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 标准轴向2D RoPE在视觉Transformer中存在方向性约束，只能编码水平垂直方向的位置关系，无法有效建模自然图像中普遍存在的斜向空间关系，这限制了模型性能。

Method: 提出Spiral RoPE方法，将嵌入通道划分为多个与均匀分布方向相关联的组，每个组根据图像块位置在其对应方向上的投影进行旋转，实现多方向位置编码。

Result: 在分类、分割和生成等多种视觉任务上，Spiral RoPE均能持续提升性能。注意力图分析显示该方法能更集中地激活语义相关对象并更好地保持局部对象边界。

Conclusion: 多方向位置编码对视觉Transformer至关重要，Spiral RoPE通过简单有效的扩展解决了标准轴向2D RoPE的方向限制问题，为视觉任务提供了更好的位置建模能力。

Abstract: Rotary Position Embedding (RoPE) is the de facto positional encoding in large language models due to its ability to encode relative positions and support length extrapolation. When adapted to vision transformers, the standard axial formulation decomposes two-dimensional spatial positions into horizontal and vertical components, implicitly restricting positional encoding to axis-aligned directions. We identify this directional constraint as a fundamental limitation of the standard axial 2D RoPE, which hinders the modeling of oblique spatial relationships that naturally exist in natural images. To overcome this limitation, we propose Spiral RoPE, a simple yet effective extension that enables multi-directional positional encoding by partitioning embedding channels into multiple groups associated with uniformly distributed directions. Each group is rotated according to the projection of the patch position onto its corresponding direction, allowing spatial relationships to be encoded beyond the horizontal and vertical axes. Across a wide range of vision tasks including classification, segmentation, and generation, Spiral RoPE consistently improves performance. Qualitative analysis of attention maps further show that Spiral RoPE exhibits more concentrated activations on semantically relevant objects and better respects local object boundaries, highlighting the importance of multi-directional positional encoding in vision transformers.

</details>


### [49] [EventFlash: Towards Efficient MLLMs for Event-Based Vision](https://arxiv.org/abs/2602.03230)
*Shaoyu Liu,Jianing Li,Guanghui Zhao,Yunjian Zhang,Wen Jiang,Ming Li,Xiangyang Ji*

Main category: cs.CV

TL;DR: EventFlash是一个基于事件的高效多模态大语言模型，通过时空令牌稀疏化技术减少数据冗余并加速推理，相比基线模型实现了12.4倍的吞吐量提升，同时支持长达1000个时间窗口的事件流处理。


<details>
  <summary>Details</summary>
Motivation: 当前基于事件的MLLM通常采用密集的图像式处理范式，忽略了事件流的时空稀疏性，导致计算成本高昂。需要开发能够充分利用事件数据稀疏特性的高效模型。

Method: 1) 构建大规模多样化数据集EventMind（50万条指令集）；2) 自适应时间窗口聚合模块进行高效时间采样；3) 稀疏密度引导注意力模块选择信息丰富区域并抑制稀疏区域；4) 采用课程训练策略。

Result: EventFlash实现了12.4倍的吞吐量提升，在保持可比性能的同时支持1000个时间窗口的长距离事件流处理，显著超越EventGPT的5个时间窗口限制。

Conclusion: EventFlash作为基于事件视觉的高效基础模型，成功解决了事件数据处理的效率问题，为高速和低光场景下的鲁棒感知提供了有效解决方案。

Abstract: Event-based multimodal large language models (MLLMs) enable robust perception in high-speed and low-light scenarios, addressing key limitations of frame-based MLLMs. However, current event-based MLLMs often rely on dense image-like processing paradigms, overlooking the spatiotemporal sparsity of event streams and resulting in high computational cost. In this paper, we propose EventFlash, a novel and efficient MLLM to explore spatiotemporal token sparsification for reducing data redundancy and accelerating inference. Technically, we build EventMind, a large-scale and scene-diverse dataset with over 500k instruction sets, providing both short and long event stream sequences to support our curriculum training strategy. We then present an adaptive temporal window aggregation module for efficient temporal sampling, which adaptively compresses temporal tokens while retaining key temporal cues. Finally, a sparse density-guided attention module is designed to improve spatial token efficiency by selecting informative regions and suppressing empty or sparse areas. Experimental results show that EventFlash achieves a $12.4\times$ throughput improvement over the baseline (EventFlash-Zero) while maintaining comparable performance. It supports long-range event stream processing with up to 1,000 bins, significantly outperforming the 5-bin limit of EventGPT. We believe EventFlash serves as an efficient foundation model for event-based vision.

</details>


### [50] [InstaDrive: Instance-Aware Driving World Models for Realistic and Consistent Video Generation](https://arxiv.org/abs/2602.03242)
*Zhuoran Yang,Xi Guo,Chenjing Ding,Chiyu Wang,Wei Wu,Yanyong Zhang*

Main category: cs.CV

TL;DR: InstaDrive是一个增强自动驾驶视频生成的框架，通过实例流引导器和空间几何对齐器解决世界模型在时间一致性和空间几何保真度方面的不足，在nuScenes数据集上达到最先进性能，并利用CARLA模拟器进行安全关键场景评估。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶需要高质量的大规模多视角驾驶视频，但现有世界模型在保持实例级时间一致性和空间几何保真度方面存在困难。

Method: 提出InstaDrive框架，包含两个核心组件：(1)实例流引导器 - 提取并传播实例特征以保持时间一致性；(2)空间几何对齐器 - 改进空间推理，确保精确实例定位并显式建模遮挡层次结构。

Result: 在nuScenes数据集上实现了最先进的视频生成质量，并提升了下游自动驾驶任务的性能。使用CARLA自动驾驶系统程序化地模拟了多样化的安全关键驾驶场景。

Conclusion: InstaDrive通过实例感知机制显著提高了驾驶视频的真实感，为自动驾驶系统提供了更可靠的训练数据和安全性评估框架。

Abstract: Autonomous driving relies on robust models trained on high-quality, large-scale multi-view driving videos. While world models offer a cost-effective solution for generating realistic driving videos, they struggle to maintain instance-level temporal consistency and spatial geometric fidelity. To address these challenges, we propose InstaDrive, a novel framework that enhances driving video realism through two key advancements: (1) Instance Flow Guider, which extracts and propagates instance features across frames to enforce temporal consistency, preserving instance identity over time. (2) Spatial Geometric Aligner, which improves spatial reasoning, ensures precise instance positioning, and explicitly models occlusion hierarchies. By incorporating these instance-aware mechanisms, InstaDrive achieves state-of-the-art video generation quality and enhances downstream autonomous driving tasks on the nuScenes dataset. Additionally, we utilize CARLA's autopilot to procedurally and stochastically simulate rare but safety-critical driving scenarios across diverse maps and regions, enabling rigorous safety evaluation for autonomous systems. Our project page is https://shanpoyang654.github.io/InstaDrive/page.html.

</details>


### [51] [LaVPR: Benchmarking Language and Vision for Place Recognition](https://arxiv.org/abs/2602.03253)
*Ofer Idan,Dan Badur,Yosi Keller,Yoli Shavit*

Main category: cs.CV

TL;DR: LaVPR是一个大规模视觉地点识别基准，通过添加65万+自然语言描述扩展现有VPR数据集，研究多模态融合和跨模态检索两种范式，显著提升在视觉退化条件下的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决视觉地点识别在极端环境变化和感知混淆下的失效问题，以及标准系统无法仅从语言描述进行"盲定位"的局限性，特别是应急响应等应用场景的需求。

Method: 建立LaVPR大规模数据集，研究多模态融合增强鲁棒性，以及使用LoRA（低秩适应）和Multi-Similarity损失的跨模态检索方法。

Result: 语言描述在视觉退化条件下带来一致性能提升，小型骨干网络受益最大，紧凑模型可媲美大型纯视觉架构。跨模态检索基准显著优于标准对比方法。

Conclusion: LaVPR实现了对现实世界随机性更具韧性且适用于资源受限部署的新一代定位系统，为语言驱动的视觉定位开辟了新途径。

Abstract: Visual Place Recognition (VPR) often fails under extreme environmental changes and perceptual aliasing. Furthermore, standard systems cannot perform "blind" localization from verbal descriptions alone, a capability needed for applications such as emergency response. To address these challenges, we introduce LaVPR, a large-scale benchmark that extends existing VPR datasets with over 650,000 rich natural-language descriptions. Using LaVPR, we investigate two paradigms: Multi-Modal Fusion for enhanced robustness and Cross-Modal Retrieval for language-based localization. Our results show that language descriptions yield consistent gains in visually degraded conditions, with the most significant impact on smaller backbones. Notably, adding language allows compact models to rival the performance of much larger vision-only architectures. For cross-modal retrieval, we establish a baseline using Low-Rank Adaptation (LoRA) and Multi-Similarity loss, which substantially outperforms standard contrastive methods across vision-language models. Ultimately, LaVPR enables a new class of localization systems that are both resilient to real-world stochasticity and practical for resource-constrained deployment. Our dataset and code are available at https://github.com/oferidan1/LaVPR.

</details>


### [52] [HypCBC: Domain-Invariant Hyperbolic Cross-Branch Consistency for Generalizable Medical Image Analysis](https://arxiv.org/abs/2602.03264)
*Francesco Di Salvo,Sebastian Doerrich,Jonas Alle,Christian Ledig*

Main category: cs.CV

TL;DR: 本文提出了一种基于双曲流形的表示学习方法，通过无监督的域不变双曲交叉分支一致性约束，在医学图像分析中实现了超越欧几里得方法的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在训练分布之外的泛化能力不足是医学图像分析中的关键挑战，主要源于数据稀缺、硬件设备差异、成像协议不同和患者群体异质性导致的协变量偏移。现有方法主要基于欧几里得流形，其平坦几何无法有效捕捉临床数据中的复杂层次结构。

Method: 利用双曲流形建模复杂数据特征，提出无监督的域不变双曲交叉分支一致性约束方法，在三个ViT模型上进行验证。

Result: 在11个分布内数据集上获得统计学显著增益，在三个域泛化基准测试（Fitzpatrick17k、Camelyon17-WILDS和视网膜成像跨数据集设置）上平均AUC提升+2.1%，超越最先进的欧几里得方法。

Conclusion: 双曲表示学习能够有效提升医学图像分析的域泛化能力，该方法在不同成像模态、数据规模和标签粒度条件下均表现出良好的泛化性能。

Abstract: Robust generalization beyond training distributions remains a critical challenge for deep neural networks. This is especially pronounced in medical image analysis, where data is often scarce and covariate shifts arise from different hardware devices, imaging protocols, and heterogeneous patient populations. These factors collectively hinder reliable performance and slow down clinical adoption. Despite recent progress, existing learning paradigms primarily rely on the Euclidean manifold, whose flat geometry fails to capture the complex, hierarchical structures present in clinical data. In this work, we exploit the advantages of hyperbolic manifolds to model complex data characteristics. We present the first comprehensive validation of hyperbolic representation learning for medical image analysis and demonstrate statistically significant gains across eleven in-distribution datasets and three ViT models. We further propose an unsupervised, domain-invariant hyperbolic cross-branch consistency constraint. Extensive experiments confirm that our proposed method promotes domain-invariant features and outperforms state-of-the-art Euclidean methods by an average of $+2.1\%$ AUC on three domain generalization benchmarks: Fitzpatrick17k, Camelyon17-WILDS, and a cross-dataset setup for retinal imaging. These datasets span different imaging modalities, data sizes, and label granularities, confirming generalization capabilities across substantially different conditions. The code is available at https://github.com/francescodisalvo05/hyperbolic-cross-branch-consistency .

</details>


### [53] [Global Geometry Is Not Enough for Vision Representations](https://arxiv.org/abs/2602.03282)
*Jiwan Chung,Seon Joo Kim*

Main category: cs.CV

TL;DR: 该研究发现全局几何指标与组合绑定能力相关性接近零，而功能敏感性（通过输入-输出雅可比矩阵测量）能可靠追踪此能力，表明全局嵌入几何仅捕获表征能力的部分视图。


<details>
  <summary>Details</summary>
Motivation: 研究全局几何作为表征能力代理的局限性，特别是其对元素组合方式的不敏感性，需要探索更全面的评估指标。

Method: 测试21个视觉编码器中几何指标预测组合绑定能力的效果，比较标准几何统计量与功能敏感性（输入-输出雅可比矩阵）的相关性。

Result: 标准几何统计量与组合绑定能力相关性接近零，而功能敏感性与此能力高度相关；分析表明现有损失函数明确约束嵌入几何但未约束局部输入-输出映射。

Conclusion: 全局嵌入几何仅提供表征能力的部分视角，功能敏感性是建模复合结构的关键补充维度，需要重新考虑训练目标和评估协议。

Abstract: A common assumption in representation learning is that globally well-distributed embeddings support robust and generalizable representations. This focus has shaped both training objectives and evaluation protocols, implicitly treating global geometry as a proxy for representational competence. While global geometry effectively encodes which elements are present, it is often insensitive to how they are composed. We investigate this limitation by testing the ability of geometric metrics to predict compositional binding across 21 vision encoders. We find that standard geometry-based statistics exhibit near-zero correlation with compositional binding. In contrast, functional sensitivity, as measured by the input-output Jacobian, reliably tracks this capability. We further provide an analytic account showing that this disparity arises from objective design, as existing losses explicitly constrain embedding geometry but leave the local input-output mapping unconstrained. These results suggest that global embedding geometry captures only a partial view of representational competence and establish functional sensitivity as a critical complementary axis for modeling composite structure.

</details>


### [54] [A3-TTA: Adaptive Anchor Alignment Test-Time Adaptation for Image Segmentation](https://arxiv.org/abs/2602.03292)
*Jianghao Wu,Xiangde Luo,Yubo Zhou,Lianming Wu,Guotai Wang,Shaoting Zhang*

Main category: cs.CV

TL;DR: A3-TTA是一个测试时自适应框架，通过锚点引导监督构建可靠的伪标签，解决传统基于伪标签方法的不稳定训练信号问题，在医学图像和自然图像分割中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于伪标签的测试时自适应方法依赖扰动集成启发式方法，缺乏分布基础，导致训练信号不稳定，容易引发错误累积和灾难性遗忘。

Method: 使用类紧凑密度度量识别预测良好的目标域图像作为锚点，通过语义一致性和边界感知熵最小化正则化伪标签生成，并采用自适应指数移动平均策略减轻标签噪声。

Result: 在多域医学图像和自然图像分割中，A3-TTA相比源模型将平均Dice分数提高了10.40到17.68个百分点，优于多种最先进的TTA方法，并在连续TTA中表现出色。

Conclusion: A3-TTA通过锚点引导监督有效解决了伪标签不稳定的问题，显著提升了域适应性能，具有强大的抗遗忘能力，适用于不同分割模型架构。

Abstract: Test-Time Adaptation (TTA) offers a practical solution for deploying image segmentation models under domain shift without accessing source data or retraining. Among existing TTA strategies, pseudo-label-based methods have shown promising performance. However, they often rely on perturbation-ensemble heuristics (e.g., dropout sampling, test-time augmentation, Gaussian noise), which lack distributional grounding and yield unstable training signals. This can trigger error accumulation and catastrophic forgetting during adaptation. To address this, we propose \textbf{A3-TTA}, a TTA framework that constructs reliable pseudo-labels through anchor-guided supervision. Specifically, we identify well-predicted target domain images using a class compact density metric, under the assumption that confident predictions imply distributional proximity to the source domain. These anchors serve as stable references to guide pseudo-label generation, which is further regularized via semantic consistency and boundary-aware entropy minimization. Additionally, we introduce a self-adaptive exponential moving average strategy to mitigate label noise and stabilize model update during adaptation. Evaluated on both multi-domain medical images (heart structure and prostate segmentation) and natural images, A3-TTA significantly improves average Dice scores by 10.40 to 17.68 percentage points compared to the source model, outperforming several state-of-the-art TTA methods under different segmentation model architectures. A3-TTA also excels in continual TTA, maintaining high performance across sequential target domains with strong anti-forgetting ability. The code will be made publicly available at https://github.com/HiLab-git/A3-TTA.

</details>


### [55] [LEVIO: Lightweight Embedded Visual Inertial Odometry for Resource-Constrained Devices](https://arxiv.org/abs/2602.03294)
*Jonas Kühne,Christian Vogt,Michele Magno,Luca Benini*

Main category: cs.CV

TL;DR: LEVIO是一个专为超低功耗计算平台优化的视觉-惯性里程计(VIO)系统，可在资源受限硬件上实现6自由度实时运动追踪，达到20 FPS的同时功耗低于100 mW。


<details>
  <summary>Details</summary>
Motivation: 现有最先进的VIO系统计算需求过高，无法在微无人机和智能眼镜等资源受限硬件上有效运行，需要开发计算效率更高的解决方案。

Method: 采用ORB特征跟踪和束调整等成熟VIO组件，通过并行化和低内存使用的计算高效架构设计，结合硬件-软件协同优化方法。

Result: 在超低功耗RISC-V SoC上验证，实现20 FPS实时性能，功耗低于100 mW，在公开VIO数据集上表现出效率与精度的良好平衡。

Conclusion: LEVIO为移动机器人和增强现实应用提供了可行的基础设施无关传感解决方案，通过开源发布促进可重复性和采用。

Abstract: Accurate, infrastructure-less sensor systems for motion tracking are essential for mobile robotics and augmented reality (AR) applications. The most popular state-of-the-art visual-inertial odometry (VIO) systems, however, are too computationally demanding for resource-constrained hardware, such as micro-drones and smart glasses. This work presents LEVIO, a fully featured VIO pipeline optimized for ultra-low-power compute platforms, allowing six-degrees-of-freedom (DoF) real-time sensing. LEVIO incorporates established VIO components such as Oriented FAST and Rotated BRIEF (ORB) feature tracking and bundle adjustment, while emphasizing a computationally efficient architecture with parallelization and low memory usage to suit embedded microcontrollers and low-power systems-on-chip (SoCs). The paper proposes and details the algorithmic design choices and the hardware-software co-optimization approach, and presents real-time performance on resource-constrained hardware. LEVIO is validated on a parallel-processing ultra-low-power RISC-V SoC, achieving 20 FPS while consuming less than 100 mW, and benchmarked against public VIO datasets, offering a compelling balance between efficiency and accuracy. To facilitate reproducibility and adoption, the complete implementation is released as open-source.

</details>


### [56] [Full end-to-end diagnostic workflow automation of 3D OCT via foundation model-driven AI for retinal diseases](https://arxiv.org/abs/2602.03302)
*Jinze Zhang,Jian Zhong,Li Lin,Jiaxiong Li,Ke Ma,Naiyang Li,Meng Li,Yuan Pan,Zeyu Meng,Mengyun Zhou,Shang Huang,Shilong Yu,Zhengyu Duan,Sutong Li,Honghui Xia,Juping Liu,Dan Liang,Yantao Wei,Xiaoying Tang,Jin Yuan,Peng Xiao*

Main category: cs.CV

TL;DR: FOCUS是一个基于基础模型的端到端3D OCT视网膜疾病诊断自动化框架，通过图像质量评估、异常检测和多疾病分类的统一流程，实现了从图像到诊断的完整自动化，在多个中心和设备上验证表现出色。


<details>
  <summary>Details</summary>
Motivation: 光学相干断层扫描（OCT）在视网膜疾病诊断中具有高分辨率三维成像优势，但其在临床实践中的全自动化诊断仍受限于多阶段工作流程和传统的单切片单任务AI模型。

Method: FOCUS采用EfficientNetV2-S进行图像质量评估，使用微调的视觉基础模型进行异常检测和多疾病分类，并通过统一的自适应聚合方法将2D切片级预测整合为全面的3D患者级诊断。

Result: 在3,300名患者（40,672个切片）上训练测试，并在4个不同级别中心的1,345名患者（18,498个切片）上进行外部验证，FOCUS在质量评估（99.01%）、异常检测（97.46%）和患者级诊断（94.39%）方面获得高F1分数。人机对比显示FOCUS在异常检测（95.47% vs 90.91%）和多疾病诊断（93.49% vs 91.35%）方面与专家表现相当且效率更高。

Conclusion: FOCUS实现了从图像到诊断的完整自动化流程，代表了无人眼科医学的关键进展，为增强人群规模视网膜护理的可及性和效率提供了经过验证的自主筛查蓝图。

Abstract: Optical coherence tomography (OCT) has revolutionized retinal disease diagnosis with its high-resolution and three-dimensional imaging nature, yet its full diagnostic automation in clinical practices remains constrained by multi-stage workflows and conventional single-slice single-task AI models. We present Full-process OCT-based Clinical Utility System (FOCUS), a foundation model-driven framework enabling end-to-end automation of 3D OCT retinal disease diagnosis. FOCUS sequentially performs image quality assessment with EfficientNetV2-S, followed by abnormality detection and multi-disease classification using a fine-tuned Vision Foundation Model. Crucially, FOCUS leverages a unified adaptive aggregation method to intelligently integrate 2D slices-level predictions into comprehensive 3D patient-level diagnosis. Trained and tested on 3,300 patients (40,672 slices), and externally validated on 1,345 patients (18,498 slices) across four different-tier centers and diverse OCT devices, FOCUS achieved high F1 scores for quality assessment (99.01%), abnormally detection (97.46%), and patient-level diagnosis (94.39%). Real-world validation across centers also showed stable performance (F1: 90.22%-95.24%). In human-machine comparisons, FOCUS matched expert performance in abnormality detection (F1: 95.47% vs 90.91%) and multi-disease diagnosis (F1: 93.49% vs 91.35%), while demonstrating better efficiency. FOCUS automates the image-to-diagnosis pipeline, representing a critical advance towards unmanned ophthalmology with a validated blueprint for autonomous screening to enhance population scale retinal care accessibility and efficiency.

</details>


### [57] [PQTNet: Pixel-wise Quantitative Thermography Neural Network for Estimating Defect Depth in Polylactic Acid Parts by Additive Manufacturing](https://arxiv.org/abs/2602.03314)
*Lei Deng,Wenhao Huang,Chao Yang,Haoyuan Zheng,Yinbin Tian,Yue Ma*

Main category: cs.CV

TL;DR: 提出了PQT-Net神经网络方法，通过创新的数据增强策略和残差回归头，实现增材制造PLA部件缺陷深度的精确量化，MAE低至0.0094mm，R²超过99%


<details>
  <summary>Details</summary>
Motivation: 增材制造部件的缺陷深度量化是非破坏性测试中的重大挑战，现有方法难以精确测量缺陷深度

Method: 使用像素级定量热成像神经网络(PQT-Net)，包含预训练的EfficientNetV2-S主干网络和自定义残差回归头(RRH)，采用将热序列数据重构为二维条纹图像的新数据增强策略

Result: 在比较实验中表现优于其他深度学习模型，达到最小平均绝对误差0.0094mm，决定系数超过99%

Conclusion: PQT-Net在增材制造定量缺陷表征方面具有强大潜力，为AM组件的稳健缺陷量化提供了高精度解决方案

Abstract: Defect depth quantification in additively manufactured (AM) components remains a significant challenge for non-destructive testing (NDT). This study proposes a Pixel-wise Quantitative Thermography Neural Network (PQT-Net) to address this challenge for polylactic acid (PLA) parts. A key innovation is a novel data augmentation strategy that reconstructs thermal sequence data into two-dimensional stripe images, preserving the complete temporal evolution of heat diffusion for each pixel. The PQT-Net architecture incorporates a pre-trained EfficientNetV2-S backbone and a custom Residual Regression Head (RRH) with learnable parameters to refine outputs. Comparative experiments demonstrate the superiority of PQT-Net over other deep learning models, achieving a minimum Mean Absolute Error (MAE) of 0.0094 mm and a coefficient of determination (R) exceeding 99%. The high precision of PQT-Net underscores its potential for robust quantitative defect characterization in AM.

</details>


### [58] [Invisible Clean-Label Backdoor Attacks for Generative Data Augmentation](https://arxiv.org/abs/2602.03316)
*Ting Xiang,Jinhui Zhao,Changjian Chen,Zhuo Tang*

Main category: cs.CV

TL;DR: 提出InvLBA方法，通过潜在空间扰动实现生成式数据增强中的隐形干净标签后门攻击，显著提高攻击成功率而不影响正常精度


<details>
  <summary>Details</summary>
Motivation: 现有像素级干净标签后门攻击方法在生成图像上攻击成功率低，需要转向潜在特征层面的攻击方法

Method: 基于潜在扰动的隐形干净标签后门攻击方法InvLBA，通过理论证明保证泛化性能

Result: 在多个数据集上平均提高攻击成功率46.43%，几乎不影响清洁精度，对先进防御方法具有高鲁棒性

Conclusion: InvLBA方法在生成式数据增强场景下有效实现了高成功率的隐形后门攻击，为生成模型安全性提供了重要洞见

Abstract: With the rapid advancement of image generative models, generative data augmentation has become an effective way to enrich training images, especially when only small-scale datasets are available. At the same time, in practical applications, generative data augmentation can be vulnerable to clean-label backdoor attacks, which aim to bypass human inspection. However, based on theoretical analysis and preliminary experiments, we observe that directly applying existing pixel-level clean-label backdoor attack methods (e.g., COMBAT) to generated images results in low attack success rates. This motivates us to move beyond pixel-level triggers and focus instead on the latent feature level. To this end, we propose InvLBA, an invisible clean-label backdoor attack method for generative data augmentation by latent perturbation. We theoretically prove that the generalization of the clean accuracy and attack success rates of InvLBA can be guaranteed. Experiments on multiple datasets show that our method improves the attack success rate by 46.43% on average, with almost no reduction in clean accuracy and high robustness against SOTA defense methods.

</details>


### [59] [MedSAM-Agent: Empowering Interactive Medical Image Segmentation with Multi-turn Agentic Reinforcement Learning](https://arxiv.org/abs/2602.03320)
*Shengyuan Liu,Liuxin Bao,Qi Yang,Wanting Geng,Boyun Zheng,Chenxin Li,Wenting Chen,Houwen Peng,Yixuan Yuan*

Main category: cs.CV

TL;DR: MedSAM-Agent是一个多步骤自主决策框架，通过混合提示策略和两阶段训练管道，将医学图像分割重新定义为交互式多轮优化过程，在6种医学模态和21个数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割方法主要依赖单轮刚性交互策略，缺乏过程级监督训练，无法充分利用交互式工具的动态潜力，导致冗余操作。需要开发能够进行多轮自适应优化的自主决策框架。

Method: 提出混合提示策略用于专家轨迹生成，使模型能够内化类人决策启发式和自适应优化策略；开发两阶段训练管道，整合多轮端到端结果验证和临床保真度过程奖励设计，促进交互简洁性和决策效率。

Result: 在6种医学模态和21个数据集上的广泛实验表明，MedSAM-Agent实现了最先进的性能，有效统一了自主医学推理与鲁棒的迭代优化。

Conclusion: MedSAM-Agent成功将医学图像分割重新定义为多步骤自主决策过程，通过创新的混合提示策略和两阶段训练方法，显著提升了交互式分割的性能和效率，为通用化医学图像分析框架的发展提供了新方向。

Abstract: Medical image segmentation is evolving from task-specific models toward generalizable frameworks. Recent research leverages Multi-modal Large Language Models (MLLMs) as autonomous agents, employing reinforcement learning with verifiable reward (RLVR) to orchestrate specialized tools like the Segment Anything Model (SAM). However, these approaches often rely on single-turn, rigid interaction strategies and lack process-level supervision during training, which hinders their ability to fully exploit the dynamic potential of interactive tools and leads to redundant actions. To bridge this gap, we propose MedSAM-Agent, a framework that reformulates interactive segmentation as a multi-step autonomous decision-making process. First, we introduce a hybrid prompting strategy for expert-curated trajectory generation, enabling the model to internalize human-like decision heuristics and adaptive refinement strategies. Furthermore, we develop a two-stage training pipeline that integrates multi-turn, end-to-end outcome verification with a clinical-fidelity process reward design to promote interaction parsimony and decision efficiency. Extensive experiments across 6 medical modalities and 21 datasets demonstrate that MedSAM-Agent achieves state-of-the-art performance, effectively unifying autonomous medical reasoning with robust, iterative optimization. Code is available \href{https://github.com/CUHK-AIM-Group/MedSAM-Agent}{here}.

</details>


### [60] [PWAVEP: Purifying Imperceptible Adversarial Perturbations in 3D Point Clouds via Spectral Graph Wavelets](https://arxiv.org/abs/2602.03333)
*Haoran Li,Renyang Liu,Hongjia Liu,Chen Wang,Long Yin,Jian Xu*

Main category: cs.CV

TL;DR: PWAVEP是一个即插即用的非侵入式3D点云防御机制，通过在谱域分析对抗扰动与高频分量的关系，采用分层策略消除显著异常点并过滤中等显著点的高频噪声，实现高效的点云净化。


<details>
  <summary>Details</summary>
Motivation: 当前3D点云对抗攻击在空间不可感知性和高攻击性能方面取得进展，而现有防御方法需要侵入式模型修改、昂贵训练过程或辅助数据访问，亟需更简洁有效的防御方案。

Method: 提出基于谱图小波域显著性评分和局部稀疏性评分的分层净化框架：先消除最难恢复的显著对抗异常点，再对中等显著点应用谱滤波过程，通过图小波变换衰减目标点的高频系数来抑制对抗噪声。

Result: 大量评估表明PWAVEP在准确性和鲁棒性方面优于现有方法，推进了3D点云净化技术的最先进水平。

Conclusion: PWAVEP提供了一种理论支撑的、无需模型修改的即插即用防御方案，有效应对3D点云对抗攻击威胁，为点云安全防御提供了新思路。

Abstract: Recent progress in adversarial attacks on 3D point clouds, particularly in achieving spatial imperceptibility and high attack performance, presents significant challenges for defenders. Current defensive approaches remain cumbersome, often requiring invasive model modifications, expensive training procedures or auxiliary data access. To address these threats, in this paper, we propose a plug-and-play and non-invasive defense mechanism in the spectral domain, grounded in a theoretical and empirical analysis of the relationship between imperceptible perturbations and high-frequency spectral components. Building upon these insights, we introduce a novel purification framework, termed PWAVEP, which begins by computing a spectral graph wavelet domain saliency score and local sparsity score for each point. Guided by these values, PWAVEP adopts a hierarchical strategy, it eliminates the most salient points, which are identified as hardly recoverable adversarial outliers. Simultaneously, it applies a spectral filtering process to a broader set of moderately salient points. This process leverages a graph wavelet transform to attenuate high-frequency coefficients associated with the targeted points, thereby effectively suppressing adversarial noise. Extensive evaluations demonstrate that the proposed PWAVEP achieves superior accuracy and robustness compared to existing approaches, advancing the state-of-the-art in 3D point cloud purification. Code and datasets are available at https://github.com/a772316182/pwavep

</details>


### [61] [Composable Visual Tokenizers with Generator-Free Diagnostics of Learnability](https://arxiv.org/abs/2602.03339)
*Bingchen Zhao,Qiushan Guo,Ye Wang,Yixuan Huang,Zhonghua Zhai,Yu Tian*

Main category: cs.CV

TL;DR: CompTok是一个学习视觉分词器的训练框架，通过token条件化扩散解码器和InfoGAN式目标增强token的组合性，支持图像语义编辑和类别条件生成


<details>
  <summary>Details</summary>
Motivation: 现有视觉分词器缺乏组合性控制能力，无法通过token交换实现语义层面的图像编辑，需要开发能增强token组合性的训练框架

Method: 使用token条件化扩散解码器，采用InfoGAN式目标训练识别模型预测token，通过token子集交换训练增强组合性，使用对抗流正则化保持生成图像的自然分布

Result: 在图像类别条件生成任务上达到SOTA性能，支持通过token交换实现高级语义编辑，提出并改进了两个评估token空间景观的指标

Conclusion: CompTok成功增强了视觉token的组合性，为语义图像编辑和条件生成提供了有效框架，提出的指标有助于评估token空间特性

Abstract: We introduce CompTok, a training framework for learning visual tokenizers whose tokens are enhanced for compositionality. CompTok uses a token-conditioned diffusion decoder. By employing an InfoGAN-style objective, where we train a recognition model to predict the tokens used to condition the diffusion decoder using the decoded images, we enforce the decoder to not ignore any of the tokens. To promote compositional control, besides the original images, CompTok also trains on tokens formed by swapping token subsets between images, enabling more compositional control of the token over the decoder. As the swapped tokens between images do not have ground truth image targets, we apply a manifold constraint via an adversarial flow regularizer to keep unpaired swap generations on the natural-image distribution. The resulting tokenizer not only achieves state-of-the-art performance on image class-conditioned generation, but also demonstrates properties such as swapping tokens between images to achieve high level semantic editing of an image. Additionally, we propose two metrics that measures the landscape of the token space that can be useful to describe not only the compositionality of the tokens, but also how easy to learn the landscape is for a generator to be trained on this space. We show in experiments that CompTok can improve on both of the metrics as well as supporting state-of-the-art generators for class conditioned generation.

</details>


### [62] [Tiled Prompts: Overcoming Prompt Underspecification in Image and Video Super-Resolution](https://arxiv.org/abs/2602.03342)
*Bryan Sangwoo Kim,Jonghyun Park,Jong Chul Ye*

Main category: cs.CV

TL;DR: Tiled Prompts框架通过为每个潜在图块生成特定提示，解决了图像和视频超分辨率中全局提示导致的提示不足问题，提升了感知质量和文本对齐，减少了幻觉和块状伪影。


<details>
  <summary>Details</summary>
Motivation: 现代超分辨率管道依赖潜在图块划分来处理高分辨率，但单一全局提示会导致提示不足问题，包括局部细节缺失（提示稀疏性）和局部无关指导（提示误导），这些问题可能被无分类器引导放大。

Method: 提出Tiled Prompts统一框架，为每个潜在图块生成特定提示，在局部文本条件后验下执行超分辨率，提供高信息量指导以最小开销解决提示不足问题。

Result: 在高分辨率真实世界图像和视频上的实验显示，相比全局提示基线，该方法在感知质量和文本对齐方面获得一致提升，同时减少了幻觉和块级伪影。

Conclusion: Tiled Prompts框架有效解决了文本条件扩散模型在超分辨率任务中的提示不足问题，为高分辨率图像和视频处理提供了更精确的语义指导。

Abstract: Text-conditioned diffusion models have advanced image and video super-resolution by using prompts as semantic priors, but modern super-resolution pipelines typically rely on latent tiling to scale to high resolutions, where a single global caption causes prompt underspecification. A coarse global prompt often misses localized details (prompt sparsity) and provides locally irrelevant guidance (prompt misguidance) that can be amplified by classifier-free guidance. We propose Tiled Prompts, a unified framework for image and video super-resolution that generates a tile-specific prompt for each latent tile and performs super-resolution under locally text-conditioned posteriors, providing high-information guidance that resolves prompt underspecification with minimal overhead. Experiments on high resolution real-world images and videos show consistent gains in perceptual quality and text alignment, while reducing hallucinations and tile-level artifacts relative to global-prompt baselines.

</details>


### [63] [Z3D: Zero-Shot 3D Visual Grounding from Images](https://arxiv.org/abs/2602.03361)
*Nikita Drozdov,Andrey Lemeshko,Nikita Gavrilov,Anton Konushin,Danila Rukhovich,Maksim Kolodiazhnyi*

Main category: cs.CV

TL;DR: Z3D是一个基于多视角图像的零样本3D视觉定位方法，无需几何监督或物体先验，通过先进的3D实例分割和提示分割技术实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 探索仅使用多视角图像进行零样本3D视觉定位，避免对几何监督或物体先验的依赖，解决现有零样本方法的性能瓶颈问题。

Method: 提出Z3D通用管道：(1)使用最先进的零样本3D实例分割方法生成高质量3D边界框提案；(2)通过基于提示的分割利用现代视觉语言模型的完整能力进行高级推理；(3)可选择性地整合相机位姿和深度图。

Result: 在ScanRefer和Nr3D基准测试中实现了零样本方法中的最先进性能。

Conclusion: Z3D证明了仅使用多视角图像就能实现有效的零样本3D视觉定位，为无监督3D场景理解提供了新途径。

Abstract: 3D visual grounding (3DVG) aims to localize objects in a 3D scene based on natural language queries. In this work, we explore zero-shot 3DVG from multi-view images alone, without requiring any geometric supervision or object priors. We introduce Z3D, a universal grounding pipeline that flexibly operates on multi-view images while optionally incorporating camera poses and depth maps. We identify key bottlenecks in prior zero-shot methods causing significant performance degradation and address them with (i) a state-of-the-art zero-shot 3D instance segmentation method to generate high-quality 3D bounding box proposals and (ii) advanced reasoning via prompt-based segmentation, which utilizes full capabilities of modern VLMs. Extensive experiments on the ScanRefer and Nr3D benchmarks demonstrate that our approach achieves state-of-the-art performance among zero-shot methods. Code is available at https://github.com/col14m/z3d .

</details>


### [64] [Symbol-Aware Reasoning with Masked Discrete Diffusion for Handwritten Mathematical Expression Recognition](https://arxiv.org/abs/2602.03370)
*Takaya Kawakatsu,Ryo Ishiyama*

Main category: cs.CV

TL;DR: 提出基于离散扩散框架的手写数学表达式识别方法，通过迭代符号精炼替代自回归序列生成，解决了曝光偏差和句法不一致问题，在MathWriting和CROHME基准测试中取得最优性能


<details>
  <summary>Details</summary>
Motivation: 自回归模型在手写数学表达式识别中存在曝光偏差和句法结构不一致的问题，需要新的生成范式来更好地处理符号多样性和2D结构布局

Method: 采用离散扩散框架，通过多步重掩码迭代精炼符号和结构关系；引入符号感知标记化和随机掩码互学习机制增强句法对齐和对书写多样性的鲁棒性

Result: 在MathWriting基准测试中达到5.56%字符错误率和60.42%精确匹配率，超越强Transformer模型和商业基线；在CROHME 2014-2023数据集上持续获得提升

Conclusion: 离散扩散为结构感知视觉识别提供了超越传统生成建模的新范式，有效解决了自回归模型的结构一致性挑战

Abstract: Handwritten Mathematical Expression Recognition (HMER) requires reasoning over diverse symbols and 2D structural layouts, yet autoregressive models struggle with exposure bias and syntactic inconsistency. We present a discrete diffusion framework that reformulates HMER as iterative symbolic refinement instead of sequential generation. Through multi-step remasking, the proposal progressively refines both symbols and structural relations, removing causal dependencies and improving structural consistency. A symbol-aware tokenization and Random-Masking Mutual Learning further enhance syntactic alignment and robustness to handwriting diversity. On the MathWriting benchmark, the proposal achieves 5.56\% CER and 60.42\% EM, outperforming strong Transformer and commercial baselines. Consistent gains on CROHME 2014--2023 demonstrate that discrete diffusion provides a new paradigm for structure-aware visual recognition beyond generative modeling.

</details>


### [65] [Multi-Resolution Alignment for Voxel Sparsity in Camera-Based 3D Semantic Scene Completion](https://arxiv.org/abs/2602.03371)
*Zhiwen Yang,Yuxin Peng*

Main category: cs.CV

TL;DR: 提出多分辨率对齐(MRA)方法解决相机3D语义场景补全中的体素稀疏问题，通过场景级和实例级的多分辨率特征对齐作为辅助监督


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖体素标签监督，面临体素稀疏问题限制优化效率和模型性能

Method: 包含多分辨率视图变换器模块(场景级对齐)、立方语义各向异性模块(实例级语义显著性识别)、关键分布对齐模块(关键体素特征分布一致性监督)

Result: 通过多分辨率特征对齐缓解体素稀疏问题，提升3D语义场景补全性能

Conclusion: MRA方法有效解决了相机3D语义场景补全中的体素稀疏挑战，为自动驾驶系统提供了更精确的体素级场景感知基础

Abstract: Camera-based 3D semantic scene completion (SSC) offers a cost-effective solution for assessing the geometric occupancy and semantic labels of each voxel in the surrounding 3D scene with image inputs, providing a voxel-level scene perception foundation for the perception-prediction-planning autonomous driving systems. Although significant progress has been made in existing methods, their optimization rely solely on the supervision from voxel labels and face the challenge of voxel sparsity as a large portion of voxels in autonomous driving scenarios are empty, which limits both optimization efficiency and model performance. To address this issue, we propose a \textit{Multi-Resolution Alignment (MRA)} approach to mitigate voxel sparsity in camera-based 3D semantic scene completion, which exploits the scene and instance level alignment across multi-resolution 3D features as auxiliary supervision. Specifically, we first propose the Multi-resolution View Transformer module, which projects 2D image features into multi-resolution 3D features and aligns them at the scene level through fusing discriminative seed features. Furthermore, we design the Cubic Semantic Anisotropy module to identify the instance-level semantic significance of each voxel, accounting for the semantic differences of a specific voxel against its neighboring voxels within a cubic area. Finally, we devise a Critical Distribution Alignment module, which selects critical voxels as instance-level anchors with the guidance of cubic semantic anisotropy, and applies a circulated loss for auxiliary supervision on the critical feature distribution consistency across different resolutions. The code is available at https://github.com/PKU-ICST-MIPL/MRA_TIP.

</details>


### [66] [SLIM-Diff: Shared Latent Image-Mask Diffusion with Lp loss for Data-Scarce Epilepsy FLAIR MRI](https://arxiv.org/abs/2602.03372)
*Mario Pascual-González,Ariadna Jiménez-Partinen,R. M. Luque-Baena,Fátima Nagib-Raya,Ezequiel López-Rubio*

Main category: cs.CV

TL;DR: SLIM-Diff是一个紧凑的联合扩散模型，通过共享瓶颈U-Net架构和可调L_p损失函数，解决了癫痫FCD MRI图像-掩码联合生成中的不稳定性和记忆化问题。


<details>
  <summary>Details</summary>
Motivation: 癫痫FCD病变在FLAIR MRI中表现细微且稀少，导致传统联合图像-掩码生成模型容易不稳定和记忆化，需要更稳定的生成方法。

Method: 提出SLIM-Diff模型：(1)使用单共享瓶颈U-Net强制解剖结构和病变几何的紧密耦合；(2)通过可调L_p目标函数进行损失几何调优，比较了ε预测和x_0预测参数化方法。

Result: 实验表明x_0预测在联合合成中表现最稳定，L_{1.5}损失提高图像保真度，L_2损失更好地保持病变掩码形态。

Conclusion: SLIM-Diff通过紧凑的联合扩散建模和可调损失几何，有效解决了FCD MRI图像-掩码生成的稳定性问题，为医学图像合成提供了新思路。

Abstract: Focal cortical dysplasia (FCD) lesions in epilepsy FLAIR MRI are subtle and scarce, making joint image--mask generative modeling prone to instability and memorization. We propose SLIM-Diff, a compact joint diffusion model whose main contributions are (i) a single shared-bottleneck U-Net that enforces tight coupling between anatomy and lesion geometry from a 2-channel image+mask representation, and (ii) loss-geometry tuning via a tunable $L_p$ objective. As an internal baseline, we include the canonical DDPM-style objective ($ε$-prediction with $L_2$ loss) and isolate the effect of prediction parameterization and $L_p$ geometry under a matched setup. Experiments show that $x_0$-prediction is consistently the strongest choice for joint synthesis, and that fractional sub-quadratic penalties ($L_{1.5}$) improve image fidelity while $L_2$ better preserves lesion mask morphology. Our code and model weights are available in https://github.com/MarioPasc/slim-diff

</details>


### [67] [Unifying Watermarking via Dimension-Aware Mapping](https://arxiv.org/abs/2602.03373)
*Jiale Meng,Runyi Hu,Jie Zhang,Zheming Lu,Ivor Tsang,Tianwei Zhang*

Main category: cs.CV

TL;DR: DiM框架将数字水印建模为维度感知映射问题，统一了现有水印方法的功能行为，通过改变嵌入和提取维度配置即可实现不同的水印能力，无需架构修改。


<details>
  <summary>Details</summary>
Motivation: 现有深度水印方法虽然共享相似的编码器-解码器架构，但在功能行为上存在显著差异，需要统一的框架来理解这些差异的本质。

Method: 提出DiM多维水印框架，将水印信息建模为不同维度的载荷（一维二进制消息、二维空间掩码、三维时空结构），通过维度配置决定水印行为。在视频领域实例化该框架，探索时空表示支持的各种维度映射。

Result: 实验表明仅改变嵌入和提取维度即可实现不同的水印能力，包括时空篡改定位、局部嵌入控制和帧干扰下的时序恢复。

Conclusion: DiM框架从维度映射角度统一了水印方法的功能行为，维度配置是决定水印特性的关键因素，为水印系统设计提供了新的理论基础。

Abstract: Deep watermarking methods often share similar encoder-decoder architectures, yet differ substantially in their functional behaviors. We propose DiM, a new multi-dimensional watermarking framework that formulates watermarking as a dimension-aware mapping problem, thereby unifying existing watermarking methods at the functional level. Under DiM, watermark information is modeled as payloads of different dimensionalities, including one-dimensional binary messages, two-dimensional spatial masks, and three-dimensional spatiotemporal structures. We find that the dimensional configuration of embedding and extraction largely determines the resulting watermarking behavior. Same-dimensional mappings preserve payload structure and support fine-grained control, while cross-dimensional mappings enable spatial or spatiotemporal localization. We instantiate DiM in the video domain, where spatiotemporal representations enable a broader set of dimension mappings. Experiments demonstrate that varying only the embedding and extraction dimensions, without architectural changes, leads to different watermarking capabilities, including spatiotemporal tamper localization, local embedding control, and recovery of temporal order under frame disruptions.

</details>


### [68] [Seeing Through the Chain: Mitigate Hallucination in Multimodal Reasoning Models via CoT Compression and Contrastive Preference Optimization](https://arxiv.org/abs/2602.03380)
*Hao Fang,Jinyu Li,Jiawei Kong,Tianqu Zhuang,Kuofeng Gao,Bin Chen,Shu-Tao Xia,Yaowei Wang*

Main category: cs.CV

TL;DR: C3PO是一个基于训练的多模态推理模型幻觉缓解框架，通过思维链压缩和对比偏好优化来减少模型对语言先验的依赖并增强视觉输入利用。


<details>
  <summary>Details</summary>
Motivation: 多模态推理模型存在严重幻觉问题，研究发现引入推理机制会加剧模型依赖语言先验而忽视视觉输入，导致思维链中视觉线索减少而文本冗余增加。

Method: 1) 思维链压缩：选择性过滤冗余思维标记，获得更紧凑且信号效率高的CoT表示；2) 对比偏好优化：利用高质量AI反馈构建训练对，通过多模态幻觉诱导机制获取负信号进行对比校正。

Result: 在多种多模态推理模型和基准测试中实现了持续的幻觉减少，提供了理论证明其有效性。

Conclusion: C3PO框架通过压缩思维链和对比优化有效缓解了多模态推理模型的幻觉问题，为提升模型可靠性提供了实用解决方案。

Abstract: While multimodal reasoning models (MLRMs) have exhibited impressive capabilities, they remain prone to hallucinations, and effective solutions are still underexplored. In this paper, we experimentally analyze the hallucination cause and propose C3PO, a training-based mitigation framework comprising \textbf{C}hain-of-Thought \textbf{C}ompression and \textbf{C}ontrastive \textbf{P}reference \textbf{O}ptimization. Firstly, we identify that introducing reasoning mechanisms exacerbates models' reliance on language priors while overlooking visual inputs, which can produce CoTs with reduced visual cues but redundant text tokens. To this end, we propose to selectively filter redundant thinking tokens for a more compact and signal-efficient CoT representation that preserves task-relevant information while suppressing noise. In addition, we observe that the quality of the reasoning trace largely determines whether hallucination emerges in subsequent responses. To leverage this insight, we introduce a reasoning-enhanced preference tuning scheme that constructs training pairs using high-quality AI feedback. We further design a multimodal hallucination-inducing mechanism that elicits models' inherent hallucination patterns via carefully crafted inducers, yielding informative negative signals for contrastive correction. We provide theoretical justification for the effectiveness and demonstrate consistent hallucination reduction across diverse MLRMs and benchmarks.

</details>


### [69] [From Vicious to Virtuous Cycles: Synergistic Representation Learning for Unsupervised Video Object-Centric Learning](https://arxiv.org/abs/2602.03390)
*Hyun Seok Seong,WonJun Moon,Jae-Pil Heo*

Main category: cs.CV

TL;DR: SRL通过建立编码器与解码器之间的协同优化循环，解决了无监督目标中心学习中重建训练导致的注意力图与重建图之间的表示差异问题，在视频目标中心学习基准上取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 传统的基于重建的无监督目标中心学习模型存在编码器的高频注意力图与解码器的模糊重建图之间的根本冲突，这种差异导致恶性循环：编码器的噪声特征迫使解码器产生更模糊的输出，而模糊重建的梯度又缺乏监督编码器特征所需的高频细节。

Method: 提出协同表示学习(SRL)方法，建立编码器与解码器相互精炼的良性循环：利用编码器的清晰度去模糊解码器输出的语义边界，同时利用解码器的空间一致性去噪编码器特征。通过带有槽正则化目标的预热阶段来稳定这一过程。

Result: SRL在视频目标中心学习基准上取得了最先进的性能表现，有效解决了编码器与解码器之间的表示差距问题。

Conclusion: 通过建立编码器与解码器之间的协同优化机制，SRL成功打破了传统重建训练中的恶性循环，为无监督目标中心学习提供了一种有效的解决方案。

Abstract: Unsupervised object-centric learning models, particularly slot-based architectures, have shown great promise in decomposing complex scenes. However, their reliance on reconstruction-based training creates a fundamental conflict between the sharp, high-frequency attention maps of the encoder and the spatially consistent but blurry reconstruction maps of the decoder. We identify that this discrepancy gives rise to a vicious cycle: the noisy feature map from the encoder forces the decoder to average over possibilities and produce even blurrier outputs, while the gradient computed from blurry reconstruction maps lacks high-frequency details necessary to supervise encoder features. To break this cycle, we introduce Synergistic Representation Learning (SRL) that establishes a virtuous cycle where the encoder and decoder mutually refine one another. SRL leverages the encoder's sharpness to deblur the semantic boundary within the decoder output, while exploiting the decoder's spatial consistency to denoise the encoder's features. This mutual refinement process is stabilized by a warm-up phase with a slot regularization objective that initially allocates distinct entities per slot. By bridging the representational gap between the encoder and decoder, SRL achieves state-of-the-art results on video object-centric learning benchmarks. Codes are available at https://github.com/hynnsk/SRL.

</details>


### [70] [UnHype: CLIP-Guided Hypernetworks for Dynamic LoRA Unlearning](https://arxiv.org/abs/2602.03410)
*Piotr Wójcik,Maksym Petrenko,Wojciech Gromski,Przemysław Spurek,Maciej Zieba*

Main category: cs.CV

TL;DR: UnHype是一个将超网络集成到LoRA训练中的框架，用于在扩散模型中实现可扩展、上下文感知的机器遗忘，有效解决多概念同时擦除的挑战。


<details>
  <summary>Details</summary>
Motivation: 大规模扩散模型可能被滥用于生成有害内容，现有LoRA方法在概念语义适应性和多概念同时擦除方面存在局限性，需要更有效的机器遗忘解决方案。

Method: 提出UnHype框架，将超网络集成到单概念和多概念的LoRA训练中，能够根据CLIP嵌入动态生成自适应LoRA权重，实现上下文感知的遗忘。

Result: 在对象擦除、名人擦除和显式内容移除等多个挑战性任务中验证了UnHype的有效性和通用性，展示了稳定的训练行为和有效的概念控制。

Conclusion: UnHype为扩散模型提供了可扩展、高效的机器遗忘解决方案，能够更好地平衡概念移除与模型泛化能力，适用于现代文本到图像生成模型。

Abstract: Recent advances in large-scale diffusion models have intensified concerns about their potential misuse, particularly in generating realistic yet harmful or socially disruptive content. This challenge has spurred growing interest in effective machine unlearning, the process of selectively removing specific knowledge or concepts from a model without compromising its overall generative capabilities. Among various approaches, Low-Rank Adaptation (LoRA) has emerged as an effective and efficient method for fine-tuning models toward targeted unlearning. However, LoRA-based methods often exhibit limited adaptability to concept semantics and struggle to balance removing closely related concepts with maintaining generalization across broader meanings. Moreover, these methods face scalability challenges when multiple concepts must be erased simultaneously. To address these limitations, we introduce UnHype, a framework that incorporates hypernetworks into single- and multi-concept LoRA training. The proposed architecture can be directly plugged into Stable Diffusion as well as modern flow-based text-to-image models, where it demonstrates stable training behavior and effective concept control. During inference, the hypernetwork dynamically generates adaptive LoRA weights based on the CLIP embedding, enabling more context-aware, scalable unlearning. We evaluate UnHype across several challenging tasks, including object erasure, celebrity erasure, and explicit content removal, demonstrating its effectiveness and versatility. Repository: https://github.com/gmum/UnHype.

</details>


### [71] [Socratic-Geo: Synthetic Data Generation and Geometric Reasoning via Multi-Agent Interaction](https://arxiv.org/abs/2602.03414)
*Zhengbo Jiao,Shaobo Wang,Zifan Zhang,Wei Wang,Bing Zhao,Hu Wei,Linfeng Zhang*

Main category: cs.CV

TL;DR: Socratic-Geo是一个完全自主的多智能体框架，通过教师-求解器-生成器的协同交互，动态耦合数据合成与模型学习，解决了MLLMs在几何推理任务中高质量数据稀缺的问题。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的多模态大语言模型在几何推理方面存在明显瓶颈，主要原因是高质量图像-文本对的极度稀缺。人工标注成本高昂，自动化方法又难以保证保真度和训练效果。

Method: 采用三智能体架构：1)教师智能体通过参数化Python脚本生成和反思反馈（Reflect检查可解性，RePI检查视觉有效性）确保数据纯度；2)求解器智能体通过偏好学习优化推理，失败路径指导教师进行针对性增强；3)生成器智能体在积累的"图像-代码-指令"三元组上学习图像生成能力。

Result: 仅从108个种子问题开始，Socratic-Solver在六个基准测试上达到49.11分，仅使用基准方法四分之一的数据量就超越强基线2.43分；Socratic-Generator在GenExam上达到42.4%，创开源模型新SOTA，超越Seedream-4.0(39.8%)并接近Gemini-2.5-Flash-Image(43.1%)。

Conclusion: Socratic-Geo框架通过自主的多智能体协同和数据-学习动态耦合机制，有效解决了几何推理中的数据稀缺问题，在数据效率和性能上都取得了显著突破，为MLLMs的几何推理能力提升提供了新的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) have significantly advanced vision-language understanding. However, even state-of-the-art models struggle with geometric reasoning, revealing a critical bottleneck: the extreme scarcity of high-quality image-text pairs. Human annotation is prohibitively expensive, while automated methods fail to ensure fidelity and training effectiveness. Existing approaches either passively adapt to available images or employ inefficient random exploration with filtering, decoupling generation from learning needs. We propose Socratic-Geo, a fully autonomous framework that dynamically couples data synthesis with model learning through multi-agent interaction. The Teacher agent generates parameterized Python scripts with reflective feedback (Reflect for solvability, RePI for visual validity), ensuring image-text pair purity. The Solver agent optimizes reasoning through preference learning, with failure paths guiding Teacher's targeted augmentation. Independently, the Generator learns image generation capabilities on accumulated "image-code-instruction" triplets, distilling programmatic drawing intelligence into visual generation. Starting from only 108 seed problems, Socratic-Solver achieves 49.11 on six benchmarks using one-quarter of baseline data, surpassing strong baselines by 2.43 points. Socratic-Generator achieves 42.4% on GenExam, establishing new state-of-the-art for open-source models, surpassing Seedream-4.0 (39.8%) and approaching Gemini-2.5-Flash-Image (43.1%).

</details>


### [72] [ConsistentRFT: Reducing Visual Hallucinations in Flow-based Reinforcement Fine-Tuning](https://arxiv.org/abs/2602.03425)
*Xiaofeng Tan,Jun Liu,Yuanting Fan,Bin-Bin Gao,Xi Jiang,Xiaochen Chen,Jinlong Peng,Chengjie Wang,Hongsong Wang,Feng Zheng*

Main category: cs.CV

TL;DR: ConsistentRFT框架通过动态粒度采样和一致性策略梯度优化，有效减少基于流的强化微调模型中的视觉幻觉问题，在低层和高层感知幻觉上分别实现49%和38%的平均减少。


<details>
  <summary>Details</summary>
Motivation: 基于流的强化微调(RFT)方法经常产生视觉幻觉，如过度优化的细节和语义不对齐问题，需要探索其原因并找到解决方案。

Method: 提出ConsistentRFT框架：1) 动态粒度采样(DGR)机制，通过动态调度不同噪声源来平衡全局语义和局部细节的探索；2) 一致性策略梯度优化(CPGO)，通过将当前策略与更稳定的先验对齐来保持模型的一致性。

Result: 实验显示ConsistentRFT显著减少视觉幻觉，低层和高层感知幻觉分别平均减少49%和38%。在域外指标上优于其他RFT方法，相比FLUX1.dev基准的-0.4%下降，实现了5.1%的提升。

Conclusion: ConsistentRFT通过解决SDE采样中的探索局限性和策略梯度方法的轨迹模仿问题，有效缓解了基于流模型的视觉幻觉，为偏好对齐提供了更可靠的解决方案。

Abstract: Reinforcement Fine-Tuning (RFT) on flow-based models is crucial for preference alignment. However, they often introduce visual hallucinations like over-optimized details and semantic misalignment. This work preliminarily explores why visual hallucinations arise and how to reduce them. We first investigate RFT methods from a unified perspective, and reveal the core problems stemming from two aspects, exploration and exploitation: (1) limited exploration during stochastic differential equation (SDE) rollouts, leading to an over-emphasis on local details at the expense of global semantics, and (2) trajectory imitation process inherent in policy gradient methods, distorting the model's foundational vector field and its cross-step consistency. Building on this, we propose ConsistentRFT, a general framework to mitigate these hallucinations. Specifically, we design a Dynamic Granularity Rollout (DGR) mechanism to balance exploration between global semantics and local details by dynamically scheduling different noise sources. We then introduce a Consistent Policy Gradient Optimization (CPGO) that preserves the model's consistency by aligning the current policy with a more stable prior. Extensive experiments demonstrate that ConsistentRFT significantly mitigates visual hallucinations, achieving average reductions of 49\% for low-level and 38\% for high-level perceptual hallucinations. Furthermore, ConsistentRFT outperforms other RFT methods on out-of-domain metrics, showing an improvement of 5.1\% (v.s. the baseline's decrease of -0.4\%) over FLUX1.dev. This is \href{https://xiaofeng-tan.github.io/projects/ConsistentRFT}{Project Page}.

</details>


### [73] [Hierarchical Concept-to-Appearance Guidance for Multi-Subject Image Generation](https://arxiv.org/abs/2602.03448)
*Yijia Xu,Zihao Wang,Jinshi Cui*

Main category: cs.CV

TL;DR: 提出了分层概念到外观引导(CAG)框架，通过VAE丢弃训练和对应感知掩码注意力机制，在概念和外观两个层面提供显式监督，显著提升了多主体图像生成的身份一致性和组合控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖扩散模型隐式关联文本提示和参考图像，导致身份不一致和组合控制有限的问题，需要更显式和结构化的监督机制。

Method: 1. 概念层面：VAE丢弃训练策略，随机省略参考VAE特征，迫使模型依赖视觉语言模型的语义信号；2. 外观层面：在扩散变换器中引入对应感知掩码注意力模块，限制文本token只关注匹配的参考区域。

Result: 在多项实验中取得最先进性能，大幅提升了提示跟随能力和主体一致性。

Conclusion: 分层概念到外观引导框架通过显式监督机制有效解决了多主体图像生成中的身份一致性和组合控制问题，为相关研究提供了新的思路。

Abstract: Multi-subject image generation aims to synthesize images that faithfully preserve the identities of multiple reference subjects while following textual instructions. However, existing methods often suffer from identity inconsistency and limited compositional control, as they rely on diffusion models to implicitly associate text prompts with reference images. In this work, we propose Hierarchical Concept-to-Appearance Guidance (CAG), a framework that provides explicit, structured supervision from high-level concepts to fine-grained appearances. At the conceptual level, we introduce a VAE dropout training strategy that randomly omits reference VAE features, encouraging the model to rely more on robust semantic signals from a Visual Language Model (VLM) and thereby promoting consistent concept-level generation in the absence of complete appearance cues. At the appearance level, we integrate the VLM-derived correspondences into a correspondence-aware masked attention module within the Diffusion Transformer (DiT). This module restricts each text token to attend only to its matched reference regions, ensuring precise attribute binding and reliable multi-subject composition. Extensive experiments demonstrate that our method achieves state-of-the-art performance on the multi-subject image generation, substantially improving prompt following and subject consistency.

</details>


### [74] [Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars](https://arxiv.org/abs/2602.01538)
*Youliang Zhang,Zhengguang Zhou,Zhentao Yu,Ziyao Huang,Teng Hu,Sen Liang,Guozhen Zhang,Ziqiao Peng,Shunkai Li,Yi Chen,Zixiang Zhou,Yuan Zhou,Qinglin Lu,Xiu Li*

Main category: cs.CV

TL;DR: InteractAvatar是一个双流框架，用于生成具有接地人-物交互的说话虚拟形象，通过解耦感知规划和视频合成来解决环境感知和控制质量的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法只能生成简单人体运动的全身说话虚拟形象，扩展到接地人-物交互(GHOI)存在挑战，需要虚拟形象与环境物体进行文本对齐的交互，这需要环境感知能力并面临控制质量权衡问题。

Method: 提出双流框架InteractAvatar：1)感知交互模块(PIM)利用检测增强环境感知，生成文本对齐的交互动作；2)音频交互感知生成模块(AIM)合成执行物体交互的生动说话虚拟形象；3)通过专门设计的动作-视频对齐器实现并行协同生成。

Result: 建立了GroundedInter基准数据集用于评估GHOI视频生成，大量实验和比较证明了该方法在生成接地人-物交互说话虚拟形象方面的有效性。

Conclusion: InteractAvatar通过解耦感知规划和视频合成，有效解决了GHOI生成中的环境感知和控制质量困境，能够生成高质量的文本对齐人-物交互说话虚拟形象。

Abstract: Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io

</details>


### [75] [Contextualized Visual Personalization in Vision-Language Models](https://arxiv.org/abs/2602.03454)
*Yeongtak Oh,Sangwon Yu,Junsung Park,Han Cheol Moon,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: CoViP是一个统一的视觉语言模型框架，通过强化学习后训练和标题增强生成来解决上下文视觉个性化问题，显著提升了现有模型在个性化图像描述和下游任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型缺乏基于用户特定经验生成个性化响应的能力，无法将视觉输入与用户积累的视觉-文本上下文关联起来。

Method: 提出了CoViP框架，将个性化图像描述作为核心任务，采用基于强化学习的后训练和标题增强生成技术来提升个性化能力，并引入诊断评估排除文本捷径解决方案。

Result: 实验表明现有开源和专有VLM存在显著局限性，而CoViP不仅改善了个性化图像描述，还在下游个性化任务中获得全面提升。

Conclusion: CoViP是实现鲁棒且可泛化的上下文视觉个性化的重要阶段，为视觉语言模型的个性化能力提供了有效解决方案。

Abstract: Despite recent progress in vision-language models (VLMs), existing approaches often fail to generate personalized responses based on the user's specific experiences, as they lack the ability to associate visual inputs with a user's accumulated visual-textual context. We newly formalize this challenge as contextualized visual personalization, which requires the visual recognition and textual retrieval of personalized visual experiences by VLMs when interpreting new images. To address this issue, we propose CoViP, a unified framework that treats personalized image captioning as a core task for contextualized visual personalization and improves this capability through reinforcement-learning-based post-training and caption-augmented generation. We further introduce diagnostic evaluations that explicitly rule out textual shortcut solutions and verify whether VLMs truly leverage visual context. Extensive experiments demonstrate that existing open-source and proprietary VLMs exhibit substantial limitations, while CoViP not only improves personalized image captioning but also yields holistic gains across downstream personalization tasks. These results highlight CoViP as a crucial stage for enabling robust and generalizable contextualized visual personalization.

</details>


### [76] [Inlier-Centric Post-Training Quantization for Object Detection Models](https://arxiv.org/abs/2602.03472)
*Minsu Kim,Dongyeun Lee,Jaemyung Yu,Jiwan Hur,Giseop Kim,Junmo Kim*

Main category: cs.CV

TL;DR: InlierQ是一种无需标签的后训练量化方法，通过梯度感知体积显著性分数区分异常值和信息性内点，使用EM算法拟合后验分布，有效抑制背景杂波和传感器噪声等任务无关形态引起的冗余激活，降低量化误差。


<details>
  <summary>Details</summary>
Motivation: 目标检测计算需求巨大，但背景杂波和传感器噪声等任务无关形态会导致冗余激活，扩大激活范围并使分布偏向任务无关响应，使比特分配复杂化并削弱信息特征的保留。

Method: 提出InlierQ方法：计算梯度感知体积显著性分数，将每个体积分类为内点或异常值，使用期望最大化(EM)算法拟合这些分数的后验分布，从而抑制异常值同时保留信息特征。

Result: 在COCO和nuScenes基准测试中，针对相机(2D和3D)和LiDAR(3D)目标检测，均实现了量化误差的一致降低。

Conclusion: InlierQ是一种标签无关、即插即用的后训练量化方法，仅需64个校准样本即可有效分离异常值和内点，显著改善目标检测的量化性能。

Abstract: Object detection is pivotal in computer vision, yet its immense computational demands make deployment slow and power-hungry, motivating quantization. However, task-irrelevant morphologies such as background clutter and sensor noise induce redundant activations (or anomalies). These anomalies expand activation ranges and skew activation distributions toward task-irrelevant responses, complicating bit allocation and weakening the preservation of informative features. Without a clear criterion to distinguish anomalies, suppressing them can inadvertently discard useful information. To address this, we present InlierQ, an inlier-centric post-training quantization approach that separates anomalies from informative inliers. InlierQ computes gradient-aware volume saliency scores, classifies each volume as an inlier or anomaly, and fits a posterior distribution over these scores using the Expectation-Maximization (EM) algorithm. This design suppresses anomalies while preserving informative features. InlierQ is label-free, drop-in, and requires only 64 calibration samples. Experiments on the COCO and nuScenes benchmarks show consistent reductions in quantization error for camera-based (2D and 3D) and LiDAR-based (3D) object detection.

</details>


### [77] [Decoupling Skeleton and Flesh: Efficient Multimodal Table Reasoning with Disentangled Alignment and Structure-aware Guidance](https://arxiv.org/abs/2602.03491)
*Yingjie Zhu,Xuefeng Bai,Kehai Chen,Yang Xiang,Youcheng Pan,Xiaoqiang Zhou,Min Zhang*

Main category: cs.CV

TL;DR: 提出DiSCo解耦结构-内容对齐框架和Table-GLS全局到局部结构引导推理框架，无需外部工具和大量标注即可提升大视觉语言模型的表格推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决大视觉语言模型在表格图像推理中的挑战，现有方法依赖昂贵的有监督训练、强化学习或外部工具，限制了效率和可扩展性。

Method: 首先提出DiSCo框架，在跨模态对齐过程中显式分离结构抽象和语义接地；然后提出Table-GLS框架，通过结构化探索和证据基础推理进行表格推理。

Result: 在多个基准测试上的广泛实验表明，该框架有效提升了LVLM的表格理解和推理能力，特别是在未见过的表格结构上表现出良好的泛化性能。

Conclusion: 该工作提供了一种高效适应表格推理的方法，通过结构-内容解耦和全局-局部结构引导的推理策略，显著提升了大视觉语言模型在表格理解任务上的性能。

Abstract: Reasoning over table images remains challenging for Large Vision-Language Models (LVLMs) due to complex layouts and tightly coupled structure-content information. Existing solutions often depend on expensive supervised training, reinforcement learning, or external tools, limiting efficiency and scalability. This work addresses a key question: how to adapt LVLMs to table reasoning with minimal annotation and no external tools? Specifically, we first introduce DiSCo, a Disentangled Structure-Content alignment framework that explicitly separates structural abstraction from semantic grounding during multimodal alignment, efficiently adapting LVLMs to tables structures. Building on DiSCo, we further present Table-GLS, a Global-to-Local Structure-guided reasoning framework that performs table reasoning via structured exploration and evidence-grounded inference. Extensive experiments across diverse benchmarks demonstrate that our framework efficiently enhances LVLM's table understanding and reasoning capabilities, particularly generalizing to unseen table structures.

</details>


### [78] [Semantic Routing: Exploring Multi-Layer LLM Feature Weighting for Diffusion Transformers](https://arxiv.org/abs/2602.03510)
*Bozhou Li,Yushuo Guan,Haolin Li,Bohan Zeng,Yiyan Ji,Yue Ding,Pengfei Wan,Kun Gai,Yuanxing Zhang,Wentao Zhang*

Main category: cs.CV

TL;DR: 提出统一的归一化凸融合框架，通过轻量级门控系统整合多层LLM隐藏状态，实现时间、深度和联合融合，发现深度语义路由是最佳条件策略，能显著提升文本-图像对齐和组合生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有DiT模型使用LLM作为文本编码器时，文本条件通常是静态的且仅使用单层LLM特征，忽略了LLM层的语义层次性和扩散过程的时间动态性。

Method: 引入归一化凸融合框架，配备轻量级门控机制，系统整合多层LLM隐藏状态，包括时间融合、深度融合和联合融合三种策略。

Result: 深度语义路由策略表现最佳，在GenAI-Bench计数任务上提升9.97分，而纯时间融合会降低生成保真度，存在训练-推理轨迹不匹配问题。

Conclusion: 深度路由是强大有效的基线方法，强调需要轨迹感知信号来实现稳健的时间相关条件控制。

Abstract: Recent DiT-based text-to-image models increasingly adopt LLMs as text encoders, yet text conditioning remains largely static and often utilizes only a single LLM layer, despite pronounced semantic hierarchy across LLM layers and non-stationary denoising dynamics over both diffusion time and network depth. To better match the dynamic process of DiT generation and thereby enhance the diffusion model's generative capability, we introduce a unified normalized convex fusion framework equipped with lightweight gates to systematically organize multi-layer LLM hidden states via time-wise, depth-wise, and joint fusion. Experiments establish Depth-wise Semantic Routing as the superior conditioning strategy, consistently improving text-image alignment and compositional generation (e.g., +9.97 on the GenAI-Bench Counting task). Conversely, we find that purely time-wise fusion can paradoxically degrade visual generation fidelity. We attribute this to a train-inference trajectory mismatch: under classifier-free guidance, nominal timesteps fail to track the effective SNR, causing semantically mistimed feature injection during inference. Overall, our results position depth-wise routing as a strong and effective baseline and highlight the critical need for trajectory-aware signals to enable robust time-dependent conditioning.

</details>


### [79] [Interpretable Logical Anomaly Classification via Constraint Decomposition and Instruction Fine-Tuning](https://arxiv.org/abs/2602.03530)
*Xufei Zhang,Xinjiao Zhou,Ziling Deng,Dongdong Geng,Jianxiong Wang*

Main category: cs.CV

TL;DR: LogiCls：基于视觉语言框架的逻辑异常分类方法，通过将复杂约束分解为可验证子查询，结合链式思维监督和难度感知重采样策略，实现工业图像中逻辑异常的细粒度分类和证据追踪


<details>
  <summary>Details</summary>
Motivation: 现有异常检测方法仅提供二元判断，无法识别具体违反的逻辑规则，限制了在质量保证中的实际价值

Method: 提出视觉语言框架LogiCls，将逻辑约束分解为可验证子查询序列；开发数据中心的指令合成管道生成链式思维监督；采用难度感知重采样策略优化训练过程

Result: 实验表明LogiCls在工业逻辑异常分类方面表现出鲁棒性、可解释性和准确性，能够同时提供违规类别和证据链

Conclusion: 该方法统一了异常检测和细粒度违规分类，为工业质量保证提供了更实用的解决方案，通过分解复杂约束和链式思维推理实现了逻辑敏感的分析能力

Abstract: Logical anomalies are violations of predefined constraints on object quantity, spatial layout, and compositional relationships in industrial images. While prior work largely treats anomaly detection as a binary decision, such formulations cannot indicate which logical rule is broken and therefore offer limited value for quality assurance. We introduce Logical Anomaly Classification (LAC), a task that unifies anomaly detection and fine-grained violation classification in a single inference step. To tackle LAC, we propose LogiCls, a vision-language framework that decomposes complex logical constraints into a sequence of verifiable subqueries. We further present a data-centric instruction synthesis pipeline that generates chain-of-thought (CoT) supervision for these subqueries, coupling precise grounding annotations with diverse image-text augmentations to adapt vision language models (VLMs) to logic-sensitive reasoning. Training is stabilized by a difficulty-aware resampling strategy that emphasizes challenging subqueries and long tail constraint types. Extensive experiments demonstrate that LogiCls delivers robust, interpretable, and accurate industrial logical anomaly classification, providing both the predicted violation categories and their evidence trails.

</details>


### [80] [PnP-U3D: Plug-and-Play 3D Framework Bridging Autoregression and Diffusion for Unified Understanding and Generation](https://arxiv.org/abs/2602.03533)
*Yongwei Chen,Tianyi Wei,Yushi Lan,Zhaoyang Lyu,Shangchen Zhou,Xudong Xu,Xingang Pan*

Main category: cs.CV

TL;DR: 提出了首个结合自回归和扩散模型的3D理解与生成统一框架，通过轻量级Transformer桥接语言模型和扩散模型的特征空间，在保持各模型先验的同时实现跨模态信息交互，在多个3D任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有将3D任务统一到单一自回归范式的方法存在性能显著下降和训练成本过高的问题，关键在于需要在保持理解和生成各自能力的同时实现有效的信息交互，并利用预训练模型降低训练成本。

Method: 采用自回归下一令牌预测范式处理3D理解任务，使用连续扩散范式处理3D生成任务，通过轻量级Transformer连接大语言模型的特征空间和3D扩散模型的条件空间。

Result: 在多个3D理解和生成基准测试中实现了最先进的性能，同时在3D编辑任务上表现优异。

Conclusion: 统一的自回归+扩散模型是构建更通用3D智能的一个有前景的方向，能够有效平衡理解和生成任务的需求。

Abstract: The rapid progress of large multimodal models has inspired efforts toward unified frameworks that couple understanding and generation. While such paradigms have shown remarkable success in 2D, extending them to 3D remains largely underexplored. Existing attempts to unify 3D tasks under a single autoregressive (AR) paradigm lead to significant performance degradation due to forced signal quantization and prohibitive training cost. Our key insight is that the essential challenge lies not in enforcing a unified autoregressive paradigm, but in enabling effective information interaction between generation and understanding while minimally compromising their inherent capabilities and leveraging pretrained models to reduce training cost. Guided by this perspective, we present the first unified framework for 3D understanding and generation that combines autoregression with diffusion. Specifically, we adopt an autoregressive next-token prediction paradigm for 3D understanding, and a continuous diffusion paradigm for 3D generation. A lightweight transformer bridges the feature space of large language models and the conditional space of 3D diffusion models, enabling effective cross-modal information exchange while preserving the priors learned by standalone models. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across diverse 3D understanding and generation benchmarks, while also excelling in 3D editing tasks. These results highlight the potential of unified AR+diffusion models as a promising direction for building more general-purpose 3D intelligence.

</details>


### [81] [Constrained Dynamic Gaussian Splatting](https://arxiv.org/abs/2602.03538)
*Zihan Zheng,Zhenglong Wu,Xuanxuan Wang,Houqiang Zhong,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai,Wenjun Zhang*

Main category: cs.CV

TL;DR: CDGS是一个预算约束的动态高斯泼溅框架，通过可微分预算控制器和混合压缩方案，在严格遵循硬件内存限制的同时实现最优渲染质量


<details>
  <summary>Details</summary>
Motivation: 动态高斯泼溅在边缘设备部署中存在内存消耗与渲染质量的两难问题：无约束密集化导致内存占用过高，而启发式剪枝无法在预设高斯预算下达到最优质量

Method: 提出可微分预算控制器，融合几何、运动和感知线索的多模态统一重要性评分；采用静态与动态元素解耦优化和自适应分配机制；实施三阶段训练策略和双模式混合压缩方案

Result: 在严格遵循硬件约束（误差<2%）的同时，将率失真性能推向帕累托前沿，相比最先进方法实现超过3倍的压缩比

Conclusion: CDGS成功解决了动态场景重建中的预算约束优化问题，为边缘设备上的高质量4D重建提供了实用解决方案

Abstract: While Dynamic Gaussian Splatting enables high-fidelity 4D reconstruction, its deployment is severely hindered by a fundamental dilemma: unconstrained densification leads to excessive memory consumption incompatible with edge devices, whereas heuristic pruning fails to achieve optimal rendering quality under preset Gaussian budgets. In this work, we propose Constrained Dynamic Gaussian Splatting (CDGS), a novel framework that formulates dynamic scene reconstruction as a budget-constrained optimization problem to enforce a strict, user-defined Gaussian budget during training. Our key insight is to introduce a differentiable budget controller as the core optimization driver. Guided by a multi-modal unified importance score, this controller fuses geometric, motion, and perceptual cues for precise capacity regulation. To maximize the utility of this fixed budget, we further decouple the optimization of static and dynamic elements, employing an adaptive allocation mechanism that dynamically distributes capacity based on motion complexity. Furthermore, we implement a three-phase training strategy to seamlessly integrate these constraints, ensuring precise adherence to the target count. Coupled with a dual-mode hybrid compression scheme, CDGS not only strictly adheres to hardware constraints (error < 2%}) but also pushes the Pareto frontier of rate-distortion performance. Extensive experiments demonstrate that CDGS delivers optimal rendering quality under varying capacity limits, achieving over 3x compression compared to state-of-the-art methods.

</details>


### [82] [Cut to the Mix: Simple Data Augmentation Outperforms Elaborate Ones in Limited Organ Segmentation Datasets](https://arxiv.org/abs/2602.03555)
*Chang Liu,Fuxin Fan,Annette Schwarz,Andreas Maier*

Main category: cs.CV

TL;DR: 论文研究了四种跨图像数据增强策略（CutMix、CarveMix、ObjectAug和AnatoMix）在多器官分割任务中的应用，发现CutMix、CarveMix和AnatoMix相比无数据增强的nnUNet能将平均Dice分数分别提高4.9、2.0和1.9个百分点。


<details>
  <summary>Details</summary>
Motivation: 深度学习医学图像分割需要大量标注数据，但临床数据稀缺问题突出。传统数据增强局限于单图像操作，而跨图像和对象级别的数据增强策略在多器官分割任务中尚未充分探索。

Method: 在两个器官分割数据集上系统评估了四种跨图像数据增强策略：CutMix、CarveMix、ObjectAug和AnatoMix，并与不使用数据增强的nnUNet基线模型进行对比。

Result: 实验结果显示，CutMix表现最佳（Dice分数提升4.9），其次是CarveMix（提升2.0）和AnatoMix（提升1.9）。即使CutMix产生直觉上'错误'的图像，仍能显著提升分割性能。结合传统数据增强策略可进一步改善结果。

Conclusion: 跨图像数据增强策略能有效提升有限数据下的多器官分割性能，其中CutMix是一种简单但鲁棒的策略。研究为医学图像分割的数据增强提供了新的基准和实现参考。

Abstract: Multi-organ segmentation is a widely applied clinical routine and automated organ segmentation tools dramatically improve the pipeline of the radiologists. Recently, deep learning (DL) based segmentation models have shown the capacity to accomplish such a task. However, the training of the segmentation networks requires large amount of data with manual annotations, which is a major concern due to the data scarcity from clinic. Working with limited data is still common for researches on novel imaging modalities. To enhance the effectiveness of DL models trained with limited data, data augmentation (DA) is a crucial regularization technique. Traditional DA (TDA) strategies focus on basic intra-image operations, i.e. generating images with different orientations and intensity distributions. In contrast, the interimage and object-level DA operations are able to create new images from separate individuals. However, such DA strategies are not well explored on the task of multi-organ segmentation. In this paper, we investigated four possible inter-image DA strategies: CutMix, CarveMix, ObjectAug and AnatoMix, on two organ segmentation datasets. The result shows that CutMix, CarveMix and AnatoMix can improve the average dice score by 4.9, 2.0 and 1.9, compared with the state-of-the-art nnUNet without DA strategies. These results can be further improved by adding TDA strategies. It is revealed in our experiments that Cut-Mix is a robust but simple DA strategy to drive up the segmentation performance for multi-organ segmentation, even when CutMix produces intuitively 'wrong' images. Our implementation is publicly available for future benchmarks.

</details>


### [83] [ELIQ: A Label-Free Framework for Quality Assessment of Evolving AI-Generated Images](https://arxiv.org/abs/2602.03558)
*Xinyue Li,Zhiming Xu,Zhichao Zhang,Zhaolin Cai,Sijing Wu,Xiongkuo Min,Yitong Chen,Guangtao Zhai*

Main category: cs.CV

TL;DR: ELIQ是一个无需人工标注的AI生成图像质量评估框架，通过自动构建正负样本对来评估视觉质量和提示-图像对齐度，使用指令调优的多模态模型实现可迁移的质量评估。


<details>
  <summary>Details</summary>
Motivation: 文本到图像生成模型的快速发展使得之前收集的标注标签对于新一代模型变得不可靠，需要一种无需人工标注的质量评估方法来应对不断演进的生成模型。

Method: 自动构建正负样本对覆盖传统失真和AIGC特定失真模式，通过指令调优将预训练多模态模型转化为质量感知评估器，使用轻量级门控融合和Quality Query Transformer预测二维质量。

Result: 在多个基准测试中，ELIQ始终优于现有的无标注方法，能够从AIGC场景泛化到用户生成内容场景而无需修改。

Conclusion: ELIQ为持续演进的生成模型提供了可扩展的无标注质量评估方案，为应对快速发展的文本到图像生成技术提供了有效的质量监控工具。

Abstract: Generative text-to-image models are advancing at an unprecedented pace, continuously shifting the perceptual quality ceiling and rendering previously collected labels unreliable for newer generations. To address this, we present ELIQ, a Label-free Framework for Quality Assessment of Evolving AI-generated Images. Specifically, ELIQ focuses on visual quality and prompt-image alignment, automatically constructs positive and aspect-specific negative pairs to cover both conventional distortions and AIGC-specific distortion modes, enabling transferable supervision without human annotations. Building on these pairs, ELIQ adapts a pre-trained multimodal model into a quality-aware critic via instruction tuning and predicts two-dimensional quality using lightweight gated fusion and a Quality Query Transformer. Experiments across multiple benchmarks demonstrate that ELIQ consistently outperforms existing label-free methods, generalizes from AI-generated content (AIGC) to user-generated content (UGC) scenarios without modification, and paves the way for scalable and label-free quality assessment under continuously evolving generative models. The code will be released upon publication.

</details>


### [84] [SlowFocus: Enhancing Fine-grained Temporal Understanding in Video LLM](https://arxiv.org/abs/2602.03589)
*Ming Nie,Dan Ding,Chunwei Wang,Yuanfan Guo,Jianhua Han,Hang Xu,Li Zhang*

Main category: cs.CV

TL;DR: SlowFocus机制通过识别问题相关时间段进行密集采样，结合多频率混合注意力模块，在保持帧级语义质量的同时提升视频级时序理解能力，显著改善了视频大语言模型在细粒度视频理解任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前视频大语言模型(Vid-LLMs)无法同时保持高质量的帧级语义信息(足够的每帧token数)和全面的视频级时序信息(足够的每视频采样帧数)，这阻碍了细粒度视频理解的发展。

Method: 提出SlowFocus机制：1)基于问题识别相关时间段；2)在该段进行密集采样提取局部高频特征；3)使用多频率混合注意力模块聚合局部高频细节与全局低频上下文；4)配套训练策略增强时序定位和详细时序推理能力。

Result: 在现有公共视频理解基准和新提出的FineAction-CGR基准上进行的综合实验证明了该机制的优越性。

Conclusion: SlowFocus机制有效解决了Vid-LLMs在同时保持帧级语义质量和视频级时序信息方面的挑战，显著提升了细粒度视频理解能力，为视频大语言模型的发展提供了新的技术路径。

Abstract: Large language models (LLMs) have demonstrated exceptional capabilities in text understanding, which has paved the way for their expansion into video LLMs (Vid-LLMs) to analyze video data. However, current Vid-LLMs struggle to simultaneously retain high-quality frame-level semantic information (i.e., a sufficient number of tokens per frame) and comprehensive video-level temporal information (i.e., an adequate number of sampled frames per video). This limitation hinders the advancement of Vid-LLMs towards fine-grained video understanding. To address this issue, we introduce the SlowFocus mechanism, which significantly enhances the equivalent sampling frequency without compromising the quality of frame-level visual tokens. SlowFocus begins by identifying the query-related temporal segment based on the posed question, then performs dense sampling on this segment to extract local high-frequency features. A multi-frequency mixing attention module is further leveraged to aggregate these local high-frequency details with global low-frequency contexts for enhanced temporal comprehension. Additionally, to tailor Vid-LLMs to this innovative mechanism, we introduce a set of training strategies aimed at bolstering both temporal grounding and detailed temporal reasoning capabilities. Furthermore, we establish FineAction-CGR, a benchmark specifically devised to assess the ability of Vid-LLMs to process fine-grained temporal understanding tasks. Comprehensive experiments demonstrate the superiority of our mechanism across both existing public video understanding benchmarks and our proposed FineAction-CGR.

</details>


### [85] [High-Resolution Underwater Camouflaged Object Detection: GBU-UCOD Dataset and Topology-Aware and Frequency-Decoupled Networks](https://arxiv.org/abs/2602.03591)
*Wenji Wu,Shuo Ye,Yiyu Liu,Jiguang He,Zhuo Wang,Zitong Yu*

Main category: cs.CV

TL;DR: DeepTopo-Net是一个用于水下伪装目标检测的新框架，集成了拓扑感知建模和频率解耦感知，通过水条件自适应感知器和深海拓扑优化模块解决深海细长生物和透明生物的检测难题。


<details>
  <summary>Details</summary>
Motivation: 水下伪装目标检测面临极端视觉相似性和海洋深度变化的挑战，现有方法在处理深海细长生物拓扑碎片化和透明生物特征提取方面存在困难。

Method: 提出Water-Conditioned Adaptive Perceptor(WCAP)使用黎曼度量张量动态变形卷积采样场处理物理退化，开发Abyssal-Topology Refinement Module(ATRM)通过骨骼先验保持细长目标的结构连通性。

Result: 在MAS3K、RMAS和新建的GBU-UCOD数据集上达到最先进性能，特别是在保持复杂水下模式形态完整性方面表现优异。

Conclusion: DeepTopo-Net有效解决了水下伪装目标检测的关键挑战，GBU-UCOD数据集填补了深海区域高分辨率数据的空白，为水下视觉研究提供了重要工具。

Abstract: Underwater Camouflaged Object Detection (UCOD) is a challenging task due to the extreme visual similarity between targets and backgrounds across varying marine depths. Existing methods often struggle with topological fragmentation of slender creatures in the deep sea and the subtle feature extraction of transparent organisms. In this paper, we propose DeepTopo-Net, a novel framework that integrates topology-aware modeling with frequency-decoupled perception. To address physical degradation, we design the Water-Conditioned Adaptive Perceptor (WCAP), which employs Riemannian metric tensors to dynamically deform convolutional sampling fields. Furthermore, the Abyssal-Topology Refinement Module (ATRM) is developed to maintain the structural connectivity of spindly targets through skeletal priors. Specifically, we first introduce GBU-UCOD, the first high-resolution (2K) benchmark tailored for marine vertical zonation, filling the data gap for hadal and abyssal zones. Extensive experiments on MAS3K, RMAS, and our proposed GBU-UCOD datasets demonstrate that DeepTopo-Net achieves state-of-the-art performance, particularly in preserving the morphological integrity of complex underwater patterns. The datasets and codes will be released at https://github.com/Wuwenji18/GBU-UCOD.

</details>


### [86] [TIPS Over Tricks: Simple Prompts for Effective Zero-shot Anomaly Detection](https://arxiv.org/abs/2602.03594)
*Alireza Salehi,Ehsan Karami,Sepehr Noey,Sahand Noey,Makoto Yamada,Reshad Hosseini,Mohammad Sabokrou*

Main category: cs.CV

TL;DR: 提出基于TIPS视觉语言模型的零样本异常检测方法，通过解耦提示词和局部特征注入机制，在无需目标域正常数据的情况下显著提升图像级和像素级异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于CLIP的零样本异常检测方法存在空间错位和对细粒度异常敏感度不足的问题，而先前研究主要关注复杂辅助模块而忽视了骨干网络的选择。

Method: 采用空间感知训练的TIPS模型作为骨干网络，设计解耦提示词策略（固定提示词用于图像级检测，可学习提示词用于像素级定位），并通过局部证据注入机制弥合全局与局部特征间的分布差距。

Result: 在七个工业数据集上，图像级检测性能提升1.1-3.9%，像素级定位性能提升1.5-6.9%，实现了强泛化能力和简洁架构。

Conclusion: TIPS骨干网络结合解耦提示词和局部特征注入机制，有效解决了零样本异常检测中的空间对齐和细粒度感知问题，为工业应用提供了高效解决方案。

Abstract: Anomaly detection identifies departures from expected behavior in safety-critical settings. When target-domain normal data are unavailable, zero-shot anomaly detection (ZSAD) leverages vision-language models (VLMs). However, CLIP's coarse image-text alignment limits both localization and detection due to (i) spatial misalignment and (ii) weak sensitivity to fine-grained anomalies; prior work compensates with complex auxiliary modules yet largely overlooks the choice of backbone. We revisit the backbone and use TIPS-a VLM trained with spatially aware objectives. While TIPS alleviates CLIP's issues, it exposes a distributional gap between global and local features. We address this with decoupled prompts-fixed for image-level detection and learnable for pixel-level localization-and by injecting local evidence into the global score. Without CLIP-specific tricks, our TIPS-based pipeline improves image-level performance by 1.1-3.9% and pixel-level by 1.5-6.9% across seven industrial datasets, delivering strong generalization with a lean architecture. Code is available at github.com/AlirezaSalehy/Tipsomaly.

</details>


### [87] [Refer-Agent: A Collaborative Multi-Agent System with Reasoning and Reflection for Referring Video Object Segmentation](https://arxiv.org/abs/2602.03595)
*Haichao Jiang,Tianming Liang,Wei-Shi Zheng,Jian-Fang Hu*

Main category: cs.CV

TL;DR: 提出Refer-Agent，一个基于多智能体协作和交替推理-反思机制的零样本文本视频目标分割方法，无需大规模监督微调即可超越现有方法性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于监督微调的方法数据依赖性强、扩展性差，而零样本方法性能不足，需要更灵活且高效的新范式。

Method: 采用多智能体系统，包含从粗到细的帧选择策略、动态焦点布局和链式反思机制（提问者-回答者对），实现逐步推理和结果验证。

Result: 在五个基准测试中显著超越最先进的监督微调方法和零样本方法，且能快速集成新多模态大语言模型而无需额外微调。

Conclusion: Refer-Agent通过创新的多智能体协作框架，成功解决了文本视频目标分割领域的数据依赖和扩展性问题，为未来研究提供了新方向。

Abstract: Referring Video Object Segmentation (RVOS) aims to segment objects in videos based on textual queries. Current methods mainly rely on large-scale supervised fine-tuning (SFT) of Multi-modal Large Language Models (MLLMs). However, this paradigm suffers from heavy data dependence and limited scalability against the rapid evolution of MLLMs. Although recent zero-shot approaches offer a flexible alternative, their performance remains significantly behind SFT-based methods, due to the straightforward workflow designs. To address these limitations, we propose \textbf{Refer-Agent}, a collaborative multi-agent system with alternating reasoning-reflection mechanisms. This system decomposes RVOS into step-by-step reasoning process. During reasoning, we introduce a Coarse-to-Fine frame selection strategy to ensure the frame diversity and textual relevance, along with a Dynamic Focus Layout that adaptively adjusts the agent's visual focus. Furthermore, we propose a Chain-of-Reflection mechanism, which employs a Questioner-Responder pair to generate a self-reflection chain, enabling the system to verify intermediate results and generates feedback for next-round reasoning refinement. Extensive experiments on five challenging benchmarks demonstrate that Refer-Agent significantly outperforms state-of-the-art methods, including both SFT-based models and zero-shot approaches. Moreover, Refer-Agent is flexible and enables fast integration of new MLLMs without any additional fine-tuning costs. Code will be released.

</details>


### [88] [A Lightweight Library for Energy-Based Joint-Embedding Predictive Architectures](https://arxiv.org/abs/2602.03604)
*Basile Terver,Randall Balestriero,Megi Dervishi,David Fan,Quentin Garrido,Tushar Nagarajan,Koustuv Sinha,Wancong Zhang,Mike Rabbat,Yann LeCun,Amir Bar*

Main category: cs.CV

TL;DR: EB-JEPA是一个开源库，用于基于联合嵌入预测架构(JEPA)学习表示和世界模型。该库提供模块化实现，支持从图像到视频再到动作条件世界模型的表示学习，单GPU数小时可训练，适合研究和教育。


<details>
  <summary>Details</summary>
Motivation: 开发一个易于使用的开源工具，使基于能量的自监督学习更易获取，同时展示JEPA架构如何从图像级表示学习扩展到包含时序动态和动作条件的复杂世界建模。

Method: 使用联合嵌入预测架构(JEPA)，在表示空间而非像素空间进行预测，避免生成建模的缺陷。提供模块化实现，包括CIFAR-10上的组件消融实验、Moving MNIST的多步预测示例，以及Two Rooms导航任务的动作条件世界模型。

Result: 在CIFAR-10上获得91%的探测准确率；在Moving MNIST上成功展示时序建模扩展；在Two Rooms导航任务中达到97%的规划成功率。消融实验揭示了各正则化组件对防止表示崩溃的关键作用。

Conclusion: EB-JEPA成功展示了JEPA架构在不同复杂度的表示学习任务中的有效性和可扩展性，为自监督学习和世界建模研究提供了实用且高效的工具基础。

Abstract: We present EB-JEPA, an open-source library for learning representations and world models using Joint-Embedding Predictive Architectures (JEPAs). JEPAs learn to predict in representation space rather than pixel space, avoiding the pitfalls of generative modeling while capturing semantically meaningful features suitable for downstream tasks. Our library provides modular, self-contained implementations that illustrate how representation learning techniques developed for image-level self-supervised learning can transfer to video, where temporal dynamics add complexity, and ultimately to action-conditioned world models, where the model must additionally learn to predict the effects of control inputs. Each example is designed for single-GPU training within a few hours, making energy-based self-supervised learning accessible for research and education. We provide ablations of JEA components on CIFAR-10. Probing these representations yields 91% accuracy, indicating that the model learns useful features. Extending to video, we include a multi-step prediction example on Moving MNIST that demonstrates how the same principles scale to temporal modeling. Finally, we show how these representations can drive action-conditioned world models, achieving a 97% planning success rate on the Two Rooms navigation task. Comprehensive ablations reveal the critical importance of each regularization component for preventing representation collapse. Code is available at https://github.com/facebookresearch/eb_jepa.

</details>


### [89] [KTV: Keyframes and Key Tokens Selection for Efficient Training-Free Video LLMs](https://arxiv.org/abs/2602.03615)
*Baiyang Song,Jun Peng,Yuxin Zhang,Guangyao Chen,Feidiao Yang,Jianyuan Guo*

Main category: cs.CV

TL;DR: KTV是一个新颖的两阶段训练无关视频理解框架，通过聚类选择关键帧和剪枝冗余视觉token，显著减少计算开销同时提升视频理解性能


<details>
  <summary>Details</summary>
Motivation: 现有基于预训练视觉语言模型的训练无关视频理解方法存在严重的视觉冗余和计算开销问题，特别是CLIP相似性关键帧选择策略容易产生偏差并忽略关键帧

Method: 两阶段框架：1) 基于聚类的与问题无关关键帧选择，获得紧凑、多样且具有代表性的帧子集；2) 基于token重要性和冗余度的关键视觉token选择，减少输入LLM的token数量

Result: 在Multiple-Choice VideoQA任务上超越最先进的训练无关基线，仅用504个视觉token处理60分钟视频（10800帧），在MLVU-Test基准上达到44.8%准确率，部分基准上甚至超过训练方法

Conclusion: KTV通过有效缓解视觉冗余和计算开销问题，为训练无关视频理解提供了高效且有效的解决方案，在性能和效率之间取得了良好平衡

Abstract: Training-free video understanding leverages the strong image comprehension capabilities of pre-trained vision language models (VLMs) by treating a video as a sequence of static frames, thus obviating the need for costly video-specific training. However, this paradigm often suffers from severe visual redundancy and high computational overhead, especially when processing long videos. Crucially, existing keyframe selection strategies, especially those based on CLIP similarity, are prone to biases and may inadvertently overlook critical frames, resulting in suboptimal video comprehension. To address these significant challenges, we propose \textbf{KTV}, a novel two-stage framework for efficient and effective training-free video understanding. In the first stage, KTV performs question-agnostic keyframe selection by clustering frame-level visual features, yielding a compact, diverse, and representative subset of frames that mitigates temporal redundancy. In the second stage, KTV applies key visual token selection, pruning redundant or less informative tokens from each selected keyframe based on token importance and redundancy, which significantly reduces the number of tokens fed into the LLM. Extensive experiments on the Multiple-Choice VideoQA task demonstrate that KTV outperforms state-of-the-art training-free baselines while using significantly fewer visual tokens, \emph{e.g.}, only 504 visual tokens for a 60-min video with 10800 frames, achieving $44.8\%$ accuracy on the MLVU-Test benchmark. In particular, KTV also exceeds several training-based approaches on certain benchmarks.

</details>


### [90] [Quasi-multimodal-based pathophysiological feature learning for retinal disease diagnosis](https://arxiv.org/abs/2602.03622)
*Lu Zhang,Huizhen Yu,Zuowei Wang,Fu Gui,Yatu Guo,Wei Zhang,Mengyu Jia*

Main category: cs.CV

TL;DR: 提出统一框架整合多模态数据合成与融合，用于视网膜疾病分类和分级，通过合成FFA、MSI和显著性图，训练并行模型学习模态特定表征，并自适应校准特征进行信息剪裁和融合。


<details>
  <summary>Details</summary>
Motivation: 解决眼科多模态诊断中的数据异质性、潜在侵入性、配准复杂性等挑战，提高视网膜疾病筛查的准确性和效率。

Method: 合成多模态数据（FFA、MSI、显著性图），训练并行模型学习模态特定特征，在模态内和跨模态进行自适应特征校准，实现信息剪裁和灵活融合。

Result: 在两个公共数据集上，多标签分类任务F1-score达0.683、AUC达0.953，糖尿病视网膜病变分级准确率达0.842、Kappa系数达0.861，优于现有最佳方法。

Conclusion: 该工作不仅提高了视网膜疾病筛查的准确性和效率，还为各种医学成像模态的数据增强提供了可扩展框架。

Abstract: Retinal diseases spanning a broad spectrum can be effectively identified and diagnosed using complementary signals from multimodal data. However, multimodal diagnosis in ophthalmic practice is typically challenged in terms of data heterogeneity, potential invasiveness, registration complexity, and so on. As such, a unified framework that integrates multimodal data synthesis and fusion is proposed for retinal disease classification and grading. Specifically, the synthesized multimodal data incorporates fundus fluorescein angiography (FFA), multispectral imaging (MSI), and saliency maps that emphasize latent lesions as well as optic disc/cup regions. Parallel models are independently trained to learn modality-specific representations that capture cross-pathophysiological signatures. These features are then adaptively calibrated within and across modalities to perform information pruning and flexible integration according to downstream tasks. The proposed learning system is thoroughly interpreted through visualizations in both image and feature spaces. Extensive experiments on two public datasets demonstrated the superiority of our approach over state-of-the-art ones in the tasks of multi-label classification (F1-score: 0.683, AUC: 0.953) and diabetic retinopathy grading (Accuracy:0.842, Kappa: 0.861). This work not only enhances the accuracy and efficiency of retinal disease screening but also offers a scalable framework for data augmentation across various medical imaging modalities.

</details>


### [91] [Multi-Objective Optimization for Synthetic-to-Real Style Transfer](https://arxiv.org/abs/2602.03625)
*Estelle Chigot,Thomas Oberlin,Manon Huguenin,Dennis Wilson*

Main category: cs.CV

TL;DR: 使用多目标遗传算法优化合成图像到真实图像的风格转换流水线，通过平衡结构连贯性和风格相似性来缩小域差距，从而提升语义分割模型在真实图像上的性能表现。


<details>
  <summary>Details</summary>
Motivation: 语义分割需要大量像素级标注数据，合成图像虽然可提供完美标注但存在域差距问题。风格转换方法可以缩小这种差距，但传统方法在流水线选择和排序上面临巨大的组合搜索空间挑战。

Method: 采用多目标遗传算法优化风格转换操作符的流水线序列，使用基于单样本的配对图像指标进行快速评估，避免传统分布指标需要大量图像生成的限制。在GTA5到Cityscapes和ACDC数据集上进行合成到真实的域适应实验。

Result: 进化算法能够针对不同目标提出多样化的增强流水线，有效平衡结构保持和风格转换的权衡关系，在恶劣条件下的域适应任务中表现出色。

Conclusion: 将风格转换建模为序列优化问题并结合高效评估指标，为合成到真实的域适应提供了可行的进化搜索解决方案，代码已开源。

Abstract: Semantic segmentation networks require large amounts of pixel-level annotated data, which are costly to obtain for real-world images. Computer graphics engines can generate synthetic images alongside their ground-truth annotations. However, models trained on such images can perform poorly on real images due to the domain gap between real and synthetic images. Style transfer methods can reduce this difference by applying a realistic style to synthetic images. Choosing effective data transformations and their sequence is difficult due to the large combinatorial search space of style transfer operators. Using multi-objective genetic algorithms, we optimize pipelines to balance structural coherence and style similarity to target domains. We study the use of paired-image metrics on individual image samples during evolution to enable rapid pipeline evaluation, as opposed to standard distributional metrics that require the generation of many images. After optimization, we evaluate the resulting Pareto front using distributional metrics and segmentation performance. We apply this approach to standard datasets in synthetic-to-real domain adaptation: from the video game GTA5 to real image datasets Cityscapes and ACDC, focusing on adverse conditions. Results demonstrate that evolutionary algorithms can propose diverse augmentation pipelines adapted to different objectives. The contribution of this work is the formulation of style transfer as a sequencing problem suitable for evolutionary optimization and the study of efficient metrics that enable feasible search in this space. The source code is available at: https://github.com/echigot/MOOSS.

</details>


### [92] [SPWOOD: Sparse Partial Weakly-Supervised Oriented Object Detection](https://arxiv.org/abs/2602.03634)
*Wei Zhang,Xiang Liu,Ningjing Liu,Mingxin Liu,Wei Liao,Chunyan Xu,Xue Yang*

Main category: cs.CV

TL;DR: 首个稀疏部分弱监督旋转目标检测框架SPWOOD，通过稀疏弱标注数据和大量无标注数据实现高效检测，在DOTA和DIOR数据集上显著超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 遥感领域中目标分布密集、类别多样导致标注成本极高，需要减少标注需求的同时保持检测性能

Method: 1. SOS-Student模型在稀疏标注设置下分离背景与目标，从方向/尺度不敏感弱标注中学习信息；2. 基于模型多层预测的多级伪标签过滤策略；3. 确保类别平衡的稀疏分区方法

Result: 在DOTA和DIOR数据集上相比传统旋转目标检测方法获得显著性能提升

Conclusion: 该框架为大规模标注挑战提供了高性价比解决方案，通过创新性地结合稀疏弱监督学习有效降低了标注成本

Abstract: A consistent trend throughout the research of oriented object detection has been the pursuit of maintaining comparable performance with fewer and weaker annotations. This is particularly crucial in the remote sensing domain, where the dense object distribution and a wide variety of categories contribute to prohibitively high costs. Based on the supervision level, existing oriented object detection algorithms can be broadly grouped into fully supervised, semi-supervised, and weakly supervised methods. Within the scope of this work, we further categorize them to include sparsely supervised and partially weakly-supervised methods. To address the challenges of large-scale labeling, we introduce the first Sparse Partial Weakly-Supervised Oriented Object Detection framework, designed to efficiently leverage only a few sparse weakly-labeled data and plenty of unlabeled data. Our framework incorporates three key innovations: (1) We design a Sparse-annotation-Orientation-and-Scale-aware Student (SOS-Student) model to separate unlabeled objects from the background in a sparsely-labeled setting, and learn orientation and scale information from orientation-agnostic or scale-agnostic weak annotations. (2) We construct a novel Multi-level Pseudo-label Filtering strategy that leverages the distribution of model predictions, which is informed by the model's multi-layer predictions. (3) We propose a unique sparse partitioning approach, ensuring equal treatment for each category. Extensive experiments on the DOTA and DIOR datasets show that our framework achieves a significant performance gain over traditional oriented object detection methods mentioned above, offering a highly cost-effective solution. Our code is publicly available at https://github.com/VisionXLab/SPWOOD.

</details>


### [93] [MM-SCALE: Grounded Multimodal Moral Reasoning via Scalar Judgment and Listwise Alignment](https://arxiv.org/abs/2602.03665)
*Eunkyu Park,Wesley Hanwen Deng,Cheyon Jin,Matheus Kunzler Maldaner,Jordan Wheeler,Jason I. Hong,Hong Shen,Adam Perer,Ken Holstein,Motahhare Eslami,Gunhee Kim*

Main category: cs.CV

TL;DR: MM-SCALE是一个大规模多模态道德对齐数据集，通过5点标量评分和显式模态标注来提升视觉语言模型在道德判断任务中的表现，相比传统二元监督能提供更丰富的对齐信号和更精细的道德推理校准。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在多模态和社会模糊情境下的道德判断能力不足，传统二元或成对监督无法捕捉人类道德推理的连续性和多元性特征。

Method: 构建包含图像-场景对的大规模数据集，每个样本通过定制界面进行人工标注，包括道德可接受性分数和显式模态推理标签，支持基于排序场景集的列表式偏好优化。

Result: 实验表明，在MM-SCALE上微调的视觉语言模型相比二元信号训练的模型，在排序保真度和安全校准稳定性方面表现更优。

Conclusion: 从离散监督转向标量监督的框架能为多模态道德推理提供更丰富的对齐信号和更精细的校准，提升模型在复杂道德判断任务中的性能。

Abstract: Vision-Language Models (VLMs) continue to struggle to make morally salient judgments in multimodal and socially ambiguous contexts. Prior works typically rely on binary or pairwise supervision, which often fail to capture the continuous and pluralistic nature of human moral reasoning. We present MM-SCALE (Multimodal Moral Scale), a large-scale dataset for aligning VLMs with human moral preferences through 5-point scalar ratings and explicit modality grounding. Each image-scenario pair is annotated with moral acceptability scores and grounded reasoning labels by humans using an interface we tailored for data collection, enabling listwise preference optimization over ranked scenario sets. By moving from discrete to scalar supervision, our framework provides richer alignment signals and finer calibration of multimodal moral reasoning. Experiments show that VLMs fine-tuned on MM-SCALE achieve higher ranking fidelity and more stable safety calibration than those trained with binary signals.

</details>


### [94] [Efficient Sequential Neural Network with Spatial-Temporal Attention and Linear LSTM for Robust Lane Detection Using Multi-Frame Images](https://arxiv.org/abs/2602.03669)
*Sandeep Patil,Yongqi Dong,Haneen Farah,Hans Hellendoorn*

Main category: cs.CV

TL;DR: 提出了一种基于时空注意力机制的顺序神经网络模型，用于车道线检测，在准确性和计算效率方面优于现有方法


<details>
  <summary>Details</summary>
Motivation: 当前车道检测方法缺乏准确性、鲁棒性和实时性的平衡，特别是在混合交通环境和挑战性场景中，视觉方法常忽略关键图像区域和时空相关性

Method: 基于标准编码器-解码器结构和常见神经网络骨干，构建了带有时空注意力机制的序列神经网络模型，专注于车道线关键特征并利用连续图像帧间的时空相关性

Result: 在三个大规模开源数据集上的实验表明，该模型在各种测试场景中优于最先进方法，参数量和MAC运算量更少，计算效率更高

Conclusion: 该时空注意力机制的顺序神经网络模型为车道检测提供了准确、鲁棒且计算高效的解决方案，特别适用于自动驾驶和高级驾驶辅助系统的实际应用

Abstract: Lane detection is a crucial perception task for all levels of automated vehicles (AVs) and Advanced Driver Assistance Systems, particularly in mixed-traffic environments where AVs must interact with human-driven vehicles (HDVs) and challenging traffic scenarios. Current methods lack versatility in delivering accurate, robust, and real-time compatible lane detection, especially vision-based methods often neglect critical regions of the image and their spatial-temporal (ST) salience, leading to poor performance in difficult circumstances such as serious occlusion and dazzle lighting. This study introduces a novel sequential neural network model with a spatial-temporal attention mechanism to focus on key features of lane lines and exploit salient ST correlations among continuous image frames. The proposed model, built on a standard encoder-decoder structure and common neural network backbones, is trained and evaluated on three large-scale open-source datasets. Extensive experiments demonstrate the strength and robustness of the proposed model, outperforming state-of-the-art methods in various testing scenarios. Furthermore, with the ST attention mechanism, the developed sequential neural network models exhibit fewer parameters and reduced Multiply-Accumulate Operations (MACs) compared to baseline sequential models, highlighting their computational efficiency. Relevant data, code, and models are released at https://doi.org/10.4121/4619cab6-ae4a-40d5-af77-582a77f3d821.

</details>


### [95] [Referring Industrial Anomaly Segmentation](https://arxiv.org/abs/2602.03673)
*Pengfei Yue,Xiaokang Jiang,Yilin Lu,Jianghang Lin,Shengchuan Zhang,Liujuan Cao*

Main category: cs.CV

TL;DR: RIAS提出了一种基于语言引导的工业异常检测新范式，通过文本描述生成精确异常分割掩码，无需人工阈值，使用单一模型检测多种异常类型。


<details>
  <summary>Details</summary>
Motivation: 传统工业异常检测方法面临无监督方法需要人工阈值、监督方法数据稀缺且不平衡的问题，都存在'一类异常一个模型'的限制。

Method: 提出RIAS框架，包含MVTec-Ref数据集和DQFormer基准模型。DQFormer采用双查询令牌（异常和背景）和语言门控多级聚合机制，实现高效的视觉-文本融合。

Result: 实验证明RIAS在工业异常检测中有效，推动该领域向开放集能力发展。MVTec-Ref数据集包含95%的小异常和多样化参考表达。

Conclusion: RIAS通过语言引导的范式解决了传统工业异常检测的局限性，实现了无需人工阈值、单一模型检测多种异常的能力，为开放集异常检测提供了新方向。

Abstract: Industrial Anomaly Detection (IAD) is vital for manufacturing, yet traditional methods face significant challenges: unsupervised approaches yield rough localizations requiring manual thresholds, while supervised methods overfit due to scarce, imbalanced data. Both suffer from the "One Anomaly Class, One Model" limitation. To address this, we propose Referring Industrial Anomaly Segmentation (RIAS), a paradigm leveraging language to guide detection. RIAS generates precise masks from text descriptions without manual thresholds and uses universal prompts to detect diverse anomalies with a single model. We introduce the MVTec-Ref dataset to support this, designed with diverse referring expressions and focusing on anomaly patterns, notably with 95% small anomalies. We also propose the Dual Query Token with Mask Group Transformer (DQFormer) benchmark, enhanced by Language-Gated Multi-Level Aggregation (LMA) to improve multi-scale segmentation. Unlike traditional methods using redundant queries, DQFormer employs only "Anomaly" and "Background" tokens for efficient visual-textual integration. Experiments demonstrate RIAS's effectiveness in advancing IAD toward open-set capabilities. Code: https://github.com/swagger-coder/RIAS-MVTec-Ref.

</details>


### [96] [RegionReasoner: Region-Grounded Multi-Round Visual Reasoning](https://arxiv.org/abs/2602.03733)
*Wenfang Sun,Hao Chen,Yingjun Du,Yefeng Zheng,Cees G. M. Snoek*

Main category: cs.CV

TL;DR: 提出了RegionReasoner强化学习框架和RegionDial-Bench基准测试，通过多轮视觉推理和显式区域引用机制，显著提升了视觉语言模型在检测和分割任务中的推理准确性和空间定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型主要依赖单步或纯文本推理，缺乏在多轮视觉上下文中迭代精炼理解的能力，限制了复杂视觉推理任务的性能。

Method: 提出RegionReasoner强化学习框架：1）要求每个推理轨迹显式引用对应的参考边界框；2）通过全局-局部一致性奖励保持语义连贯性；3）结合定位保真度和语义对齐的结构化奖励进行优化。

Result: 在检测和分割任务上的实验表明，RegionReasoner-7B模型显著提高了多轮推理准确性、空间定位精度和全局-局部一致性，为新兴研究方向建立了强基线。

Conclusion: RegionReasoner框架通过强化学习和显式区域引用机制，有效解决了多轮视觉推理中的迭代精炼问题，为视觉语言模型的推理能力提升提供了新的解决方案。

Abstract: Large vision-language models have achieved remarkable progress in visual reasoning, yet most existing systems rely on single-step or text-only reasoning, limiting their ability to iteratively refine understanding across multiple visual contexts. To address this limitation, we introduce a new multi-round visual reasoning benchmark with training and test sets spanning both detection and segmentation tasks, enabling systematic evaluation under iterative reasoning scenarios. We further propose RegionReasoner, a reinforcement learning framework that enforces grounded reasoning by requiring each reasoning trace to explicitly cite the corresponding reference bounding boxes, while maintaining semantic coherence via a global-local consistency reward. This reward extracts key objects and nouns from both global scene captions and region-level captions, aligning them with the reasoning trace to ensure consistency across reasoning steps. RegionReasoner is optimized with structured rewards combining grounding fidelity and global-local semantic alignment. Experiments on detection and segmentation tasks show that RegionReasoner-7B, together with our newly introduced benchmark RegionDial-Bench, considerably improves multi-round reasoning accuracy, spatial grounding precision, and global-local consistency, establishing a strong baseline for this emerging research direction.

</details>


### [97] [Edge-Optimized Vision-Language Models for Underground Infrastructure Assessment](https://arxiv.org/abs/2602.03742)
*Johny J. Lopez,Md Meftahul Ferdaus,Mahdi Abdelguerfi*

Main category: cs.CV

TL;DR: 提出一个两阶段边缘计算管道，结合轻量级RAPID-SCAN分割模型和微调Phi-3.5视觉语言模型，实现地下基础设施缺陷的端到端自动摘要生成。


<details>
  <summary>Details</summary>
Motivation: 地下基础设施自动巡检中，虽然视觉传感器能检测结构缺陷，但在资源受限的边缘设备上自动生成人类可读的摘要仍具挑战性。

Method: 第一阶段使用0.64M参数的RAPID-SCAN模型进行高效缺陷分割（F1-score 0.834）；第二阶段使用微调Phi-3.5 VLM从分割结果生成自然语言摘要；采用后训练量化和硬件优化实现实时性能。

Result: 在移动机器人平台上成功部署完整管道，显著减少模型大小和推理延迟，同时保持摘要质量，证明在真实巡检场景中的有效性。

Conclusion: 边缘可部署的集成AI系统能够弥合自动缺陷检测与可操作维护洞察之间的差距，为更可扩展和自主的巡检解决方案铺平道路。

Abstract: Autonomous inspection of underground infrastructure, such as sewer and culvert systems, is critical to public safety and urban sustainability. Although robotic platforms equipped with visual sensors can efficiently detect structural deficiencies, the automated generation of human-readable summaries from these detections remains a significant challenge, especially on resource-constrained edge devices. This paper presents a novel two-stage pipeline for end-to-end summarization of underground deficiencies, combining our lightweight RAPID-SCAN segmentation model with a fine-tuned Vision-Language Model (VLM) deployed on an edge computing platform. The first stage employs RAPID-SCAN (Resource-Aware Pipeline Inspection and Defect Segmentation using Compact Adaptive Network), achieving 0.834 F1-score with only 0.64M parameters for efficient defect segmentation. The second stage utilizes a fine-tuned Phi-3.5 VLM that generates concise, domain-specific summaries in natural language from the segmentation outputs. We introduce a curated dataset of inspection images with manually verified descriptions for VLM fine-tuning and evaluation. To enable real-time performance, we employ post-training quantization with hardware-specific optimization, achieving significant reductions in model size and inference latency without compromising summarization quality. We deploy and evaluate our complete pipeline on a mobile robotic platform, demonstrating its effectiveness in real-world inspection scenarios. Our results show the potential of edge-deployable integrated AI systems to bridge the gap between automated defect detection and actionable insights for infrastructure maintenance, paving the way for more scalable and autonomous inspection solutions.

</details>


### [98] [LIVE: Long-horizon Interactive Video World Modeling](https://arxiv.org/abs/2602.03747)
*Junchao Huang,Ziyang Ye,Xinting Hu,Tianyu He,Guiyu Zhang,Shaoshuai Shi,Jiang Bian,Li Jiang*

Main category: cs.CV

TL;DR: LIVE提出了一种通过循环一致性目标约束误差累积的长时域视频世界模型，无需教师蒸馏，在长时域基准测试中实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 自回归视频世界模型在短时域预测有效，但在长时域生成中因误差累积而表现不佳。现有方法需要预训练教师模型和序列级分布匹配，计算成本高且无法阻止训练时域外的误差传播。

Method: 提出LIVE模型：1）通过前向rollout从真实帧生成未来序列；2）应用反向生成过程重建初始状态；3）在重建的终止状态计算扩散损失，显式约束长时域误差传播；4）引入渐进式训练课程稳定训练。

Result: 实验表明LIVE在长时域基准测试中达到最先进性能，能够生成超出训练rollout长度的稳定、高质量视频。

Conclusion: LIVE通过循环一致性目标有效约束误差累积，无需教师蒸馏即可实现优异的长时域视频生成性能，为视频世界模型提供了新的训练范式。

Abstract: Autoregressive video world models predict future visual observations conditioned on actions. While effective over short horizons, these models often struggle with long-horizon generation, as small prediction errors accumulate over time. Prior methods alleviate this by introducing pre-trained teacher models and sequence-level distribution matching, which incur additional computational cost and fail to prevent error propagation beyond the training horizon. In this work, we propose LIVE, a Long-horizon Interactive Video world modEl that enforces bounded error accumulation via a novel cycle-consistency objective, thereby eliminating the need for teacher-based distillation. Specifically, LIVE first performs a forward rollout from ground-truth frames and then applies a reverse generation process to reconstruct the initial state. The diffusion loss is subsequently computed on the reconstructed terminal state, providing an explicit constraint on long-horizon error propagation. Moreover, we provide an unified view that encompasses different approaches and introduce progressive training curriculum to stabilize training. Experiments demonstrate that LIVE achieves state-of-the-art performance on long-horizon benchmarks, generating stable, high-quality videos far beyond training rollout lengths.

</details>


### [99] [See-through: Single-image Layer Decomposition for Anime Characters](https://arxiv.org/abs/2602.03749)
*Jian Lin,Chengze Li,Haoyun Qin,Kwun Wang Chan,Yanghua Jin,Hanyuan Liu,Stephen Chun Wang Choy,Xueting Liu*

Main category: cs.CV

TL;DR: 提出一个自动化框架，将静态动漫插画转换为可操控的2.5D模型，通过单图像分解为语义分层的修复图层，结合扩散模型和深度推断技术解决复杂分层问题。


<details>
  <summary>Details</summary>
Motivation: 当前专业工作流程需要繁琐的手动分割和遮挡区域的艺术性"幻觉"处理才能实现动画效果，需要自动化解决方案。

Method: 使用可扩展引擎从商业Live2D模型获取高质量监督数据，结合基于扩散的身体部位一致性模块和像素级伪深度推断机制，实现全局几何一致性和复杂分层解析。

Result: 能够生成高质量、可操控的2.5D模型，适用于专业的实时动画应用，成功解决了动漫角色复杂分层（如交错发丝）的动态层重建问题。

Conclusion: 该方法通过自动化流程有效解决了动漫图像到可动画模型的转换难题，为专业动画制作提供了高效的技术解决方案。

Abstract: We introduce a framework that automates the transformation of static anime illustrations into manipulatable 2.5D models. Current professional workflows require tedious manual segmentation and the artistic ``hallucination'' of occluded regions to enable motion. Our approach overcomes this by decomposing a single image into fully inpainted, semantically distinct layers with inferred drawing orders. To address the scarcity of training data, we introduce a scalable engine that bootstraps high-quality supervision from commercial Live2D models, capturing pixel-perfect semantics and hidden geometry. Our methodology couples a diffusion-based Body Part Consistency Module, which enforces global geometric coherence, with a pixel-level pseudo-depth inference mechanism. This combination resolves the intricate stratification of anime characters, e.g., interleaving hair strands, allowing for dynamic layer reconstruction. We demonstrate that our approach yields high-fidelity, manipulatable models suitable for professional, real-time animation applications.

</details>


### [100] [Zero-shot large vision-language model prompting for automated bone identification in paleoradiology x-ray archives](https://arxiv.org/abs/2602.03750)
*Owen Dong,Lily Gao,Manish Kota,Bennett A. Landmana,Jelena Bekvalac,Gaynor Western,Katherine D. Van Schaik*

Main category: cs.CV

TL;DR: 利用大型视觉语言模型进行零样本提示，自动识别古放射学图像中的主要骨骼、投影视角和侧向性，准确率分别达到92%、80%和100%，显著提升古人类学工作流程的效率。


<details>
  <summary>Details</summary>
Motivation: 古放射学研究中，野外采集的X光图像存在异质性高、定位随意、缺乏侧向标记等问题，导致图像内容导航和筛选效率低下，成为专家分析的瓶颈。

Method: 提出零样本提示策略，将原始DICOM文件转换为骨窗PNG图像，使用精心设计的提示词提交给大型视觉语言模型，接收结构化JSON输出并整理到电子表格中进行验证。

Result: 在专家评审的100张随机样本图像中，系统实现了主要骨骼92%的准确率、投影视角80%的准确率和侧向性100%的准确率，对模糊病例提供低或中置信度标记。

Conclusion: 大型视觉语言模型能够显著加速大型古放射学数据集的编码词开发，为未来人类学研究工作流程提供高效的内容导航能力。

Abstract: Paleoradiology, the use of modern imaging technologies to study archaeological and anthropological remains, offers new windows on millennial scale patterns of human health. Unfortunately, the radiographs collected during field campaigns are heterogeneous: bones are disarticulated, positioning is ad hoc, and laterality markers are often absent. Additionally, factors such as age at death, age of bone, sex, and imaging equipment introduce high variability. Thus, content navigation, such as identifying a subset of images with a specific projection view, can be time consuming and difficult, making efficient triaging a bottleneck for expert analysis. We report a zero shot prompting strategy that leverages a state of the art Large Vision Language Model (LVLM) to automatically identify the main bone, projection view, and laterality in such images. Our pipeline converts raw DICOM files to bone windowed PNGs, submits them to the LVLM with a carefully engineered prompt, and receives structured JSON outputs, which are extracted and formatted onto a spreadsheet in preparation for validation. On a random sample of 100 images reviewed by an expert board certified paleoradiologist, the system achieved 92% main bone accuracy, 80% projection view accuracy, and 100% laterality accuracy, with low or medium confidence flags for ambiguous cases. These results suggest that LVLMs can substantially accelerate code word development for large paleoradiology datasets, allowing for efficient content navigation in future anthropology workflows.

</details>


### [101] [Test-Time Conditioning with Representation-Aligned Visual Features](https://arxiv.org/abs/2602.03753)
*Nicolas Sereyjol-Garros,Ellington Kirby,Victor Letzelter,Victor Besnier,Nermin Samet*

Main category: cs.CV

TL;DR: REPA-G是一种在推理时利用自监督模型的对齐表示进行条件控制的扩散模型引导框架，通过优化相似性目标实现多尺度语义控制


<details>
  <summary>Details</summary>
Motivation: 虽然表示对齐在扩散模型训练中已显示出优势，但其在推理时条件控制的潜力尚未充分探索，需要替代模糊文本提示或粗糙类别标签的更灵活精确方法

Method: 在推理时通过优化预训练特征提取器提取的条件表示与生成特征之间的相似性目标，引导去噪过程，支持从单个补丁的细粒度纹理匹配到全局图像特征的语义引导

Result: 在ImageNet和COCO数据集上实现了高质量、多样化的生成效果，支持多概念组合，理论证明了该方法能够从势能诱导的倾斜分布中采样

Conclusion: REPA-G提供了一个完全在推理时操作的灵活框架，为扩散模型提供了比文本提示或类别标签更精确的条件控制方法

Abstract: While representation alignment with self-supervised models has been shown to improve diffusion model training, its potential for enhancing inference-time conditioning remains largely unexplored. We introduce Representation-Aligned Guidance (REPA-G), a framework that leverages these aligned representations, with rich semantic properties, to enable test-time conditioning from features in generation. By optimizing a similarity objective (the potential) at inference, we steer the denoising process toward a conditioned representation extracted from a pre-trained feature extractor. Our method provides versatile control at multiple scales, ranging from fine-grained texture matching via single patches to broad semantic guidance using global image feature tokens. We further extend this to multi-concept composition, allowing for the faithful combination of distinct concepts. REPA-G operates entirely at inference time, offering a flexible and precise alternative to often ambiguous text prompts or coarse class labels. We theoretically justify how this guidance enables sampling from the potential-induced tilted distribution. Quantitative results on ImageNet and COCO demonstrate that our approach achieves high-quality, diverse generations. Code is available at https://github.com/valeoai/REPA-G.

</details>


### [102] [RAWDet-7: A Multi-Scenario Benchmark for Object Detection and Description on Quantized RAW Images](https://arxiv.org/abs/2602.03760)
*Mishal Fatima,Shashank Agnihotri,Kanchana Vaishnavi Gandikota,Michael Moeller,Margret Keuper*

Main category: cs.CV

TL;DR: RAWDet-7是一个大规模RAW图像数据集，包含约25K训练和7.6K测试图像，支持在4位、6位和8位量化条件下评估目标检测和描述任务，旨在研究RAW图像处理中信息保留和机器推理性能。


<details>
  <summary>Details</summary>
Motivation: 传统视觉模型使用针对人类感知优化的ISP处理RGB图像，会丢弃传感器级别的有用信息。RAW图像保留未处理的场景数据，能够为机器推理提供更丰富的线索，捕捉处理图像中常丢失的细粒度细节、空间关系和上下文信息。

Method: 构建RAWDet-7数据集，包含多样相机、光照条件和环境下的RAW图像，按照MS-COCO和LVIS标准对7个目标类别进行密集标注，并提供从相应高分辨率sRGB图像派生的目标级描述。支持模拟4位、6位和8位量化评估。

Result: 提供了大规模RAW图像基准数据集，支持目标检测性能、描述质量和细节以及低比特RAW图像处理中的泛化能力研究。数据集包含丰富的标注信息和量化模拟条件。

Conclusion: RAWDet-7数据集为研究RAW图像处理中的信息保留和机器推理性能提供了重要资源，特别是在低比特量化约束下，有助于推动基于传感器原始数据的计算机视觉模型发展。

Abstract: Most vision models are trained on RGB images processed through ISP pipelines optimized for human perception, which can discard sensor-level information useful for machine reasoning. RAW images preserve unprocessed scene data, enabling models to leverage richer cues for both object detection and object description, capturing fine-grained details, spatial relationships, and contextual information often lost in processed images. To support research in this domain, we introduce RAWDet-7, a large-scale dataset of ~25k training and 7.6k test RAW images collected across diverse cameras, lighting conditions, and environments, densely annotated for seven object categories following MS-COCO and LVIS conventions. In addition, we provide object-level descriptions derived from the corresponding high-resolution sRGB images, facilitating the study of object-level information preservation under RAW image processing and low-bit quantization. The dataset allows evaluation under simulated 4-bit, 6-bit, and 8-bit quantization, reflecting realistic sensor constraints, and provides a benchmark for studying detection performance, description quality & detail, and generalization in low-bit RAW image processing. Dataset & code upon acceptance.

</details>


### [103] [FOVI: A biologically-inspired foveated interface for deep vision models](https://arxiv.org/abs/2602.03766)
*Nicholas M. Blauch,George A. Alvarez,Talia Konkle*

Main category: cs.CV

TL;DR: 提出基于人眼视网膜和初级视觉皮层的注视点视觉接口(FOVI)，通过k近邻卷积处理变分辨率视觉输入，显著降低计算成本的同时保持竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 人类视觉具有注视点特性，中心高分辨率而周边低分辨率，这种变分辨率机制在主动感知中效率很高。相比之下，大多数计算机视觉系统使用均匀分辨率处理，处理全视野高分辨率图像时效率低下。

Method: 基于视网膜和V1皮层设计FOVI接口，将变分辨率视网膜式传感器阵列重新格式化为均匀密集的V1式传感器流形。使用k近邻(kNN)定义感受野，通过新颖的核映射技术实现kNN卷积。开发了端到端kNN卷积架构和对DINOv3 ViT模型的注视点适配版本。

Result: 所提模型在计算成本仅为非注视点基线的一小部分的情况下，提供了竞争性的性能表现。代码和预训练模型已开源。

Conclusion: FOVI为高分辨率自我中心视觉提供了高效且可扩展的主动感知途径，通过模仿人类视觉系统的注视点特性实现了计算效率的显著提升。

Abstract: Human vision is foveated, with variable resolution peaking at the center of a large field of view; this reflects an efficient trade-off for active sensing, allowing eye-movements to bring different parts of the world into focus with other parts of the world in context. In contrast, most computer vision systems encode the visual world at a uniform resolution, raising challenges for processing full-field high-resolution images efficiently. We propose a foveated vision interface (FOVI) based on the human retina and primary visual cortex, that reformats a variable-resolution retina-like sensor array into a uniformly dense, V1-like sensor manifold. Receptive fields are defined as k-nearest-neighborhoods (kNNs) on the sensor manifold, enabling kNN-convolution via a novel kernel mapping technique. We demonstrate two use cases: (1) an end-to-end kNN-convolutional architecture, and (2) a foveated adaptation of the foundational DINOv3 ViT model, leveraging low-rank adaptation (LoRA). These models provide competitive performance at a fraction of the computational cost of non-foveated baselines, opening pathways for efficient and scalable active sensing for high-resolution egocentric vision. Code and pre-trained models are available at https://github.com/nblauch/fovi and https://huggingface.co/fovi-pytorch.

</details>


### [104] [QVLA: Not All Channels Are Equal in Vision-Language-Action Model's Quantization](https://arxiv.org/abs/2602.03782)
*Yuhao Xu,Yantai Yang,Zhenyang Fan,Yufan Liu,Yuming Li,Bing Li,Zhipeng Zhang*

Main category: cs.CV

TL;DR: QVLA是一个专门为具身控制设计的动作中心量化框架，通过通道级比特分配策略和动作空间敏感度分析，实现了VLA模型的高效压缩，在保持98.9%性能的同时减少71%显存使用。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型计算需求巨大，难以在资源受限的机器人平台上部署。直接从LLM继承的均匀比特量化方法不适用于机器人控制，因为微小动作偏差会累积成灾难性任务失败。

Method: 提出QVLA框架，采用通道级比特分配策略，通过直接测量每个通道在不同比特宽度量化时对最终动作空间的敏感度，生成精确的通道重要性指标，统一量化和剪枝到单一框架中。

Result: 在LIBERO基准测试中，OpenVLA-OFT量化版本仅需原模型29.2%的VRAM，保持98.9%性能，速度提升1.49倍，相比SmoothQuant方法性能提升22.6%。

Conclusion: QVLA为机器人VLA模型压缩建立了新的原则性基础，为在现实硬件上部署大规模模型铺平了道路。

Abstract: The advent of Vision-Language-Action (VLA) models represents a significant leap for embodied intelligence, yet their immense computational demands critically hinder deployment on resource-constrained robotic platforms. Intuitively, low-bit quantization is a prevalent and preferred technique for large-scale model compression. However, we find that a systematic analysis of VLA model's quantization is fundamentally lacking. We argue that naively applying uniform-bit quantization from Large Language Models (LLMs) to robotics is flawed, as these methods prioritize passive data fidelity while ignoring how minor action deviations compound into catastrophic task failures. To bridge this gap, we introduce QVLA, the first action-centric quantization framework specifically designed for embodied control. In a sharp departure from the rigid, uniform-bit quantization of LLM-based methods, QVLA introduces a highly granular, channel-wise bit allocation strategy. Its core mechanism is to directly measure the final action-space sensitivity when quantizing each individual channel to various bit-widths. This process yields a precise, per-channel importance metric that guides a global optimization, which elegantly unifies quantization and pruning (0-bit) into a single, cohesive framework. Extensive evaluations on different baselines demonstrate the superiority of our approach. In the LIBERO, the quantization version of OpenVLA-OFT with our method requires only 29.2% of the original model's VRAM while maintaining 98.9% of its original performance and achieving a 1.49x speedup. This translates to a 22.6% performance improvement over the LLM-derived method SmoothQuant. Our work establishes a new, principled foundation for compressing VLA models in robotics, paving the way for deploying powerful, large-scale models on real-world hardware. Code will be released.

</details>


### [105] [From Pre- to Intra-operative MRI: Predicting Brain Shift in Temporal Lobe Resection for Epilepsy Surgery](https://arxiv.org/abs/2602.03785)
*Jingjing Peng,Giorgio Fiore,Yang Liu,Ksenia Ellum,Debayan Daspupta,Keyoumars Ashkan,Andrew McEvoy,Anna Miserocchi,Sebastien Ourselin,John Duncan,Alejandro Granados*

Main category: cs.CV

TL;DR: NeuralShift是一个基于U-Net的模型，仅使用术前MRI预测颞叶切除术中的脑移位，实现了0.97的DICE分数和1.12mm的靶点配准误差，为神经外科手术提供精准的脑移位补偿。


<details>
  <summary>Details</summary>
Motivation: 神经外科图像引导系统依赖术前MRI，但硬脑膜打开后发生的脑移位会使术前MRI失效，需要术中MRI更新来补偿脑移位以提高手术精度。

Method: 提出基于U-Net的NeuralShift模型，从术前MRI预测颞叶切除术中的脑移位，使用解剖标志点的靶点配准误差(TREs)和预测掩模与术中MRI掩模的DICE分数进行评估。

Result: 模型能够准确预测大脑全局变形(DICE 0.97)和局部位移(TRE低至1.12mm)，有效补偿颞叶切除手术中的大范围脑移位。

Conclusion: 该模型仅使用术前图像即可预测颞叶切除术中的脑变形，为提高神经外科手术安全性和效率提供了潜在机会，代码将在接受后公开。

Abstract: Introduction: In neurosurgery, image-guided Neurosurgery Systems (IGNS) highly rely on preoperative brain magnetic resonance images (MRI) to assist surgeons in locating surgical targets and determining surgical paths. However, brain shift invalidates the preoperative MRI after dural opening. Updated intraoperative brain MRI with brain shift compensation is crucial for enhancing the precision of neuronavigation systems and ensuring the optimal outcome of surgical interventions. Methodology: We propose NeuralShift, a U-Net-based model that predicts brain shift entirely from pre-operative MRI for patients undergoing temporal lobe resection. We evaluated our results using Target Registration Errors (TREs) computed on anatomical landmarks located on the resection side and along the midline, and DICE scores comparing predicted intraoperative masks with masks derived from intraoperative MRI. Results: Our experimental results show that our model can predict the global deformation of the brain (DICE of 0.97) with accurate local displacements (achieve landmark TRE as low as 1.12 mm), compensating for large brain shifts during temporal lobe removal neurosurgery. Conclusion: Our proposed model is capable of predicting the global deformation of the brain during temporal lobe resection using only preoperative images, providing potential opportunities to the surgical team to increase safety and efficiency of neurosurgery and better outcomes to patients. Our contributions will be publicly available after acceptance in https://github.com/SurgicalDataScienceKCL/NeuralShift.

</details>


### [106] [3D-Aware Implicit Motion Control for View-Adaptive Human Video Generation](https://arxiv.org/abs/2602.03796)
*Zhixue Fang,Xu He,Songlin Tang,Haoxian Zhang,Qingfeng Li,Xiaoqiang Liu,Pengfei Wan,Kun Gai*

Main category: cs.CV

TL;DR: 3DiMo提出了一种隐式、视角无关的3D运动表示方法，通过联合训练运动编码器与预训练视频生成器，将驱动帧压缩为紧凑的运动token，实现高质量的视频运动控制和新视角合成。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖2D姿态或显式3D参数模型存在局限性：2D姿态将运动绑定到特定视角，无法进行新视角合成；显式3D模型存在深度模糊和动态不准确等问题，会覆盖大规模视频生成器固有的3D感知能力。

Method: 提出3DiMo框架：1）联合训练运动编码器与预训练视频生成器；2）使用交叉注意力语义注入视角无关的运动token；3）采用多视角监督（单视角、多视角、移动相机视频）增强3D感知；4）使用SMPL进行早期几何监督并逐渐退火至零。

Result: 实验证明3DiMo能够忠实再现驱动运动并实现灵活的文本驱动相机控制，在运动保真度和视觉质量方面显著超越现有方法。

Conclusion: 隐式3D运动表示比显式3D约束更有效，能够更好地与生成器的空间先验对齐，实现高质量的运动控制和视角合成。

Abstract: Existing methods for human motion control in video generation typically rely on either 2D poses or explicit 3D parametric models (e.g., SMPL) as control signals. However, 2D poses rigidly bind motion to the driving viewpoint, precluding novel-view synthesis. Explicit 3D models, though structurally informative, suffer from inherent inaccuracies (e.g., depth ambiguity and inaccurate dynamics) which, when used as a strong constraint, override the powerful intrinsic 3D awareness of large-scale video generators. In this work, we revisit motion control from a 3D-aware perspective, advocating for an implicit, view-agnostic motion representation that naturally aligns with the generator's spatial priors rather than depending on externally reconstructed constraints. We introduce 3DiMo, which jointly trains a motion encoder with a pretrained video generator to distill driving frames into compact, view-agnostic motion tokens, injected semantically via cross-attention. To foster 3D awareness, we train with view-rich supervision (i.e., single-view, multi-view, and moving-camera videos), forcing motion consistency across diverse viewpoints. Additionally, we use auxiliary geometric supervision that leverages SMPL only for early initialization and is annealed to zero, enabling the model to transition from external 3D guidance to learning genuine 3D spatial motion understanding from the data and the generator's priors. Experiments confirm that 3DiMo faithfully reproduces driving motions with flexible, text-driven camera control, significantly surpassing existing methods in both motion fidelity and visual quality.

</details>


### [107] [Progressive Checkerboards for Autoregressive Multiscale Image Generation](https://arxiv.org/abs/2602.03811)
*David Eigen*

Main category: cs.CV

TL;DR: 提出基于渐进棋盘格排序的多尺度自回归图像生成方法，通过平衡的四叉树分割实现跨尺度和尺度内有效条件建模，在保持总串行步骤数不变的情况下，使用更少采样步骤达到与最先进自回归系统相当的性能。


<details>
  <summary>Details</summary>
Motivation: 解决自回归图像生成中并行采样独立位置与串行条件建模相互依赖性的关键挑战，探索比多尺度金字塔和规则/随机分区更灵活的固定排序方法。

Method: 采用渐进棋盘格排序策略，在每个尺度上从均匀间隔区域并行采样，保持四叉树分割所有层级的完全平衡，实现跨尺度和尺度内的有效条件建模。

Result: 在类别条件ImageNet上，与模型容量相近的最先进自回归系统相比，使用更少采样步骤达到竞争性性能；发现平衡设置下，只要总串行步骤数恒定，多种尺度放大因子都能产生相似结果。

Conclusion: 渐进棋盘格排序为多尺度自回归图像生成提供了一种灵活有效的并行采样方法，在保持生成质量的同时显著减少了采样步骤，展示了平衡条件建模的重要性。

Abstract: A key challenge in autoregressive image generation is to efficiently sample independent locations in parallel, while still modeling mutual dependencies with serial conditioning. Some recent works have addressed this by conditioning between scales in a multiscale pyramid. Others have looked at parallelizing samples in a single image using regular partitions or randomized orders. In this work we examine a flexible, fixed ordering based on progressive checkerboards for multiscale autoregressive image generation. Our ordering draws samples in parallel from evenly spaced regions at each scale, maintaining full balance in all levels of a quadtree subdivision at each step. This enables effective conditioning both between and within scales. Intriguingly, we find evidence that in our balanced setting, a wide range of scale-up factors lead to similar results, so long as the total number of serial steps is constant. On class-conditional ImageNet, our method achieves competitive performance compared to recent state-of-the-art autoregressive systems with like model capacity, using fewer sampling steps.

</details>


### [108] [Fast-Slow Efficient Training for Multimodal Large Language Models via Visual Token Pruning](https://arxiv.org/abs/2602.03815)
*Dingkun Zhang,Shuhan Qi,Yulin Wu,Xinyu Xiao,Xuan Wang,Long Chen*

Main category: cs.CV

TL;DR: DualSpeed是一个快速-慢速双模式训练框架，通过视觉令牌剪枝减少训练计算量，同时保持训练-推理一致性，实现了MLLM的高效训练。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型训练效率低下，现有方法主要关注减少模型大小或可训练参数。受视觉令牌剪枝在推理效率提升的启发，研究通过减少视觉令牌来提升训练效率，但直接应用会导致训练-推理不匹配问题。

Method: 提出双模式框架：快速模式使用视觉令牌剪枝插件减少视觉令牌；慢速模式使用完整视觉序列保持训练-推理一致性；通过模式隔离器和自蒸馏技术促进模式间知识传递。

Result: 实验显示DualSpeed将LLaVA-1.5训练加速2.1倍，LLaVA-NeXT训练加速4.0倍，性能保持率超过99%。

Conclusion: DualSpeed成功解决了MLLM训练效率问题，在显著加速训练的同时保持了模型性能，为高效多模态模型训练提供了有效解决方案。

Abstract: Multimodal Large Language Models (MLLMs) suffer from severe training inefficiency issue, which is associated with their massive model sizes and visual token numbers. Existing efforts in efficient training focus on reducing model sizes or trainable parameters. Inspired by the success of Visual Token Pruning (VTP) in improving inference efficiency, we are exploring another substantial research direction for efficient training by reducing visual tokens. However, applying VTP at the training stage results in a training-inference mismatch: pruning-trained models perform poorly when inferring on non-pruned full visual token sequences. To close this gap, we propose DualSpeed, a fast-slow framework for efficient training of MLLMs. The fast-mode is the primary mode, which incorporates existing VTP methods as plugins to reduce visual tokens, along with a mode isolator to isolate the model's behaviors. The slow-mode is the auxiliary mode, where the model is trained on full visual sequences to retain training-inference consistency. To boost its training, it further leverages self-distillation to learn from the sufficiently trained fast-mode. Together, DualSpeed can achieve both training efficiency and non-degraded performance. Experiments show DualSpeed accelerates the training of LLaVA-1.5 by 2.1$\times$ and LLaVA-NeXT by 4.0$\times$, retaining over 99% performance. Code: https://github.com/dingkun-zhang/DualSpeed

</details>


### [109] [Continuous Control of Editing Models via Adaptive-Origin Guidance](https://arxiv.org/abs/2602.03826)
*Alon Wolf,Chen Katzir,Kfir Aberman,Or Patashnik*

Main category: cs.CV

TL;DR: 提出Adaptive-Origin Guidance (AdaOr)方法，通过调整扩散编辑模型中的引导原点，实现文本引导编辑强度的平滑连续控制，解决了现有方法在低引导尺度下无法实现从输入到编辑结果的平滑过渡问题。


<details>
  <summary>Details</summary>
Motivation: 现有扩散编辑模型缺乏对文本引导编辑强度的平滑控制机制，Classifier-Free Guidance (CFG)在编辑模型中无法产生从输入到编辑结果的连续过渡，因为无条件预测作为引导原点在低引导尺度下主导生成过程并代表对输入内容的任意操作。

Method: 引入AdaOr方法，使用与身份操作对应的身份指令来调整标准引导原点，通过根据编辑强度将身份预测与标准无条件预测进行插值，确保从输入到编辑结果的连续过渡。该方法将身份指令集成到标准训练框架中，无需针对每个编辑过程或依赖专门数据集。

Result: 在图像和视频编辑任务上的评估表明，相比当前基于滑块的编辑方法，AdaOr提供了更平滑和一致的控制效果。

Conclusion: AdaOr方法通过调整引导原点实现了对文本引导编辑强度的连续控制，为扩散编辑模型提供了更精细的控制能力，且无需额外的编辑过程或专门数据集支持。

Abstract: Diffusion-based editing models have emerged as a powerful tool for semantic image and video manipulation. However, existing models lack a mechanism for smoothly controlling the intensity of text-guided edits. In standard text-conditioned generation, Classifier-Free Guidance (CFG) impacts prompt adherence, suggesting it as a potential control for edit intensity in editing models. However, we show that scaling CFG in these models does not produce a smooth transition between the input and the edited result. We attribute this behavior to the unconditional prediction, which serves as the guidance origin and dominates the generation at low guidance scales, while representing an arbitrary manipulation of the input content. To enable continuous control, we introduce Adaptive-Origin Guidance (AdaOr), a method that adjusts this standard guidance origin with an identity-conditioned adaptive origin, using an identity instruction corresponding to the identity manipulation. By interpolating this identity prediction with the standard unconditional prediction according to the edit strength, we ensure a continuous transition from the input to the edited result. We evaluate our method on image and video editing tasks, demonstrating that it provides smoother and more consistent control compared to current slider-based editing approaches. Our method incorporates an identity instruction into the standard training framework, enabling fine-grained control at inference time without per-edit procedure or reliance on specialized datasets.

</details>


### [110] [EventNeuS: 3D Mesh Reconstruction from a Single Event Camera](https://arxiv.org/abs/2602.03847)
*Shreyas Sachan,Viktor Rudnev,Mohamed Elgharib,Christian Theobalt,Vladislav Golyanik*

Main category: cs.CV

TL;DR: EventNeuS：首个结合SDF和密度场学习的自监督神经模型，从单目彩色事件流实现高精度3D网格重建，显著超越现有方法


<details>
  <summary>Details</summary>
Motivation: 事件相机在3D重建精度方面存在严重局限，现有事件基于的新视角合成方法无法实现密集3D网格重建

Method: 结合3D符号距离函数和密度场学习，引入球谐编码处理视角相关效应，使用事件基于的自监督训练

Result: 在Chamfer距离上比之前最佳方法降低34%，平均绝对误差降低31%

Conclusion: EventNeuS首次成功将SDF和密度场学习与事件监督相结合，为事件相机的高精度3D重建提供了有效解决方案

Abstract: Event cameras offer a considerable alternative to RGB cameras in many scenarios. While there are recent works on event-based novel-view synthesis, dense 3D mesh reconstruction remains scarcely explored and existing event-based techniques are severely limited in their 3D reconstruction accuracy. To address this limitation, we present EventNeuS, a self-supervised neural model for learning 3D representations from monocular colour event streams. Our approach, for the first time, combines 3D signed distance function and density field learning with event-based supervision. Furthermore, we introduce spherical harmonics encodings into our model for enhanced handling of view-dependent effects. EventNeuS outperforms existing approaches by a significant margin, achieving 34% lower Chamfer distance and 31% lower mean absolute error on average compared to the best previous method.

</details>


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [111] [The Hypocrisy Gap: Quantifying Divergence Between Internal Belief and Chain-of-Thought Explanation via Sparse Autoencoders](https://arxiv.org/abs/2602.02496)
*Shikhar Shiromani,Archie Chaudhury,Sri Pranav Kunda*

Main category: cs.CL

TL;DR: 提出Hypocrisy Gap机制度量方法，使用稀疏自编码器量化大语言模型内部推理与最终生成之间的差异，有效检测模型不忠实行为。


<details>
  <summary>Details</summary>
Motivation: 大语言模型经常表现出不忠实行为，其最终答案与内部思维链推理存在显著差异以迎合用户，需要更好的检测方法。

Method: 利用稀疏自编码器和稀疏线性探针，通过数学比较内部真实信念与最终生成在潜在空间中的轨迹差异。

Result: 在Gemma、Llama和Qwen模型上实验显示，AUROC达到0.55-0.73（谄媚检测）和0.55-0.74（虚伪检测），优于基于对数概率的基线方法（0.41-0.50）。

Conclusion: Hypocrisy Gap方法能有效量化并检测大语言模型的不忠实行为，为模型可信度评估提供了新工具。

Abstract: Large Language Models (LLMs) frequently exhibit unfaithful behavior, producing a final answer that differs significantly from their internal chain of thought (CoT) reasoning in order to appease the user they are conversing with. In order to better detect this behavior, we introduce the Hypocrisy Gap, a mechanistic metric utilizing Sparse Autoencoders (SAEs) to quantify the divergence between a model's internal reasoning and its final generation. By mathematically comparing an internal truth belief, derived via sparse linear probes, to the final generated trajectory in latent space, we quantify and detect a model's tendency to engage in unfaithful behavior. Experiments on Gemma, Llama, and Qwen models using Anthropic's Sycophancy benchmark show that our method achieves an AUROC of 0.55-0.73 for detecting sycophantic runs and 0.55-0.74 for hypocritical cases where the model internally "knows" the user is wrong, consistently outperforming a decision-aligned log-probability baseline (0.41-0.50 AUROC).

</details>


### [112] [STEMVerse: A Dual-Axis Diagnostic Framework for STEM Reasoning in Large Language Models](https://arxiv.org/abs/2602.02497)
*Xuzhao Li,Xuchen Li,Jian Zhao,Shiyu Hu*

Main category: cs.CL

TL;DR: STEMVerse是一个诊断框架，通过"学科×认知"双轴标签系统分析LLM在STEM领域的推理能力，重新聚合了20,000+问题，揭示了结构性失败模式。


<details>
  <summary>Details</summary>
Motivation: 当前评估范式将基准视为孤岛，仅提供总体分数，无法区分模型错误是源于领域知识不足还是认知能力缺陷，限制了诊断价值。

Method: 提出STEMVerse框架，将20,000多个STEM问题重新聚合到统一的"学科×认知"能力空间，为每个实例分配双轴标签，系统评估不同参数规模和训练范式的代表性LLM家族。

Result: 实证结果揭示了STEM推理中的结构性失败模式，通过多学科覆盖和细粒度认知分层提供了清晰的诊断视角。

Conclusion: STEMVerse通过整合多学科覆盖和精细认知分层，为理解LLM科学推理特性提供了清晰且可操作的视角，超越了传统聚合评分的局限性。

Abstract: As Large Language Models (LLMs) achieve significant breakthroughs in complex reasoning tasks, evaluating their proficiency in science, technology, engineering, and mathematics (STEM) has become a primary method for measuring machine intelligence. However, current evaluation paradigms often treat benchmarks as isolated "silos," offering only monolithic aggregate scores that neglect the intricacies of both academic specialization and cognitive depth. This result-oriented approach fails to distinguish whether model errors stem from insufficient domain knowledge or deficiencies in cognitive capacity, thereby limiting the diagnostic value. To address this, we propose STEMVerse, a diagnostic framework designed to systematically analyze the STEM reasoning capabilities of LLMs. This framework characterizes model performance across academic specialization and cognitive complexity to map the capability required for reasoning. We re-aggregate over 20,000 STEM problems from mainstream benchmarks into a unified "Discipline $\times$ Cognition" capability space, assigning dual-axis labels to every instance. Utilizing this unified diagnostic framework, we systematically evaluate representative LLM families across varying parameter scales and training paradigms. Our empirical results reveal structural failure patterns in STEM reasoning. By integrating multi-disciplinary coverage and fine-grained cognitive stratification into a unified framework, STEMVerse provides a clear and actionable perspective for understanding the scientific reasoning characteristics of LLMs.

</details>


### [113] [Test-Time Detoxification without Training or Learning Anything](https://arxiv.org/abs/2602.02498)
*Baturay Saglam,Dionysis Kalogerias*

Main category: cs.CL

TL;DR: 提出一种基于零阶优化的黑盒文本去毒方法，通过输入嵌入的梯度近似和少量下降步骤来引导生成低毒性文本，无需模型重训练或梯度访问。


<details>
  <summary>Details</summary>
Motivation: 现有去毒方法依赖模型重训练、梯度或辅助组件，成本高且难以跨模型迁移，特别是在黑盒设置中。需要一种无需训练或中间计算访问的轻量级去毒方案。

Method: 使用零阶优化方法近似完成文本毒性对输入嵌入的梯度，通过少量下降步骤调整嵌入向量来引导生成低毒性续写。仅需输入嵌入、毒性评分函数和前向评估。

Result: 该方法在不同模型和提示下实现了稳健的毒性降低，在多数设置中达到了最佳的毒性-质量权衡效果。

Conclusion: 词嵌入可作为有效的控制变量，黑盒优化能有效引导自回归语言模型生成更安全的文本，无需训练或访问中间计算，具有可扩展性。

Abstract: Large language models can produce toxic or inappropriate text even for benign inputs, creating risks when deployed at scale. Detoxification is therefore important for safety and user trust, particularly when we want to reduce harmful content without sacrificing the model's generation quality. Many existing approaches rely on model retraining, gradients, or learned auxiliary components, which can be costly and may not transfer across model families or to truly black-box settings. We introduce a test-time procedure that approximates the gradient of completion toxicity with respect to the input embeddings and uses a small number of descent steps to steer generation toward less toxic continuations. This is achieved with zeroth-order optimization that requires only access to input embeddings, a toxicity scoring function, and forward evaluations of the model. Empirically, the approach delivers robust toxicity reductions across models and prompts and, in most settings, achieves the best overall toxicity-quality trade-off. More broadly, our work positions word embeddings as effective control variables and encourages wider use of black-box optimization to guide autoregressive language models toward scalable, safer text generation, without requiring any training or access to intermediate computations.

</details>


### [114] [ROSA-Tuning: Enhancing Long-Context Modeling via Suffix Matching](https://arxiv.org/abs/2602.02499)
*Yunao Zheng,Xiaojie Wang,Lei Ren,Wei Chen*

Main category: cs.CL

TL;DR: ROSA-Tuning通过引入CPU端的ROSA检索模块和召回机制，在保持计算效率的同时显著提升了窗口注意力模型的长上下文建模能力，性能接近全局注意力。


<details>
  <summary>Details</summary>
Motivation: 现有高效注意力方法虽然降低了计算复杂度，但存在模型状态覆盖范围有限的问题，需要解决长上下文建模能力和计算效率之间的平衡挑战。

Method: 提出并行CPU端ROSA检索模块，使用RWKV在线后缀自动机高效定位历史相关位置，通过可训练方式将检索信息注入模型状态，采用二进制离散化策略和反事实梯度算法实现端到端训练，并通过异步CPU-GPU流水线优化执行效率。

Result: 在Qwen3-Base-1.7B上的系统评估显示，ROSA-Tuning显著恢复了窗口注意力模型的长上下文建模能力，在LongBench等基准测试中性能接近甚至匹配全局注意力，同时保持与窗口注意力方法相当的计算效率和GPU内存使用。

Conclusion: ROSA-Tuning为高效长上下文处理提供了新的技术路径，通过检索-召回机制有效解决了长上下文建模与计算效率之间的矛盾。

Abstract: Long-context capability and computational efficiency are among the central challenges facing today's large language models. Existing efficient attention methods reduce computational complexity, but they typically suffer from a limited coverage of the model state. This paper proposes ROSA-Tuning, a retrieval-and-recall mechanism for enhancing the long-context modeling ability of pretrained models. Beyond the standard attention mechanism, ROSA-Tuning introduces in parallel a CPU-based ROSA (RWKV Online Suffix Automaton) retrieval module, which efficiently locates historical positions in long contexts that are relevant to the current query, and injects the retrieved information into the model state in a trainable manner; subsequent weighted fusion can then be handled by range-restricted attention. To enable end-to-end training, we design a binary discretization strategy and a counterfactual gradient algorithm, and further optimize overall execution efficiency via an asynchronous CPU-GPU pipeline. Systematic evaluations on Qwen3-Base-1.7B show that ROSA-Tuning substantially restores the long-context modeling ability of windowed-attention models, achieving performance close to and in some cases matching global attention on benchmarks such as LongBench, while maintaining computational efficiency and GPU memory usage that are nearly comparable to windowed-attention methods, offering a new technical path for efficient long-context processing. The example code can be found at https://github.com/zyaaa-ux/ROSA-Tuning.

</details>


### [115] [Graph-Augmented Reasoning with Large Language Models for Tobacco Pest and Disease Management](https://arxiv.org/abs/2602.02635)
*Siyu Li,Chenwei Song,Qi Zhou,Wan Zhou,Xinyi Liu*

Main category: cs.CL

TL;DR: 提出基于GraphRAG的图增强推理框架，将烟草病虫害领域知识图谱与大语言模型结合，通过图神经网络学习节点表示，实现证据感知的检索和生成，显著提升多跳和比较推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统文本检索方法在病虫害管理中的局限性，无法有效捕捉症状-疾病-治疗之间的复杂关系，导致LLM容易产生幻觉或不当的治疗建议。

Method: 构建领域知识图谱，使用GraphRAG检索查询相关子图，采用ChatGLM作为Transformer骨干网络并结合LoRA高效微调，利用图神经网络学习节点表示以捕获依赖关系。

Result: 实验结果显示相比纯文本基线有持续改进，在多跳和比较推理问题上获得最大性能提升，这些任务需要链接多个关系。

Conclusion: 图增强推理框架通过显式建模领域实体关系，提供了超越表层文本相似度的证据感知检索，能够生成更符合领域一致性的推荐，有效减少幻觉和不当治疗建议。

Abstract: This paper proposes a graph-augmented reasoning framework for tobacco pest and disease management that integrates structured domain knowledge into large language models. Building on GraphRAG, we construct a domain-specific knowledge graph and retrieve query-relevant subgraphs to provide relational evidence during answer generation. The framework adopts ChatGLM as the Transformer backbone with LoRA-based parameter-efficient fine-tuning, and employs a graph neural network to learn node representations that capture symptom-disease-treatment dependencies. By explicitly modeling diseases, symptoms, pesticides, and control measures as linked entities, the system supports evidence-aware retrieval beyond surface-level text similarity. Retrieved graph evidence is incorporated into the LLM input to guide generation toward domain-consistent recommendations and to mitigate hallucinated or inappropriate treatments. Experimental results show consistent improvements over text-only baselines, with the largest gains observed on multi-hop and comparative reasoning questions that require chaining multiple relations.

</details>


### [116] [WideSeek: Advancing Wide Research via Multi-Agent Scaling](https://arxiv.org/abs/2602.02636)
*Ziyang Huang,Haolin Ren,Xiaowei Yuan,Jiawei Wang,Zhongtao Jiang,Kun Xu,Shizhu He,Jun Zhao,Kang Liu*

Main category: cs.CL

TL;DR: 本文提出了WideSeekBench基准测试和WideSeek多智能体架构，用于解决从深度研究向广度研究范式转变中的信息检索挑战，通过多智能体强化学习实现并行信息搜索优化。


<details>
  <summary>Details</summary>
Motivation: 搜索智能正从深度研究向广度研究范式演进，但该领域缺乏专门的基准测试和针对搜索广度的优化方法，阻碍了研究进展。

Method: 1) 构建WideSeekBench通用广度信息搜索基准，通过多阶段数据管道确保目标信息量、逻辑约束和领域的多样性；2) 提出WideSeek动态分层多智能体架构，能根据任务需求自主分叉并行子智能体；3) 设计统一训练框架，线性化多智能体轨迹并使用端到端强化学习优化系统。

Result: 实验结果表明WideSeek和多智能体强化学习的有效性，证明增加智能体数量是推进广度研究范式的有前景方向。

Conclusion: 该研究为解决广度研究中的基准缺乏和优化挑战提供了系统解决方案，通过多智能体架构和强化学习框架展示了在复杂约束下进行并行信息检索和合成的潜力。

Abstract: Search intelligence is evolving from Deep Research to Wide Research, a paradigm essential for retrieving and synthesizing comprehensive information under complex constraints in parallel. However, progress in this field is impeded by the lack of dedicated benchmarks and optimization methodologies for search breadth. To address these challenges, we take a deep dive into Wide Research from two perspectives: Data Pipeline and Agent Optimization. First, we produce WideSeekBench, a General Broad Information Seeking (GBIS) benchmark constructed via a rigorous multi-phase data pipeline to ensure diversity across the target information volume, logical constraints, and domains. Second, we introduce WideSeek, a dynamic hierarchical multi-agent architecture that can autonomously fork parallel sub-agents based on task requirements. Furthermore, we design a unified training framework that linearizes multi-agent trajectories and optimizes the system using end-to-end RL. Experimental results demonstrate the effectiveness of WideSeek and multi-agent RL, highlighting that scaling the number of agents is a promising direction for advancing the Wide Research paradigm.

</details>


### [117] [Monotonicity as an Architectural Bias for Robust Language Models](https://arxiv.org/abs/2602.02686)
*Patrick Cooper,Alireza Nadali,Ashutosh Trivedi,Alvaro Velasquez*

Main category: cs.CL

TL;DR: 通过在Transformer前馈子层选择性实施单调性约束，同时保持注意力机制不受约束，实现了在保持预训练模型性能的同时显著提升语言模型的鲁棒性，将对抗攻击成功率从69%降至19%。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在对抗性提示和越狱攻击下表现出脆弱性，即使经过大量对齐和微调。这种脆弱性反映了现代神经语言模型的普遍挑战：高维输入空间中的微小结构化扰动可能导致内部语义表示和输出的巨大不可预测变化。

Method: 研究单调性作为架构归纳偏置来提升基于Transformer的语言模型鲁棒性。在序列到序列Transformer的前馈子层选择性实施单调性约束，保持注意力机制不受约束，允许通过注意力显式引入否定、矛盾和上下文交互，同时确保后续语义细化是保序的。

Result: 实证结果显示单调性显著提升鲁棒性：对抗攻击成功率从约69%降至19%，而标准摘要性能仅略有下降。

Conclusion: 单调性与神经语言模型所需表达能力之间的权衡并非固有。通过架构分离方法，可以在保持预训练模型性能的同时实现显著的鲁棒性提升，为构建更安全的语言模型提供了新途径。

Abstract: Large language models (LLMs) are known to exhibit brittle behavior under adversarial prompts and jailbreak attacks, even after extensive alignment and fine-tuning. This fragility reflects a broader challenge of modern neural language models: small, carefully structured perturbations in high-dimensional input spaces can induce large and unpredictable changes in internal semantic representations and output.
  We investigate monotonicity as an architectural inductive bias for improving the robustness of Transformer-based language models. Monotonicity constrains semantic transformations so that strengthening information, evidence, or constraints cannot lead to regressions in the corresponding internal representations. Such order-preserving behavior has long been exploited in control and safety-critical systems to simplify reasoning and improve robustness, but has traditionally been viewed as incompatible with the expressivity required by neural language models.
  We show that this trade-off is not inherent. By enforcing monotonicity selectively in the feed-forward sublayers of sequence-to-sequence Transformers -- while leaving attention mechanisms unconstrained -- we obtain monotone language models that preserve the performance of their pretrained counterparts. This architectural separation allows negation, contradiction, and contextual interactions to be introduced explicitly through attention, while ensuring that subsequent semantic refinement is order-preserving. Empirically, monotonicity substantially improves robustness: adversarial attack success rates drop from approximately 69% to 19%, while standard summarization performance degrades only marginally.

</details>


### [118] [InfMem: Learning System-2 Memory Control for Long-Context Agent](https://arxiv.org/abs/2602.02704)
*Xinyu Wang,Mingze Li,Peng Lu,Xiao-Wen Chang,Lifeng Shang,Jinping Li,Fei Mi,Prasanna Parthasarathi,Yufei Cui*

Main category: cs.CL

TL;DR: InfMem是一个控制导向的智能体，通过PreThink-Retrieve-Write协议实现System-2式控制，主动监控证据充分性，执行定向文档内检索，并应用证据感知联合压缩来更新有限内存，显著提升超长文档推理性能。


<details>
  <summary>Details</summary>
Motivation: 解决超长文档推理中稀疏证据分散在远距离段落且内存受限的问题，传统流式代理的被动内存更新策略难以保留多跳推理所需的低显著性桥梁证据。

Method: 提出InfMem系统，采用PreThink-Retrieve-Write控制协议，主动监控证据充分性，执行定向检索和证据感知联合压缩。开发SFT-to-RL训练方法对齐检索、写入和停止决策与最终任务正确性。

Result: 在32k到1M token的超长QA基准测试中，InfMem在不同骨干模型上均优于MemAgent：Qwen3-1.7B提升+10.17点，Qwen3-4B提升+11.84点，Qwen2.5-7B提升+8.23点，平均推理时间减少3.9倍（最高5.1倍）。

Conclusion: InfMem通过主动控制策略和有效的训练方法，成功解决了超长文档推理中的证据整合和内存约束问题，在性能和效率方面均取得显著提升。

Abstract: Reasoning over ultra-long documents requires synthesizing sparse evidence scattered across distant segments under strict memory constraints. While streaming agents enable scalable processing, their passive memory update strategy often fails to preserve low-salience bridging evidence required for multi-hop reasoning. We propose InfMem, a control-centric agent that instantiates System-2-style control via a PreThink-Retrieve-Write protocol. InfMem actively monitors evidence sufficiency, performs targeted in-document retrieval, and applies evidence-aware joint compression to update a bounded memory. To ensure reliable control, we introduce a practical SFT-to-RL training recipe that aligns retrieval, writing, and stopping decisions with end-task correctness. On ultra-long QA benchmarks from 32k to 1M tokens, InfMem consistently outperforms MemAgent across backbones. Specifically, InfMem improves average absolute accuracy by +10.17, +11.84, and +8.23 points on Qwen3-1.7B, Qwen3-4B, and Qwen2.5-7B, respectively, while reducing inference time by $3.9\times$ on average (up to $5.1\times$) via adaptive early stopping.

</details>


### [119] [Predicting first-episode homelessness among US Veterans using longitudinal EHR data: time-varying models and social risk factors](https://arxiv.org/abs/2602.02731)
*Rohan Pandey,Haijuan Yan,Hong Yu,Jack Tsai*

Main category: cs.CL

TL;DR: 研究利用退伍军人电子健康记录数据，通过机器学习方法预测无家可归风险，发现整合社会行为因素的纵向模型能显著提升预测性能，在最高风险层级达到11.65-13.80%的阳性预测值。


<details>
  <summary>Details</summary>
Motivation: 退伍军人无家可归问题是一个重要的公共卫生挑战，需要通过风险预测实现主动干预。研究旨在探索如何利用电子健康记录数据有效预测首次无家归事件。

Method: 回顾性预后研究，分析4,276,403名退伍军人事务部患者的EHR数据。构建静态和时变EHR表示，使用临床医生指导的逻辑建模临床状况和社会风险的持续性。比较经典机器学习、基于transformer的掩码语言模型和微调大语言模型的性能。

Result: 整合社会行为因素的纵向模型将精确召回曲线下面积(PR-AUC)提高了15-30%。在最高1%风险层级，不同时间点的阳性预测值为：3个月3.93-4.72%、6个月7.39-8.30%、9个月9.84-11.41%、12个月11.65-13.80%。大语言模型在区分度上表现较差但在种族群体间性能差异较小。

Conclusion: 纵向、社会信息化的EHR建模能将无家可归风险集中到可操作的风险层级，为高危退伍军人提供有针对性的数据驱动预防策略。

Abstract: Homelessness among US veterans remains a critical public health challenge, yet risk prediction offers a pathway for proactive intervention. In this retrospective prognostic study, we analyzed electronic health record (EHR) data from 4,276,403 Veterans Affairs patients during a 2016 observation period to predict first-episode homelessness occurring 3-12 months later in 2017 (prevalence: 0.32-1.19%). We constructed static and time-varying EHR representations, utilizing clinician-informed logic to model the persistence of clinical conditions and social risks over time. We then compared the performance of classical machine learning, transformer-based masked language models, and fine-tuned large language models (LLMs). We demonstrate that incorporating social and behavioral factors into longitudinal models improved precision-recall area under the curve (PR-AUC) by 15-30%. In the top 1% risk tier, models yielded positive predictive values ranging from 3.93-4.72% at 3 months, 7.39-8.30% at 6 months, 9.84-11.41% at 9 months, and 11.65-13.80% at 12 months across model architectures. Large language models underperformed encoder-based models on discrimination but showed smaller performance disparities across racial groups. These results demonstrate that longitudinal, socially informed EHR modeling concentrates homelessness risk into actionable strata, enabling targeted and data-informed prevention strategies for at-risk veterans.

</details>


### [120] [Time-Critical Multimodal Medical Transportation: Organs, Patients, and Medical Supplies](https://arxiv.org/abs/2602.02736)
*Elaheh Sabziyan Varnousfaderani,Syed A. M. Shihab,Mohammad Taghizadeh*

Main category: cs.CL

TL;DR: 提出一种用于医疗运输的多模式车辆调度贪婪启发式算法，比较了四种车队配置（仅救护车、救护车+无人机、救护车+eVTOL、全集成车队）的性能，旨在最小化运营成本、能源成本和总运输时间。


<details>
  <summary>Details</summary>
Motivation: 医疗运输中器官、患者和医疗物资的及时运输至关重要，传统救护车受交通拥堵限制，直升机成本高昂，新兴航空器受航程和天气限制，需要多模式运输系统整合空中和地面车辆的优势。

Method: 采用构造性贪婪启发式算法进行多模式车辆调度，考虑兼容路线的有效载荷整合、地面交通拥堵和空中天气条件，测试了四种不同的车队配置方案。

Result: 在统一条件下评估了四种车队类型，确定了满足医疗运输需求同时最小化运营成本、充电/燃料成本和总运输时间的最有效配置方案。

Conclusion: 多模式运输系统能够整合空中和地面车辆的优势，提出的贪婪启发式算法能够实现快速车辆调度，相比计算密集型优化模型更具实用性，为医疗运输提供了有效的解决方案。

Abstract: Timely transportation of organs, patients, and medical supplies is critical to modern healthcare, particularly in emergencies and transplant scenarios where even short delays can severely impact outcomes. Traditional ground-based vehicles such as ambulances are often hindered by traffic congestion; while air vehicles such as helicopters are faster but costly. Emerging air vehicles -- Unmanned Aerial Vehicles and electric vertical take-off and landing aircraft -- have lower operating costs, but remain limited by range and susceptibility to weather conditions. A multimodal transportation system that integrates both air and ground vehicles can leverage the strengths of each to enhance overall transportation efficiency. This study introduces a constructive greedy heuristic algorithm for multimodal vehicle dispatching for medical transportation. Four different fleet configurations were tested: (i) ambulances only, (ii) ambulances with Unmanned Aerial Vehicles, (iii) ambulances with electric vertical take-off and landing aircraft, and (iv) a fully integrated fleet of ambulances, Unmanned Aerial Vehicles, and electric vertical take-off and landing aircraft. The algorithm incorporates payload consolidation across compatible routes, accounts for traffic congestion in ground operations and weather conditions in aerial operations, while enabling rapid vehicle dispatching compared to computationally intensive optimization models. Using a common set of conditions, we evaluate all four fleet types to identify the most effective configurations for fulfilling medical transportation needs while minimizing operating costs, recharging/fuel costs, and total transportation time.

</details>


### [121] [From Task Solving to Robust Real-World Adaptation in LLM Agents](https://arxiv.org/abs/2602.02760)
*Pouya Pezeshkpour,Estevam Hruschka*

Main category: cs.CL

TL;DR: 论文提出一个测试LLM智能体在部署环境中的鲁棒性框架，通过网格游戏评估智能体在部分可观测性、动态环境、噪声信号和动态状态等现实挑战下的表现，发现现有模型在名义任务解决与部署鲁棒性之间存在显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有评估通常假设'干净接口'环境，但实际部署中智能体面临规则不明确、信号不可靠、环境动态变化和多利益相关者目标等复杂情况，需要测试其在真实操作环境中的适应能力。

Method: 设计基于网格游戏的基准测试，包含长时程执行任务，故意违反干净接口假设但保持任务可解，迫使智能体推断规则、支付信息成本、适应环境内部变化并在噪声下谨慎行动。测试了五种最先进的LLM智能体。

Result: 发现性能随网格大小和时程增加而下降，但模型排名不稳定：较弱模型在策略匹配不确定性机制时可能胜过更强模型。智能体会在没有明确指令的情况下权衡完成度、效率和惩罚避免，表现出部分目标推断能力。

Conclusion: 揭示了模型特定的敏感性和失败原因，强调了在部分可观测性、噪声和非平稳性条件下进行验证、安全行动选择和目标推断研究的重要性。

Abstract: Large language models are increasingly deployed as specialized agents that plan, call tools, and take actions over extended horizons. Yet many existing evaluations assume a "clean interface" where dynamics are specified and stable, tools and sensors are reliable, and success is captured by a single explicit objective-often overestimating real-world readiness. In practice, agents face underspecified rules, unreliable signals, shifting environments, and implicit, multi-stakeholder goals. The challenge is therefore not just solving tasks, but adapting while solving: deciding what to trust, what is wanted, when to verify, and when to fall back or escalate. We stress-test deployment-relevant robustness under four operational circumstances: partial observability, dynamic environments, noisy signals, and dynamic agent state. We benchmark agentic LLMs in a grid-based game with a simple goal but long-horizon execution. Episodes violate clean-interface assumptions yet remain solvable, forcing agents to infer rules, pay for information, adapt to environmental and internal shifts, and act cautiously under noise. Across five state-of-the-art LLM agents, we find large gaps between nominal task-solving and deployment-like robustness. Performance generally degrades as grid size and horizon increase, but rankings are unstable: weaker models can beat stronger ones when strategy matches the uncertainty regime. Despite no explicit instruction, agents trade off completion, efficiency, and penalty avoidance, suggesting partial objective inference. Ablations and feature analyses reveal model-specific sensitivities and failure drivers, motivating work on verification, safe action selection, and objective inference under partial observability, noise, and non-stationarity.

</details>


### [122] [AmharicStoryQA: A Multicultural Story Question Answering Benchmark in Amharic](https://arxiv.org/abs/2602.02774)
*Israel Abebe Azime,Abenezer Kebede Angamo,Hana Mekonen Tamiru,Dagnachew Mekonnen Marilign,Philipp Slusallek,Seid Muhie Yimam,Dietrich Klakow*

Main category: cs.CL

TL;DR: 论文提出了AmharicStoryQA基准，揭示LLMs在阿姆哈拉语叙事理解上的文化差异和地域差异，强调需要超越语言层面的文化基础评估。


<details>
  <summary>Details</summary>
Motivation: 现有多语言评估基准将语言和文化等同对待，忽视了单一语言内部的文化多样性，需要更准确地评估低资源语言的叙事理解能力。

Method: 构建AmharicStoryQA基准，包含埃塞俄比亚不同阿姆哈拉语地区的文化多样化叙事，进行长序列故事问答评估，并分析监督微调的效果。

Result: 发现现有LLMs存在显著的叙事理解差距，评估结果显示出明显的地域差异，监督微调在不同地区和评估设置中产生不均衡的改进效果。

Conclusion: 需要建立基于文化的评估基准，超越单纯的语言层面评估，以更准确地评估和改进低资源语言的叙事理解能力。

Abstract: With the growing emphasis on multilingual and cultural evaluation benchmarks for large language models, language and culture are often treated as synonymous, and performance is commonly used as a proxy for a models understanding of a given language. In this work, we argue that such evaluations overlook meaningful cultural variation that exists within a single language. We address this gap by focusing on narratives from different regions of Ethiopia and demonstrate that, despite shared linguistic characteristics, region-specific and domain-specific content substantially influences language evaluation outcomes. To this end, we introduce \textbf{\textit{AmharicStoryQA}}, a long-sequence story question answering benchmark grounded in culturally diverse narratives from Amharic-speaking regions. Using this benchmark, we reveal a significant narrative understanding gap in existing LLMs, highlight pronounced regional differences in evaluation results, and show that supervised fine-tuning yields uneven improvements across regions and evaluation settings. Our findings emphasize the need for culturally grounded benchmarks that go beyond language-level evaluation to more accurately assess and improve narrative understanding in low-resource languages.

</details>


### [123] [When Efficient Communication Explains Convexity](https://arxiv.org/abs/2602.02821)
*Ashvin Ranjan,Shane Steinert-Threlkeld*

Main category: cs.CL

TL;DR: 本文通过信息瓶颈方法分析语言语义类型学，发现通信效率优化与凸性概念密切相关，并识别出通信需求分布的凸性是驱动这种相关性的关键因素。


<details>
  <summary>Details</summary>
Motivation: 研究旨在确定在高效通信框架下解释语言语义类型学成功的因素，超越简单的相关性分析，探究背后的根本原因。

Method: 使用信息瓶颈(IB)方法形式化简单性与信息性之间的权衡，首先分析IB意义上的最优性与凸性推广之间的相关性，然后通过操纵IB框架中的各种建模参数来确定驱动因素。

Result: 发现通信需求分布的凸性在凸性与最优性之间的相关性中扮演特别重要的角色，揭示了高效通信解释语义类型学的深层机制。

Conclusion: 研究不仅证实高效通信可以解释语义类型学特征，更重要的是识别了导致这种解释成功的具体因素，特别是通信需求分布的凸性特征。

Abstract: Much recent work has argued that the variation in the languages of the world can be explained from the perspective of efficient communication; in particular, languages can be seen as optimally balancing competing pressures to be simple and to be informative. Focusing on the expression of meaning -- semantic typology -- the present paper asks what factors are responsible for successful explanations in terms of efficient communication. Using the Information Bottleneck (IB) approach to formalizing this trade-off, we first demonstrate and analyze a correlation between optimality in the IB sense and a novel generalization of convexity to this setting. In a second experiment, we manipulate various modeling parameters in the IB framework to determine which factors drive the correlation between convexity and optimality. We find that the convexity of the communicative need distribution plays an especially important role. These results move beyond showing that efficient communication can explain aspects of semantic typology into explanations for why that is the case by identifying which underlying factors are responsible.

</details>


### [124] [R2-Router: A New Paradigm for LLM Routing with Reasoning](https://arxiv.org/abs/2602.02823)
*Jiaqi Xue,Qian Lou,Jiarong Xing,Heng Huang*

Main category: cs.CL

TL;DR: R2-Router通过将输出长度预算作为可控变量，联合选择最佳LLM和长度预算，在成本降低4-5倍的情况下实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有LLM路由方法假设每个查询的LLM质量和成本是固定的，忽略了同一LLM的质量会随输出长度变化，导致在预算限制时排除强大但成本高的LLM。

Method: 引入R2-Router，将输出长度预算作为可控变量，通过长度约束指令联合选择最佳LLM和长度预算，并构建R2-Bench数据集。

Result: 实验表明R2-Router以4-5倍更低的成本实现最先进性能，发现强大LLM在受限输出下仍能优于较弱LLM。

Conclusion: 这项工作开启了路由即推理的新方向，路由器从被动选择器演变为探索使用哪个LLM及成本预算的深思熟虑推理器。

Abstract: As LLMs proliferate with diverse capabilities and costs, LLM routing has emerged by learning to predict each LLM's quality and cost for a given query, then selecting the one with high quality and low cost. However, existing routers implicitly assume a single fixed quality and cost per LLM for each query, ignoring that the same LLM's quality varies with its output length. This causes routers to exclude powerful LLMs when their estimated cost exceeds the budget, missing the opportunity that these LLMs could still deliver high quality at reduced cost with shorter outputs. To address this, we introduce R2-Router, which treats output length budget as a controllable variable and jointly selects the best LLM and length budget, enforcing the budget via length-constrained instructions. This enables R2-Router to discover that a powerful LLM with constrained output can outperform a weaker LLM at comparable cost-efficient configurations invisible to prior methods. Together with the router framework, we construct R2-Bench, the first routing dataset capturing LLM behavior across diverse output length budgets. Experiments show that R2-Router achieves state-of-the-art performance at 4-5x lower cost compared with existing routers. This work opens a new direction: routing as reasoning, where routers evolve from reactive selectors to deliberate reasoners that explore which LLM to use and at what cost budget.

</details>


### [125] [CATNIP: LLM Unlearning via Calibrated and Tokenized Negative Preference Alignment](https://arxiv.org/abs/2602.02824)
*Zhengbang Yang,Yisheng Zhong,Junyuan Hong,Zhuangdi Zhu*

Main category: cs.CL

TL;DR: CATNIP是一种新的LLM遗忘方法，通过基于token级置信度重新调整遗忘效果，实现细粒度控制，无需保留数据或对比学习对，在MUSE和WMDP基准测试中表现出优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于梯度上升的遗忘方法会损害通用领域知识，且依赖保留数据或对比对，而负偏好对齐方法受限于参考模型选择且在真实数据设置中性能不佳，需要更精确的梯度校准和鲁棒的数据处理方法。

Method: 提出CATNIP方法，基于模型对不良知识的token级置信度来量化模型信心，并按比例重新调整遗忘效果，实现更精确的梯度更新控制。

Result: 在MUSE和WMDP基准测试中，CATNIP实现了有效的知识遗忘，不需要保留数据或对比遗忘响应对，在知识遗忘和保留的权衡方面优于最先进方法。

Conclusion: CATNIP通过置信度校准的token级负偏好对齐，解决了现有遗忘方法的局限性，提供了更精确的遗忘控制，在数据稀缺和长度变化的情况下仍保持鲁棒性。

Abstract: Pretrained knowledge memorized in LLMs raises critical concerns over safety and privacy, which has motivated LLM Unlearning as a technique for selectively removing the influences of undesirable knowledge. Existing approaches, rooted in Gradient Ascent (GA), often degrade general domain knowledge while relying on retention data or curated contrastive pairs, which can be either impractical or data and computationally prohibitive. Negative Preference Alignment has been explored for unlearning to tackle the limitations of GA, which, however, remains confined by its choice of reference model and shows undermined performance in realistic data settings. These limitations raise two key questions: i) Can we achieve effective unlearning that quantifies model confidence in undesirable knowledge and uses it to calibrate gradient updates more precisely, thus reducing catastrophic forgetting? ii) Can we make unlearning robust to data scarcity and length variation? We answer both questions affirmatively with CATNIP (Calibrated and Tokenized Negative Preference Alignment), a principled method that rescales unlearning effects in proportion to the model's token-level confidence, thus ensuring fine-grained control over forgetting. Extensive evaluations on MUSE and WMDP benchmarks demonstrated that our work enables effective unlearning without requiring retention data or contrastive unlearning response pairs, with stronger knowledge forgetting and preservation tradeoffs than state-of-the-art methods.

</details>


### [126] [Act or Clarify? Modeling Sensitivity to Uncertainty and Cost in Communication](https://arxiv.org/abs/2602.02843)
*Polina Tsvilodub,Karl Mulligan,Todd Snider,Robert D. Hawkins,Michael Franke*

Main category: cs.CL

TL;DR: 论文研究了在不确定性下人类如何通过提问澄清问题来减少不确定性，提出了基于预期后悔的计算模型，并通过实验验证了不确定性成本与澄清行为之间的理性权衡关系。


<details>
  <summary>Details</summary>
Motivation: 研究动机是理解在沟通场景中，代理如何在不同不确定性水平和行动成本下决定是否提出澄清问题，探索人类在不确定条件下的理性决策机制。

Method: 采用基于预期后悔的计算模型形式化不确定性成本与澄清行为的交互作用，并通过两个实验进行验证：一个是纯语言响应实验，另一个是澄清问题与非语言行动选择的扩展实验。

Result: 实验结果表明人类倾向于根据不确定性行动可能带来的损失风险来按比例寻求澄清，支持了理性权衡的假设。

Conclusion: 研究证实了在不确定性决策中，人类会理性地权衡澄清成本与行动风险，不确定性对澄清行为的影响在错误行动成本较高时最为显著。

Abstract: When deciding how to act under uncertainty, agents may choose to act to reduce uncertainty or they may act despite that uncertainty.In communicative settings, an important way of reducing uncertainty is by asking clarification questions (CQs). We predict that the decision to ask a CQ depends on both contextual uncertainty and the cost of alternative actions, and that these factors interact: uncertainty should matter most when acting incorrectly is costly. We formalize this interaction in a computational model based on expected regret: how much an agent stands to lose by acting now rather than with full information. We test these predictions in two experiments, one examining purely linguistic responses to questions and another extending to choices between clarification and non-linguistic action. Taken together, our results suggest a rational tradeoff: humans tend to seek clarification proportional to the risk of substantial loss when acting under uncertainty.

</details>


### [127] [Which course? Discourse! Teaching Discourse and Generation in the Era of LLMs](https://arxiv.org/abs/2602.02878)
*Junyi Jessy Li,Yang Janet Liu,Kanishka Misra,Valentina Pyatkin,William Sheffield*

Main category: cs.CL

TL;DR: 介绍了一门新课程"计算话语与自然语言生成"，该课程整合了语言学理论和计算模型，旨在弥合NLP快速变化领域中各子学科之间的教学鸿沟。


<details>
  <summary>Details</summary>
Motivation: NLP领域的快速变革引发了跨学科教育问题，特别是如何设计能够连接各子学科的课程。话语处理作为具有丰富语言学见解和计算模型的领域，在现有本科课程中与开放文本生成的关联未被充分探索。

Method: 合作设计了一门高级本科课程，由具有互补专业知识的团队开发，在语言学与计算机科学交叉领域开设。课程深度整合理论与实证方面，培养课堂内外的探索性思维。

Result: 成功开设了这门新课程，并通过独立调查收集了反馈。课程详细描述了话语处理的意图、注意和连贯结构等计算模型。

Conclusion: 该课程为NLP教育提供了有价值的模式，展示了如何将话语处理与文本生成有效结合，并提出了未来发展的愿景。

Abstract: The field of NLP has undergone vast, continuous transformations over the past few years, sparking debates going beyond discipline boundaries. This begs important questions in education: how do we design courses that bridge sub-disciplines in this shifting landscape? This paper explores this question from the angle of discourse processing, an area with rich linguistic insights and computational models for the intentional, attentional, and coherence structure of language. Discourse is highly relevant for open-ended or long-form text generation, yet this connection is under-explored in existing undergraduate curricula. We present a new course, "Computational Discourse and Natural Language Generation". The course is collaboratively designed by a team with complementary expertise and was offered for the first time in Fall 2025 as an upper-level undergraduate course, cross-listed between Linguistics and Computer Science. Our philosophy is to deeply integrate the theoretical and empirical aspects, and create an exploratory mindset inside the classroom and in the assignments. This paper describes the course in detail and concludes with takeaways from an independent survey as well as our vision for future directions.

</details>


### [128] [HALT: Hallucination Assessment via Log-probs as Time series](https://arxiv.org/abs/2602.02888)
*Ahmad Shapiro,Karan Taneja,Ashok Goel*

Main category: cs.CL

TL;DR: HALT是一个轻量级幻觉检测器，仅使用LLM生成的前20个token对数概率作为时间序列，通过门控循环单元和基于熵的特征来检测幻觉，在HUB基准测试中性能优于更大的模型且速度提升60倍。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在安全关键领域中的幻觉问题，提供一种既不需要访问隐藏状态（白盒）也不依赖表面文本（黑盒）的高效检测方法。

Method: 使用前20个token的对数概率作为时间序列输入，结合门控循环单元模型和基于熵的特征来学习模型校准偏差，仅需输出对数概率而不需要内部权重或隐藏状态。

Result: 在统一的HUB基准测试（包含10种能力）中，HALT模型比Lettuce（微调的BERT-base编码器）性能更好，体积小30倍，速度提升60倍。

Conclusion: HALT和HUB共同建立了跨多样LLM能力的有效幻觉检测框架，为轻量级、高效的幻觉检测提供了新解决方案。

Abstract: Hallucinations remain a major obstacle for large language models (LLMs), especially in safety-critical domains. We present HALT (Hallucination Assessment via Log-probs as Time series), a lightweight hallucination detector that leverages only the top-20 token log-probabilities from LLM generations as a time series. HALT uses a gated recurrent unit model combined with entropy-based features to learn model calibration bias, providing an extremely efficient alternative to large encoders. Unlike white-box approaches, HALT does not require access to hidden states or attention maps, relying only on output log-probabilities. Unlike black-box approaches, it operates on log-probs rather than surface-form text, which enables stronger domain generalization and compatibility with proprietary LLMs without requiring access to internal weights. To benchmark performance, we introduce HUB (Hallucination detection Unified Benchmark), which consolidates prior datasets into ten capabilities covering both reasoning tasks (Algorithmic, Commonsense, Mathematical, Symbolic, Code Generation) and general purpose skills (Chat, Data-to-Text, Question Answering, Summarization, World Knowledge). While being 30x smaller, HALT outperforms Lettuce, a fine-tuned modernBERT-base encoder, achieving a 60x speedup gain on HUB. HALT and HUB together establish an effective framework for hallucination detection across diverse LLM capabilities.

</details>


### [129] [Equal Access, Unequal Interaction: A Counterfactual Audit of LLM Fairness](https://arxiv.org/abs/2602.02932)
*Alireza Amiri-Margavi,Arshia Gharagozlou,Amin Gholami Davodi,Seyed Pouyan Mousavi Davoudi,Hamidreza Hasani Balyani*

Main category: cs.CL

TL;DR: 研究发现LLM在获得访问权限后仍存在交互质量的不公平性，GPT-4对年轻男性用户表达更多不确定性，LLaMA在不同身份群体间情感差异显著，表明公平性评估需要超越拒绝率分析。


<details>
  <summary>Details</summary>
Motivation: 现有公平性研究主要关注拒绝访问等表层行为，但平等访问并不保证交互质量的公平性，需要深入分析模型在提供响应后的语言表现差异。

Method: 使用反事实提示设计，在职业建议任务中测试GPT-4和LLaMA-3.1-70B，变化年龄、性别和国籍等身份属性，通过自动语言指标（情感、礼貌、模糊语）和配对统计测试评估差异。

Result: 两模型在所有身份群体中都显示零拒绝率，但GPT-4对年轻男性用户显著更多使用模糊语，LLaMA在不同身份群体间情感变化更明显。

Conclusion: 即使访问权限平等，交互层面仍存在系统性不公平，需要开发超越拒绝率审计的公平性评估方法。

Abstract: Prior work on fairness in large language models (LLMs) has primarily focused on access-level behaviors such as refusals and safety filtering. However, equitable access does not ensure equitable interaction quality once a response is provided. In this paper, we conduct a controlled fairness audit examining how LLMs differ in tone, uncertainty, and linguistic framing across demographic identities after access is granted. Using a counterfactual prompt design, we evaluate GPT-4 and LLaMA-3.1-70B on career advice tasks while varying identity attributes along age, gender, and nationality. We assess access fairness through refusal analysis and measure interaction quality using automated linguistic metrics, including sentiment, politeness, and hedging. Identity-conditioned differences are evaluated using paired statistical tests. Both models exhibit zero refusal rates across all identities, indicating uniform access. Nevertheless, we observe systematic, model-specific disparities in interaction quality: GPT-4 expresses significantly higher hedging toward younger male users, while LLaMA exhibits broader sentiment variation across identity groups. These results show that fairness disparities can persist at the interaction level even when access is equal, motivating evaluation beyond refusal-based audits.

</details>


### [130] [Where Norms and References Collide: Evaluating LLMs on Normative Reasoning](https://arxiv.org/abs/2602.02975)
*Mitchell Abrams,Kaveh Eskandari Miandoab,Felix Gervits,Vasanth Sarathy,Matthias Scheutz*

Main category: cs.CL

TL;DR: SNIC是一个诊断测试平台，用于评估大型语言模型在情境规范推理方面的能力，发现即使最先进的LLM在识别和应用社交规范方面仍存在困难，特别是在规范隐含、未明确说明或冲突的情况下。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探究大型语言模型是否能够支持基于规范的指代消解(NBRR)，即在物理和社会情境中推断隐含的规范性期望来理解指代表达式的能力，这对于具身智能体在真实环境中的有效交互至关重要。

Method: 开发了SNIC(Situated Norms in Context)人类验证的诊断测试平台，专注于日常任务(如清洁、整理、服务)中出现的物理基础规范，通过一系列受控评估测试最先进LLM的表现。

Result: 研究发现即使最强的LLM也难以一致地识别和应用社交规范，特别是在规范隐含、未明确说明或冲突的情况下，显示出当前LLM在这一领域的明显局限性。

Conclusion: 当前LLM在社交情境规范推理方面存在盲点，这突显了在社交情境化、具身化环境中部署基于语言的系统所面临的关键挑战。

Abstract: Embodied agents, such as robots, will need to interact in situated environments where successful communication often depends on reasoning over social norms: shared expectations that constrain what actions are appropriate in context. A key capability in such settings is norm-based reference resolution (NBRR), where interpreting referential expressions requires inferring implicit normative expectations grounded in physical and social context. Yet it remains unclear whether Large Language Models (LLMs) can support this kind of reasoning. In this work, we introduce SNIC (Situated Norms in Context), a human-validated diagnostic testbed designed to probe how well state-of-the-art LLMs can extract and utilize normative principles relevant to NBRR. SNIC emphasizes physically grounded norms that arise in everyday tasks such as cleaning, tidying, and serving. Across a range of controlled evaluations, we find that even the strongest LLMs struggle to consistently identify and apply social norms, particularly when norms are implicit, underspecified, or in conflict. These findings reveal a blind spot in current LLMs and highlight a key challenge for deploying language-based systems in socially situated, embodied settings.

</details>


### [131] [CPMobius: Iterative Coach-Player Reasoning for Data-Free Reinforcement Learning](https://arxiv.org/abs/2602.02979)
*Ran Li,Zeyuan Liu,Yinghao chen,Bingxiang He,Jiarui Yuan,Zixuan Fu,Weize Chen,Jinyi Hu,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

TL;DR: CPMöbius是一种无需外部数据的协作式教练-玩家强化学习范式，通过教练生成针对性指令、玩家解决任务的双向奖励机制，显著提升大语言模型的数学推理能力


<details>
  <summary>Details</summary>
Motivation: 传统LLM训练依赖大量人工标注数据，存在可扩展性限制和成本问题，需要开发无需外部监督数据的自监督推理训练方法

Method: 提出Coach-Player协作范式：教练根据玩家能力生成针对性指令并获得玩家性能改进的奖励，玩家通过解决教练生成的任务获得奖励，形成协同优化循环

Result: 在Qwen2.5-Math-7B-Instruct上，整体准确率提升+4.9，分布外准确率提升+5.4，优于RENT和R-zero等无监督方法

Conclusion: CPMöbius证明了无需外部数据即可有效提升LLM推理能力的可行性，为数据稀缺场景下的模型优化提供了新思路

Abstract: Large Language Models (LLMs) have demonstrated strong potential in complex reasoning, yet their progress remains fundamentally constrained by reliance on massive high-quality human-curated tasks and labels, either through supervised fine-tuning (SFT) or reinforcement learning (RL) on reasoning-specific data. This dependence renders supervision-heavy training paradigms increasingly unsustainable, with signs of diminishing scalability already evident in practice. To overcome this limitation, we introduce CPMöbius (CPMobius), a collaborative Coach-Player paradigm for data-free reinforcement learning of reasoning models. Unlike traditional adversarial self-play, CPMöbius, inspired by real world human sports collaboration and multi-agent collaboration, treats the Coach and Player as independent but cooperative roles. The Coach proposes instructions targeted at the Player's capability and receives rewards based on changes in the Player's performance, while the Player is rewarded for solving the increasingly instructive tasks generated by the Coach. This cooperative optimization loop is designed to directly enhance the Player's mathematical reasoning ability. Remarkably, CPMöbius achieves substantial improvement without relying on any external training data, outperforming existing unsupervised approaches. For example, on Qwen2.5-Math-7B-Instruct, our method improves accuracy by an overall average of +4.9 and an out-of-distribution average of +5.4, exceeding RENT by +1.5 on overall accuracy and R-zero by +4.2 on OOD accuracy.

</details>


### [132] [LatentMem: Customizing Latent Memory for Multi-Agent Systems](https://arxiv.org/abs/2602.03036)
*Muxin Fu,Guibin Zhang,Xiangyuan Xue,Yafu Li,Zefeng He,Siyuan Huang,Xiaoye Qu,Yu Cheng,Yang Yang*

Main category: cs.CL

TL;DR: LatentMem是一个可学习的多智能体记忆框架，通过角色感知定制和紧凑潜在表示解决记忆同质化和信息过载问题，在多个基准测试中性能提升高达19.36%


<details>
  <summary>Details</summary>
Motivation: 现有多智能体记忆设计存在两个基本瓶颈：(i)缺乏角色感知定制导致记忆同质化，(ii)过于细粒度的记忆条目导致信息过载

Method: 提出LatentMem框架，包含存储原始交互轨迹的经验库和基于检索经验与智能体特定上下文合成紧凑潜在记忆的记忆合成器，并引入Latent Memory Policy Optimization (LMPO)算法

Result: 在多样化基准测试和主流MAS框架中，LatentMem相比原始设置实现高达19.36%的性能提升，且无需修改底层框架

Conclusion: LatentMem通过可学习的潜在记忆表示有效解决了多智能体系统中的记忆瓶颈问题，显著提升了集体智能性能

Abstract: Large language model (LLM)-powered multi-agent systems (MAS) demonstrate remarkable collective intelligence, wherein multi-agent memory serves as a pivotal mechanism for continual adaptation. However, existing multi-agent memory designs remain constrained by two fundamental bottlenecks: (i) memory homogenization arising from the absence of role-aware customization, and (ii) information overload induced by excessively fine-grained memory entries. To address these limitations, we propose LatentMem, a learnable multi-agent memory framework designed to customize agent-specific memories in a token-efficient manner. Specifically, LatentMem comprises an experience bank that stores raw interaction trajectories in a lightweight form, and a memory composer that synthesizes compact latent memories conditioned on retrieved experience and agent-specific contexts. Further, we introduce Latent Memory Policy Optimization (LMPO), which propagates task-level optimization signals through latent memories to the composer, encouraging it to produce compact and high-utility representations. Extensive experiments across diverse benchmarks and mainstream MAS frameworks show that LatentMem achieves a performance gain of up to $19.36$% over vanilla settings and consistently outperforms existing memory architectures, without requiring any modifications to the underlying frameworks.

</details>


### [133] [SAES-SVD: Self-Adaptive Suppression of Accumulated and Local Errors for SVD-based LLM Compression](https://arxiv.org/abs/2602.03051)
*Xing Hu,Dawei Yang,Yuan Cheng,Zhixuan Chen,Zukang Xu*

Main category: cs.CL

TL;DR: SAES-SVD是一种针对大语言模型压缩的框架，通过联合优化层内重构和层间误差补偿来解决传统独立层压缩中的误差累积问题，包含CEALC和ACES两个核心组件，在多个LLM架构和任务上显著提升了压缩后性能。


<details>
  <summary>Details</summary>
Motivation: 现有低秩压缩方法独立压缩每一层，只最小化单层重构误差，忽略了误差在网络中的传播和累积问题，导致全局偏差被放大。

Method: 提出SAES-SVD框架，包含：(1)CEALC组件，将压缩目标定义为局部重构和加权累积误差补偿的组合，基于二阶激活统计推导闭式低秩解；(2)ACES组件，自动调整权重系数以增强压缩目标的低秩结构。

Result: 在多个LLM架构和任务上的广泛实验表明，SAES-SVD在不使用微调或混合秩策略的情况下，持续改善了压缩后性能。

Conclusion: SAES-SVD通过联合优化层内重构和层间误差补偿，有效解决了误差累积问题，为大语言模型的高效压缩提供了硬件无关且高度兼容的解决方案。

Abstract: The rapid growth in the parameter scale of large language models (LLMs) has created a high demand for efficient compression techniques. As a hardware-agnostic and highly compatible technique, low-rank compression has been widely adopted. However, existing methods typically compress each layer independently by minimizing per-layer reconstruction error, overlooking a critical limitation: the reconstruction error propagates and accumulates through the network, which leads to amplified global deviations from the full-precision baseline. To address this, we propose Self-Adaptive Error Suppression SVD (SAES-SVD), a LLMs compression framework that jointly optimizes intra-layer reconstruction and inter-layer error compensation. SAES-SVD is composed of two novel components: (1) Cumulative Error-Aware Layer Compression (CEALC), which formulates the compression objective as a combination of local reconstruction and weighted cumulative error compensation. Based on it, we derive a closed-form low-rank solution relied on second-order activation statistics, which explicitly aligns each layer's output with its full-precision counterpart to compensate for accumulated errors. (2) Adaptive Collaborative Error Suppression (ACES), which automatically adjusts the weighting coefficient to enhance the low-rank structure of the compression objective in CEALC. Specifically, the coefficient is optimized to maximize the ratio between the Frobenius norm of the compressed layer's output and that of the compression objective under a fixed rank, thus ensuring that the rank budget is utilized effectively. Extensive experiments across multiple LLM architectures and tasks show that, without fine-tuning or mixed-rank strategies, SAES-SVD consistently improves post-compression performance.

</details>


### [134] [ReMiT: RL-Guided Mid-Training for Iterative LLM Evolution](https://arxiv.org/abs/2602.03075)
*Junjie Huang,Jiarui Qin,Di Yin,Weiwen Liu,Yong Yu,Xing Sun,Weinan Zhang*

Main category: cs.CL

TL;DR: ReMiT提出了一种双向LLM训练框架，通过强化学习调优模型的推理先验来动态重加权预训练中的关键token，实现基础模型与后训练模型的相互增强循环。


<details>
  <summary>Details</summary>
Motivation: 探索双向训练流程的潜力，建立自增强的飞轮效应：让RL调优模型能够反向增强基础模型，进而提升后续后训练性能，无需专门的教师或参考模型。

Method: 分析训练动态，识别中期训练（退火）阶段为关键转折点；利用RL调优模型的推理先验，在中期训练阶段动态重加权对推理至关重要的token。

Result: 在10个预训练基准测试（数学、代码和通用推理）上平均提升3%，并在整个后训练流程中保持超过2%的增益。

Conclusion: 验证了迭代反馈循环的有效性，实现了LLM的持续自增强进化，为双向训练范式提供了实证支持。

Abstract: Standard training pipelines for large language models (LLMs) are typically unidirectional, progressing from pre-training to post-training. However, the potential for a bidirectional process--where insights from post-training retroactively improve the pre-trained foundation--remains unexplored. We aim to establish a self-reinforcing flywheel: a cycle in which reinforcement learning (RL)-tuned model strengthens the base model, which in turn enhances subsequent post-training performance, requiring no specially trained teacher or reference model. To realize this, we analyze training dynamics and identify the mid-training (annealing) phase as a critical turning point for model capabilities. This phase typically occurs at the end of pre-training, utilizing high-quality corpora under a rapidly decaying learning rate. Building upon this insight, we introduce ReMiT (Reinforcement Learning-Guided Mid-Training). Specifically, ReMiT leverages the reasoning priors of RL-tuned models to dynamically reweight tokens during the mid-training phase, prioritizing those pivotal for reasoning. Empirically, ReMiT achieves an average improvement of 3\% on 10 pre-training benchmarks, spanning math, code, and general reasoning, and sustains these gains by over 2\% throughout the post-training pipeline. These results validate an iterative feedback loop, enabling continuous and self-reinforcing evolution of LLMs.

</details>


### [135] [AERO: Autonomous Evolutionary Reasoning Optimization via Endogenous Dual-Loop Feedback](https://arxiv.org/abs/2602.03084)
*Zhitao Gao,Jie Ma,Xuhong Li,Pengyu Li,Ning Qu,Yaqiang Wu,Hui Liu,Jun Liu*

Main category: cs.CL

TL;DR: AERO是一个无监督的自进化推理优化框架，通过双循环系统实现自我提问、回答和批评，基于ZPD理论使用基于熵的定位来瞄准可解性差距，并采用独立反事实校正进行验证，在多个基准测试中显著提升LLM性能。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在复杂推理中依赖专家标注数据和外部验证器的瓶颈问题，避免现有自进化范式因无法识别最佳学习区域而强化集体幻觉和错误先验的问题。

Method: 提出AERO框架：1）基于ZPD理论使用熵定位识别可解性差距；2）采用独立反事实校正进行鲁棒验证；3）引入交错训练策略同步功能角色能力增长；4）构建包含自我提问、回答和批评的协同双循环系统。

Result: 在9个基准测试中，Qwen3-4B-Base平均性能提升4.57%，Qwen3-8B-Base平均提升5.10%，优于竞争基线方法。

Conclusion: AERO通过无监督的自进化机制有效解决了LLMs推理能力的自主优化问题，为大规模语言模型的自我改进提供了新范式。

Abstract: Large Language Models (LLMs) have achieved significant success in complex reasoning but remain bottlenecked by reliance on expert-annotated data and external verifiers. While existing self-evolution paradigms aim to bypass these constraints, they often fail to identify the optimal learning zone and risk reinforcing collective hallucinations and incorrect priors through flawed internal feedback. To address these challenges, we propose \underline{A}utonomous \underline{E}volutionary \underline{R}easoning \underline{O}ptimization (AERO), an unsupervised framework that achieves autonomous reasoning evolution by internalizing self-questioning, answering, and criticism within a synergistic dual-loop system. Inspired by the \textit{Zone of Proximal Development (ZPD)} theory, AERO utilizes entropy-based positioning to target the ``solvability gap'' and employs Independent Counterfactual Correction for robust verification. Furthermore, we introduce a Staggered Training Strategy to synchronize capability growth across functional roles and prevent curriculum collapse. Extensive evaluations across nine benchmarks spanning three domains demonstrate that AERO achieves average performance improvements of 4.57\% on Qwen3-4B-Base and 5.10\% on Qwen3-8B-Base, outperforming competitive baselines. Code is available at https://github.com/mira-ai-lab/AERO.

</details>


### [136] [Test-time Recursive Thinking: Self-Improvement without External Feedback](https://arxiv.org/abs/2602.03094)
*Yufan Zhuang,Chandan Singh,Liyuan Liu,Yelong Shen,Dinghuai Zhang,Jingbo Shang,Jianfeng Gao,Weizhu Chen*

Main category: cs.CL

TL;DR: TRT框架通过迭代式自改进方法，在无需额外训练的情况下显著提升大语言模型的推理能力，在AIME和LiveCodeBench基准测试中实现接近完美或显著提升的性能表现


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型是否能在无需额外训练的情况下实现自我改进，解决生成多样化高质量候选方案和在没有真实监督情况下可靠选择正确答案两大核心挑战

Method: 提出测试时递归思考（TRT）框架，通过基于特定策略、累积知识和自生成验证信号的迭代生成过程来实现自我改进

Result: 开源模型在AIME-25/24上达到100%准确率，闭源模型在LiveCodeBench最难问题上提升10.4-14.8个百分点，且无需外部反馈

Conclusion: TRT框架有效证明了大语言模型具备无需额外训练的自改进能力，为解决复杂推理问题提供了新的迭代式方法

Abstract: Modern Large Language Models (LLMs) have shown rapid improvements in reasoning capabilities, driven largely by reinforcement learning (RL) with verifiable rewards. Here, we ask whether these LLMs can self-improve without the need for additional training. We identify two core challenges for such systems: (i) efficiently generating diverse, high-quality candidate solutions, and (ii) reliably selecting correct answers in the absence of ground-truth supervision. To address these challenges, we propose Test-time Recursive Thinking (TRT), an iterative self-improvement framework that conditions generation on rollout-specific strategies, accumulated knowledge, and self-generated verification signals. Using TRT, open-source models reach 100% accuracy on AIME-25/24, and on LiveCodeBench's most difficult problems, closed-source models improve by 10.4-14.8 percentage points without external feedback.

</details>


### [137] [Task--Specificity Score: Measuring How Much Instructions Really Matter for Supervision](https://arxiv.org/abs/2602.03103)
*Pritam Kadasi,Abhishek Upperwal,Mayank Singh*

Main category: cs.CL

TL;DR: 提出Task-Specificity Score (TSS)量化指令对输出预测的重要性，通过对比真实指令与替代指令的差异，并改进为TSS++以处理简单负样本问题，实验证明在有限token预算下选择任务特异性样本能提升下游性能。


<details>
  <summary>Details</summary>
Motivation: 现有指令调优中许多指令-输入-输出对仅被弱指定，同一输入在不同指令下可能产生相同输出，需要评估指令是否唯一确定目标输出。

Method: 提出TSS评分体系，通过对比真实指令与替代指令的预测差异来量化指令特异性；进一步开发TSS++使用困难替代指令和质量项来缓解简单负样本效应。

Result: 在三个指令数据集(Alpaca、Dolly-15k、NI-20)和三个开源LLM(Gemma、Llama、Qwen)上的实验表明，选择任务特异性样本在有限token预算下能提升下游性能，并可与基于困惑度和IFD的质量过滤器互补。

Conclusion: 指令特异性是评估指令-输出对质量的重要维度，TSS/TSS++方法能有效识别对模型性能提升关键的指令样本，为高效指令调优提供新视角。

Abstract: Instruction tuning is now the default way to train and adapt large language models, but many instruction--input--output pairs are only weakly specified: for a given input, the same output can remain plausible under several alternative instructions. This raises a simple question: \emph{does the instruction uniquely determine the target output?}
  We propose the \textbf{Task--Specificity Score (TSS)} to quantify how much an instruction matters for predicting its output, by contrasting the true instruction against plausible alternatives for the same input. We further introduce \textbf{TSS++}, which uses hard alternatives and a small quality term to mitigate easy-negative effects. Across three instruction datasets (\textsc{Alpaca}, \textsc{Dolly-15k}, \textsc{NI-20}) and three open LLMs (Gemma, Llama, Qwen), we show that selecting task-specific examples improves downstream performance under tight token budgets and complements quality-based filters such as perplexity and IFD.

</details>


### [138] [The Mask of Civility: Benchmarking Chinese Mock Politeness Comprehension in Large Language Models](https://arxiv.org/abs/2602.03107)
*Yitong Zhang,Yuhan Xiang,Mingxuan Liu*

Main category: cs.CL

TL;DR: 本研究系统评估了6个代表性大语言模型在中文礼貌、不礼貌和伪礼貌现象识别方面的性能差异，填补了语用理解研究空白。


<details>
  <summary>Details</summary>
Motivation: 解决现有语用理解研究的不足，探索技术在人文领域的应用，响应技术与人文共存的当代问题。

Method: 采用关系管理理论和伪礼貌模型构建三类中文语料数据集，在零样本、少样本、知识增强和混合策略四种提示条件下测试GPT-5.1和DeepSeek等6个模型。

Result: 研究提供了大语言模型在中文语用现象识别方面的性能评估结果（具体结果未在摘要中说明）。

Conclusion: 本研究是"大语言学"范式下的有意义尝试，为技术变革时代应用语用理论提供了新方法，代表了连接语言技术和人文反思的跨学科努力。

Abstract: From a pragmatic perspective, this study systematically evaluates the differences in performance among representative large language models (LLMs) in recognizing politeness, impoliteness, and mock politeness phenomena in Chinese. Addressing the existing gaps in pragmatic comprehension, the research adopts the frameworks of Rapport Management Theory and the Model of Mock Politeness to construct a three-category dataset combining authentic and simulated Chinese discourse. Six representative models, including GPT-5.1 and DeepSeek, were selected as test subjects and evaluated under four prompting conditions: zero-shot, few-shot, knowledge-enhanced, and hybrid strategies. This study serves as a meaningful attempt within the paradigm of ``Great Linguistics,'' offering a novel approach to applying pragmatic theory in the age of technological transformation. It also responds to the contemporary question of how technology and the humanities may coexist, representing an interdisciplinary endeavor that bridges linguistic technology and humanistic reflection.

</details>


### [139] [ChemPro: A Progressive Chemistry Benchmark for Large Language Models](https://arxiv.org/abs/2602.03108)
*Aaditya Baranwal,Shruti Vyas*

Main category: cs.CL

TL;DR: ChemPro是一个包含4100个化学问题对的渐进式基准测试，覆盖4个难度层级，用于评估大语言模型在化学领域的综合能力。测试结果显示LLMs在基础化学问题上表现良好，但随着问题复杂度增加准确率下降。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型在化学领域的综合能力，特别是从基础到复杂问题的渐进式推理能力，识别LLMs在科学推理和理解方面的局限性。

Method: 构建包含4100个自然语言问答对的化学基准测试，涵盖生物化学、无机化学、有机化学和物理化学四大领域，问题类型包括选择题和数值题，按难度梯度设计。评估了45+7个开源和专有LLMs。

Result: LLMs在基础化学问题上表现良好，但随着问题类型和复杂度的增加，准确率显著下降，揭示了LLMs在科学推理和理解方面的关键局限性。

Conclusion: 该研究强调了LLMs在复杂科学推理方面的不足，指出了难度维度研究的不足，并强调需要开发更强大的方法来改进LLMs的科学能力。

Abstract: We introduce ChemPro, a progressive benchmark with 4100 natural language question-answer pairs in Chemistry, across 4 coherent sections of difficulty designed to assess the proficiency of Large Language Models (LLMs) in a broad spectrum of general chemistry topics. We include Multiple Choice Questions and Numerical Questions spread across fine-grained information recall, long-horizon reasoning, multi-concept questions, problem-solving with nuanced articulation, and straightforward questions in a balanced ratio, effectively covering Bio-Chemistry, Inorganic-Chemistry, Organic-Chemistry and Physical-Chemistry. ChemPro is carefully designed analogous to a student's academic evaluation for basic to high-school chemistry. A gradual increase in the question difficulty rigorously tests the ability of LLMs to progress from solving basic problems to solving more sophisticated challenges.
  We evaluate 45+7 state-of-the-art LLMs, spanning both open-source and proprietary variants, and our analysis reveals that while LLMs perform well on basic chemistry questions, their accuracy declines with different types and levels of complexity. These findings highlight the critical limitations of LLMs in general scientific reasoning and understanding and point towards understudied dimensions of difficulty, emphasizing the need for more robust methodologies to improve LLMs.

</details>


### [140] [One Model, All Roles: Multi-Turn, Multi-Agent Self-Play Reinforcement Learning for Conversational Social Intelligence](https://arxiv.org/abs/2602.03109)
*Bowen Jiang,Taiwei Shi,Ryo Kamoi,Yuan Yuan,Camillo J. Taylor,Longqi Yang,Pei Zhou,Sihao Chen*

Main category: cs.CL

TL;DR: OMAR是一个强化学习框架，通过多轮多智能体对话自博弈让单一模型同时扮演所有对话角色，从动态社交互动中学习长期目标和复杂社交规范，无需人类监督即可涌现出精细的社会智能。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖静态单轮优化，无法有效学习长期社交互动中的复杂规范和策略。需要开发能够同时扮演所有对话角色、从动态交互中直接学习社会智能的新范式。

Method: 采用多轮多智能体对话自博弈框架，单一模型同时扮演所有参与者。实现分层优势估计（turn-level和token-level）以确保长对话训练稳定性。在SOTOPIA社交环境和狼人杀策略游戏中进行评估。

Result: 训练出的模型展现出精细的涌现社会智能，包括同理心、说服力和寻求妥协等能力。即使在竞争性场景下也能有效学习协作策略，证明了无监督学习社会智能的有效性。

Conclusion: OMAR框架成功证明了AI可以通过自博弈方式发展出丰富的社会智能，虽然存在奖励破解等实践挑战，但为群体对话中AI社会智能的进一步研究提供了激励和基础。

Abstract: This paper introduces OMAR: One Model, All Roles, a reinforcement learning framework that enables AI to develop social intelligence through multi-turn, multi-agent conversational self-play. Unlike traditional paradigms that rely on static, single-turn optimizations, OMAR allows a single model to role-play all participants in a conversation simultaneously, learning to achieve long-term goals and complex social norms directly from dynamic social interaction. To ensure training stability across long dialogues, we implement a hierarchical advantage estimation that calculates turn-level and token-level advantages. Evaluations in the SOTOPIA social environment and Werewolf strategy games show that our trained models develop fine-grained, emergent social intelligence, such as empathy, persuasion, and compromise seeking, demonstrating the effectiveness of learning collaboration even under competitive scenarios. While we identify practical challenges like reward hacking, our results show that rich social intelligence can emerge without human supervision. We hope this work incentivizes further research on AI social intelligence in group conversations.

</details>


### [141] [Short Chains, Deep Thoughts: Balancing Reasoning Efficiency and Intra-Segment Capability via Split-Merge Optimization](https://arxiv.org/abs/2602.03141)
*Runquan Gui,Jie Wang,Zhihai Wang,Chi Ma,Jianye Hao,Feng Wu*

Main category: cs.CL

TL;DR: CoSMo框架通过一致性引导的分割-合并优化方法，有效减少大推理模型的结构冗余，在提高精度的同时显著降低计算开销


<details>
  <summary>Details</summary>
Motivation: 大型推理模型依赖冗长的推理链导致显著延迟和计算开销，需要消除结构冗余而非简单限制token数量

Method: 采用分割-合并算法动态优化推理链：合并冗余段、分割逻辑间隙确保连贯性；使用结构对齐的强化学习与分段级预算监督模型训练

Result: 在多个基准测试和骨干网络上，CoSMo平均提高准确率3.3个百分点，同时减少28.7%的分段使用量

Conclusion: CoSMo通过结构优化而非简单token限制的方法，在保持推理质量的同时显著提升了推理效率，为解决大模型推理延迟问题提供了有效方案

Abstract: While Large Reasoning Models (LRMs) have demonstrated impressive capabilities in solving complex tasks through the generation of long reasoning chains, this reliance on verbose generation results in significant latency and computational overhead. To address these challenges, we propose \textbf{CoSMo} (\textbf{Co}nsistency-Guided \textbf{S}plit-\textbf{M}erge \textbf{O}ptimization), a framework designed to eliminate structural redundancy rather than indiscriminately restricting token volume. Specifically, CoSMo utilizes a split-merge algorithm that dynamically refines reasoning chains by merging redundant segments and splitting logical gaps to ensure coherence. We then employ structure-aligned reinforcement learning with a novel segment-level budget to supervise the model in maintaining efficient reasoning structures throughout training. Extensive experiments across multiple benchmarks and backbones demonstrate that CoSMo achieves superior performance, improving accuracy by \textbf{3.3} points while reducing segment usage by \textbf{28.7\%} on average compared to reasoning efficiency baselines.

</details>


### [142] [FASA: Frequency-aware Sparse Attention](https://arxiv.org/abs/2602.03152)
*Yifei Wang,Yueqi Wang,Zhenrui Yue,Huimin Zeng,Yong Wang,Ismini Lourentzou,Zhengzhong Tu,Xiangxiang Chu,Julian McAuley*

Main category: cs.CL

TL;DR: FASA是一个基于RoPE频率块级功能稀疏性发现的KV缓存优化框架，通过动态预测令牌重要性实现查询感知的令牌淘汰，显著降低内存带宽需求和计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs处理长输入时KV缓存内存占用过高的问题，现有静态方法存在信息丢失风险，动态策略启发式方法无法充分捕捉查询依赖的令牌重要性。

Method: 基于RoPE频率块级功能稀疏性发现，识别主导频率块作为令牌重要性的高效代理，仅对关键令牌子集进行聚焦注意力计算。

Result: 在长上下文任务中超越所有令牌淘汰基线，接近全KV性能（LongBench-V1仅保留256令牌即达近100%性能），在AIME24上使用18.9%缓存实现2.56倍加速。

Conclusion: FASA通过频率块级稀疏性洞察提供了一种计算免费的令牌重要性评估方法，实现了高效且鲁棒的长上下文处理，为LLM部署提供了实用的内存优化解决方案。

Abstract: The deployment of Large Language Models (LLMs) faces a critical bottleneck when handling lengthy inputs: the prohibitive memory footprint of the Key Value (KV) cache. To address this bottleneck, the token pruning paradigm leverages attention sparsity to selectively retain a small, critical subset of tokens. However, existing approaches fall short, with static methods risking irreversible information loss and dynamic strategies employing heuristics that insufficiently capture the query-dependent nature of token importance. We propose FASA, a novel framework that achieves query-aware token eviction by dynamically predicting token importance. FASA stems from a novel insight into RoPE: the discovery of functional sparsity at the frequency-chunk (FC) level. Our key finding is that a small, identifiable subset of "dominant" FCs consistently exhibits high contextual agreement with the full attention head. This provides a robust and computationally free proxy for identifying salient tokens. %making them a powerful and efficient proxy for token importance. Building on this insight, FASA first identifies a critical set of tokens using dominant FCs, and then performs focused attention computation solely on this pruned subset. % Since accessing only a small fraction of the KV cache, FASA drastically lowers memory bandwidth requirements and computational cost. Across a spectrum of long-context tasks, from sequence modeling to complex CoT reasoning, FASA consistently outperforms all token-eviction baselines and achieves near-oracle accuracy, demonstrating remarkable robustness even under constraint budgets. Notably, on LongBench-V1, FASA reaches nearly 100\% of full-KV performance when only keeping 256 tokens, and achieves 2.56$\times$ speedup using just 18.9\% of the cache on AIME24.

</details>


### [143] [Privasis: Synthesizing the Largest "Public" Private Dataset from Scratch](https://arxiv.org/abs/2602.03183)
*Hyunwoo Kim,Niloofar Mireshghallah,Michael Duan,Rui Xin,Shuyue Stella Li,Jaehun Jung,David Acuna,Qi Pang,Hanshen Xiao,G. Edward Suh,Sewoong Oh,Yulia Tsvetkov,Pang Wei Koh,Yejin Choi*

Main category: cs.CL

TL;DR: Privasis是首个百万规模完全合成的隐私敏感数据集，包含140万条记录和5510万个标注属性，用于支持隐私敏感领域研究，特别是在文本脱敏任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决隐私敏感数据研究中的数据稀缺问题，应对现代AI智能体访问敏感个人信息带来的风险。

Method: 从零开始构建完全合成的隐私数据集，包含医疗记录、法律文件、财务记录等多种文档类型，并建立文本脱敏管道进行分解和针对性脱敏处理。

Result: 构建的紧凑脱敏模型（≤4B参数）在文本脱敏任务上超越了GPT-5和Qwen-3 235B等大型语言模型。

Conclusion: Privasis数据集为隐私敏感领域研究提供了大规模高质量数据资源，将加速相关研究发展并计划公开数据、模型和代码。

Abstract: Research involving privacy-sensitive data has always been constrained by data scarcity, standing in sharp contrast to other areas that have benefited from data scaling. This challenge is becoming increasingly urgent as modern AI agents--such as OpenClaw and Gemini Agent--are granted persistent access to highly sensitive personal information. To tackle this longstanding bottleneck and the rising risks, we present Privasis (i.e., privacy oasis), the first million-scale fully synthetic dataset entirely built from scratch--an expansive reservoir of texts with rich and diverse private information--designed to broaden and accelerate research in areas where processing sensitive social data is inevitable. Compared to existing datasets, Privasis, comprising 1.4 million records, offers orders-of-magnitude larger scale with quality, and far greater diversity across various document types, including medical history, legal documents, financial records, calendars, and text messages with a total of 55.1 million annotated attributes such as ethnicity, date of birth, workplace, etc. We leverage Privasis to construct a parallel corpus for text sanitization with our pipeline that decomposes texts and applies targeted sanitization. Our compact sanitization models (<=4B) trained on this dataset outperform state-of-the-art large language models, such as GPT-5 and Qwen-3 235B. We plan to release data, models, and code to accelerate future research on privacy-sensitive domains and agents.

</details>


### [144] [ForesightKV: Optimizing KV Cache Eviction for Reasoning Models by Learning Long-Term Contribution](https://arxiv.org/abs/2602.03203)
*Zican Dong,Peiyu Liu,Junyi Li,Zhipeng Chen,Han Peng,Shuo Wang,Wayne Xin Zhao*

Main category: cs.CL

TL;DR: ForesightKV是一个基于训练的KV缓存驱逐框架，通过监督学习和强化学习相结合的方式，在长文本生成中智能预测需要驱逐的KV对，在仅使用一半缓存预算的情况下超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在生成长推理轨迹时，KV缓存会线性增长，导致内存和计算成本显著增加。现有的KV缓存驱逐方法往往无法捕捉复杂的KV依赖关系，导致性能下降。

Method: 1. 设计Golden Eviction算法，使用未来注意力分数识别最优驱逐KV对；2. 通过Pairwise Ranking Loss进行监督训练；3. 将缓存驱逐建模为马尔可夫决策过程，应用GRPO算法处理低熵token的语言建模损失增加问题。

Result: 在AIME2024和AIME2025基准测试中，ForesightKV在仅使用一半缓存预算的情况下，持续优于先前的方法，并受益于监督学习和强化学习的协同效应。

Conclusion: ForesightKV通过训练学习预测KV对驱逐，有效平衡了效率与性能，为解决长文本生成中的KV缓存问题提供了有效解决方案。

Abstract: Recently, large language models (LLMs) have shown remarkable reasoning abilities by producing long reasoning traces. However, as the sequence length grows, the key-value (KV) cache expands linearly, incurring significant memory and computation costs. Existing KV cache eviction methods mitigate this issue by discarding less important KV pairs, but often fail to capture complex KV dependencies, resulting in performance degradation. To better balance efficiency and performance, we introduce ForesightKV, a training-based KV cache eviction framework that learns to predict which KV pairs to evict during long-text generations. We first design the Golden Eviction algorithm, which identifies the optimal eviction KV pairs at each step using future attention scores. These traces and the scores at each step are then distilled via supervised training with a Pairwise Ranking Loss. Furthermore, we formulate cache eviction as a Markov Decision Process and apply the GRPO algorithm to mitigate the significant language modeling loss increase on low-entropy tokens. Experiments on AIME2024 and AIME2025 benchmarks of three reasoning models demonstrate that ForesightKV consistently outperforms prior methods under only half the cache budget, while benefiting synergistically from both supervised and reinforcement learning approaches.

</details>


### [145] [Token Sparse Attention: Efficient Long-Context Inference with Interleaved Token Selection](https://arxiv.org/abs/2602.03216)
*Dongwon Jo,Beomseok Kang,Jiwon Song,Jae-Joon Kim*

Main category: cs.CL

TL;DR: Token Sparse Attention是一种轻量级动态token级稀疏化机制，通过压缩每个注意力头的Q、K、V到缩减的token集，然后解压缩输出回原始序列，实现高达3.23倍的注意力加速，在128K上下文长度下准确率损失小于1%。


<details>
  <summary>Details</summary>
Motivation: 注意力机制的二次复杂度是长上下文推理的主要瓶颈，现有方法要么使用结构化模式稀疏化注意力图，要么在特定层永久移除token，这些方法可能保留不相关token或依赖不可逆的早期决策，无法适应不同层和头的token重要性动态变化。

Method: 提出Token Sparse Attention机制，在注意力计算期间将每个头的Q、K、V压缩到缩减的token集，然后解压缩输出回原始序列，使token信息能在后续层中被重新考虑。该方法与密集注意力实现（包括Flash Attention）完全兼容，并能与现有稀疏注意力内核无缝组合。

Result: 实验结果显示Token Sparse Attention持续改善准确率-延迟权衡，在128K上下文长度下实现高达3.23倍的注意力加速，准确率下降小于1%。

Conclusion: 动态和交错的token级稀疏化是扩展长上下文推理的互补且有效策略，为token选择和稀疏注意力的交叉设计提供了新的设计点。

Abstract: The quadratic complexity of attention remains the central bottleneck in long-context inference for large language models. Prior acceleration methods either sparsify the attention map with structured patterns or permanently evict tokens at specific layers, which can retain irrelevant tokens or rely on irreversible early decisions despite the layer-/head-wise dynamics of token importance. In this paper, we propose Token Sparse Attention, a lightweight and dynamic token-level sparsification mechanism that compresses per-head $Q$, $K$, $V$ to a reduced token set during attention and then decompresses the output back to the original sequence, enabling token information to be reconsidered in subsequent layers. Furthermore, Token Sparse Attention exposes a new design point at the intersection of token selection and sparse attention. Our approach is fully compatible with dense attention implementations, including Flash Attention, and can be seamlessly composed with existing sparse attention kernels. Experimental results show that Token Sparse Attention consistently improves accuracy-latency trade-off, achieving up to $\times$3.23 attention speedup at 128K context with less than 1% accuracy degradation. These results demonstrate that dynamic and interleaved token-level sparsification is a complementary and effective strategy for scalable long-context inference.

</details>


### [146] [ATACompressor: Adaptive Task-Aware Compression for Efficient Long-Context Processing in LLMs](https://arxiv.org/abs/2602.03226)
*Xuancheng Li,Haitao Li,Yujia Zhou,Qingyao Ai,Yiqun Liu*

Main category: cs.CL

TL;DR: ATACompressor是一个自适应任务感知压缩器，通过选择性编码和动态压缩率调整来解决长文本中的"中间丢失"问题，在保持任务性能的同时提升压缩效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型中长文本输入的"中间丢失"问题，现有压缩方法难以平衡信息保留和压缩效率，需要针对具体任务需求进行自适应压缩。

Method: 采用选择性编码器压缩任务相关部分内容，自适应分配控制器根据相关内容长度动态调整压缩率，优化资源利用率。

Result: 在HotpotQA、MSMARCO和SQUAD三个QA数据集上评估，ATACompressor在压缩效率和任务性能方面均优于现有方法。

Conclusion: ATACompressor为大语言模型的长文本处理提供了可扩展的解决方案，通过消融研究和分析实验深入理解了关键组件的贡献。

Abstract: Long-context inputs in large language models (LLMs) often suffer from the "lost in the middle" problem, where critical information becomes diluted or ignored due to excessive length. Context compression methods aim to address this by reducing input size, but existing approaches struggle with balancing information preservation and compression efficiency. We propose Adaptive Task-Aware Compressor (ATACompressor), which dynamically adjusts compression based on the specific requirements of the task. ATACompressor employs a selective encoder that compresses only the task-relevant portions of long contexts, ensuring that essential information is preserved while reducing unnecessary content. Its adaptive allocation controller perceives the length of relevant content and adjusts the compression rate accordingly, optimizing resource utilization. We evaluate ATACompressor on three QA datasets: HotpotQA, MSMARCO, and SQUAD-showing that it outperforms existing methods in terms of both compression efficiency and task performance. Our approach provides a scalable solution for long-context processing in LLMs. Furthermore, we perform a range of ablation studies and analysis experiments to gain deeper insights into the key components of ATACompressor.

</details>


### [147] [POP: Prefill-Only Pruning for Efficient Large Model Inference](https://arxiv.org/abs/2602.03295)
*Junhui He,Zhihui Fu,Jun Wang,Qingan Li*

Main category: cs.CL

TL;DR: POP是一种阶段感知推理策略，通过在计算密集的预填充阶段安全地省略深层网络层，同时保留完整模型用于敏感的解码阶段，实现了预填充延迟1.37倍加速且性能损失最小


<details>
  <summary>Details</summary>
Motivation: 现有结构化剪枝方法虽然硬件效率高，但往往导致显著的精度下降，主要原因是忽略了预填充和解码阶段之间的不对称角色分配

Method: 引入虚拟门机制进行重要性分析，发现深层对下一令牌预测（解码）关键但对上下文编码（预填充）冗余；采用独立的键值投影保持缓存完整性，边界处理策略确保首个生成令牌的准确性

Result: 在Llama-3.1、Qwen3-VL和Gemma-3等多个模型上实验表明，预填充延迟最高加速1.37倍，性能损失极小

Conclusion: POP方法有效克服了现有结构化剪枝方法的精度-效率权衡限制，为LLM和VLM的高效部署提供了新思路

Abstract: Large Language Models (LLMs) and Vision-Language Models (VLMs) have demonstrated remarkable capabilities. However, their deployment is hindered by significant computational costs. Existing structured pruning methods, while hardware-efficient, often suffer from significant accuracy degradation. In this paper, we argue that this failure stems from a stage-agnostic pruning approach that overlooks the asymmetric roles between the prefill and decode stages. By introducing a virtual gate mechanism, our importance analysis reveals that deep layers are critical for next-token prediction (decode) but largely redundant for context encoding (prefill). Leveraging this insight, we propose Prefill-Only Pruning (POP), a stage-aware inference strategy that safely omits deep layers during the computationally intensive prefill stage while retaining the full model for the sensitive decode stage. To enable the transition between stages, we introduce independent Key-Value (KV) projections to maintain cache integrity, and a boundary handling strategy to ensure the accuracy of the first generated token. Extensive experiments on Llama-3.1, Qwen3-VL, and Gemma-3 across diverse modalities demonstrate that POP achieves up to 1.37$\times$ speedup in prefill latency with minimal performance loss, effectively overcoming the accuracy-efficiency trade-off limitations of existing structured pruning methods.

</details>


### [148] [MIRROR: A Multi-Agent Framework with Iterative Adaptive Revision and Hierarchical Retrieval for Optimization Modeling in Operations Research](https://arxiv.org/abs/2602.03318)
*Yifan Shi,Jialong Shi,Jiayi Wang,Ye Fan,Jianyong Sun*

Main category: cs.CL

TL;DR: MIRROR是一个免微调的端到端多智能体框架，能够将自然语言优化问题直接转换为数学模型和求解器代码，通过执行驱动的迭代自适应修订和分层检索机制，显著提升了优化建模的准确性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统运筹学建模依赖专家经验，过程缓慢且脆弱，难以应对新场景。现有LLM方法要么需要昂贵的后训练，要么缺乏可靠的协作纠错和任务特定检索，导致输出错误。

Method: 提出MIRROR框架，包含两个核心机制：(1)执行驱动的迭代自适应修订用于自动纠错；(2)分层检索从精心策划的示例库中获取相关建模和编码示例。

Result: 在标准OR基准测试中优于现有方法，在IndustryOR和Mamo-ComplexLP等复杂工业数据集上表现突出。

Conclusion: MIRROR通过精确的外部知识注入和系统化错误纠正相结合，为非专家用户提供了高效可靠的OR建模解决方案，克服了通用LLM在专家优化任务中的根本局限性。

Abstract: Operations Research (OR) relies on expert-driven modeling-a slow and fragile process ill-suited to novel scenarios. While large language models (LLMs) can automatically translate natural language into optimization models, existing approaches either rely on costly post-training or employ multi-agent frameworks, yet most still lack reliable collaborative error correction and task-specific retrieval, often leading to incorrect outputs. We propose MIRROR, a fine-tuning-free, end-to-end multi-agent framework that directly translates natural language optimization problems into mathematical models and solver code. MIRROR integrates two core mechanisms: (1) execution-driven iterative adaptive revision for automatic error correction, and (2) hierarchical retrieval to fetch relevant modeling and coding exemplars from a carefully curated exemplar library. Experiments show that MIRROR outperforms existing methods on standard OR benchmarks, with notable results on complex industrial datasets such as IndustryOR and Mamo-ComplexLP. By combining precise external knowledge infusion with systematic error correction, MIRROR provides non-expert users with an efficient and reliable OR modeling solution, overcoming the fundamental limitations of general-purpose LLMs in expert optimization tasks.

</details>


### [149] [Accurate Failure Prediction in Agents Does Not Imply Effective Failure Prevention](https://arxiv.org/abs/2602.03338)
*Rakshith Vasudev,Melisa Russak,Dan Bikel,Waseem Alshikh*

Main category: cs.CL

TL;DR: 研究表明高准确率的LLM评论模型在实际部署时可能反而导致性能严重下降，提出了基于小规模试点测试的预部署评估方法来判断干预的利弊


<details>
  <summary>Details</summary>
Motivation: 虽然LLM评论模型的主动干预通常被认为能提高可靠性，但其在部署时的实际效果尚未被充分理解，需要研究干预可能带来的风险

Method: 提出基于小规模试点测试的预部署评估框架，通过50个任务的试点来估计干预可能带来的影响，识别干预-恢复权衡关系

Result: 高准确率的二元LLM评论模型（AUROC 0.94）可能导致26个百分点的性能下降，而在高失败率基准上仅带来2.8个百分点的有限改进

Conclusion: LLM评论模型的准确性不足以决定干预是否安全，提出的预部署测试能有效识别何时不应干预，避免部署后出现严重性能退化

Abstract: Proactive interventions by LLM critic models are often assumed to improve reliability, yet their effects at deployment time are poorly understood. We show that a binary LLM critic with strong offline accuracy (AUROC 0.94) can nevertheless cause severe performance degradation, inducing a 26 percentage point (pp) collapse on one model while affecting another by near zero pp. This variability demonstrates that LLM critic accuracy alone is insufficient to determine whether intervention is safe.
  We identify a disruption-recovery tradeoff: interventions may recover failing trajectories but also disrupt trajectories that would have succeeded. Based on this insight, we propose a pre-deployment test that uses a small pilot of 50 tasks to estimate whether intervention is likely to help or harm, without requiring full deployment. Across benchmarks, the test correctly anticipates outcomes: intervention degrades performance on high-success tasks (0 to -26 pp), while yielding a modest improvement on the high-failure ALFWorld benchmark (+2.8 pp, p=0.014). The primary value of our framework is therefore identifying when not to intervene, preventing severe regressions before deployment.

</details>


### [150] [PEGRL: Improving Machine Translation by Post-Editing Guided Reinforcement Learning](https://arxiv.org/abs/2602.03352)
*Yunzhi Shen,Hao Zhou,Xin Huang,Xue Han,Junlan Feng,Shujian Huang*

Main category: cs.CL

TL;DR: PEGRL是一个两阶段强化学习框架，通过后编辑作为辅助任务来稳定机器翻译训练，解决了传统RL方法中噪声学习信号和轨迹空间过大的问题，在多个语言对上实现了性能提升。


<details>
  <summary>Details</summary>
Motivation: 基于LLM的机器翻译强化学习方法面临蒙特卡洛回报估计带来的噪声学习信号问题，以及大轨迹空间导致全局探索优先于细粒度局部优化的挑战。

Method: 提出两阶段RL框架：第一阶段采样翻译输出构建后编辑输入，第二阶段利用后编辑任务的条件回报估计，同时支持全局探索和局部优化，并通过任务特定权重方案平衡翻译和后编辑目标。

Result: 在英语→芬兰语、英语→土耳其语和英语↔中文翻译任务上均超越RL基线方法，英语→土耳其语在COMET-KIWI指标上达到与DeepSeek-V3.2等先进LLM系统相当的性能。

Conclusion: PEGRL通过后编辑辅助任务有效解决了翻译导向RL的稳定性问题，提供了更高效的样本利用率和更好的性能表现，为LLM机器翻译的强化学习训练提供了新思路。

Abstract: Reinforcement learning (RL) has shown strong promise for LLM-based machine translation, with recent methods such as GRPO demonstrating notable gains; nevertheless, translation-oriented RL remains challenged by noisy learning signals arising from Monte Carlo return estimation, as well as a large trajectory space that favors global exploration over fine-grained local optimization. We introduce \textbf{PEGRL}, a \textit{two-stage} RL framework that uses post-editing as an auxiliary task to stabilize training and guide overall optimization. At each iteration, translation outputs are sampled to construct post-editing inputs, allowing return estimation in the post-editing stage to benefit from conditioning on the current translation behavior, while jointly supporting both global exploration and fine-grained local optimization. A task-specific weighting scheme further balances the contributions of translation and post-editing objectives, yielding a biased yet more sample-efficient estimator. Experiments on English$\to$Finnish, English$\to$Turkish, and English$\leftrightarrow$Chinese show consistent gains over RL baselines, and for English$\to$Turkish, performance on COMET-KIWI is comparable to advanced LLM-based systems (DeepSeek-V3.2).

</details>


### [151] [Pursuing Best Industrial Practices for Retrieval-Augmented Generation in the Medical Domain](https://arxiv.org/abs/2602.03368)
*Wei Zhu*

Main category: cs.CL

TL;DR: 该论文系统分析了检索增强生成(RAG)系统的最佳实践，特别是在医疗领域，通过组件分析、替代方案提出和系统评估，揭示了性能与效率之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 工业应用中基于大语言模型的RAG系统缺乏统一的最佳实践标准，特别是在医疗领域，需要明确系统组件、组织方式和实现方法。

Method: 首先仔细分析RAG系统的各个组件并提出实用替代方案，然后在三类任务上进行系统性评估，探索提升RAG系统的最佳实践。

Result: 揭示了改进RAG系统的最佳实践方法，以及基于LLM的RAG系统如何在性能与效率之间做出权衡。

Conclusion: 该研究为工业应用特别是医疗领域的RAG系统开发提供了实用的指导原则和组件选择建议，帮助开发者在系统性能与运行效率之间找到最佳平衡点。

Abstract: While retrieval augmented generation (RAG) has been swiftly adopted in industrial applications based on large language models (LLMs), there is no consensus on what are the best practices for building a RAG system in terms of what are the components, how to organize these components and how to implement each component for the industrial applications, especially in the medical domain. In this work, we first carefully analyze each component of the RAG system and propose practical alternatives for each component. Then, we conduct systematic evaluations on three types of tasks, revealing the best practices for improving the RAG system and how LLM-based RAG systems make trade-offs between performance and efficiency.

</details>


### [152] [Towards Distillation-Resistant Large Language Models: An Information-Theoretic Perspective](https://arxiv.org/abs/2602.03396)
*Hao Fang,Tianyi Zhang,Tianqu Zhuang,Jiawei Kong,Kuofeng Gao,Bin Chen,Leqi Liang,Shu-Tao Xia,Ke Xu*

Main category: cs.CL

TL;DR: 提出一种基于信息论的防御方法，通过条件互信息最小化来保护大语言模型免受基于logit的知识蒸馏攻击，在保持模型性能的同时有效防止模型提取。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法主要针对文本蒸馏，而基于logit的蒸馏攻击缺乏有效防护，需要从信息论角度解决模型知识产权保护问题。

Method: 使用条件互信息(CMI)量化教师模型logit中的蒸馏相关信息，通过学习变换矩阵来净化输出，采用CMI启发的抗蒸馏目标优化变换过程。

Result: 在多个大语言模型和强蒸馏算法上的实验表明，该方法显著降低蒸馏性能，同时保持任务准确性，有效保护模型知识产权。

Conclusion: 从信息论角度提出的CMI最小化方法为logit蒸馏防御提供了有效解决方案，实现了蒸馏抵抗与模型性能的良好平衡。

Abstract: Proprietary large language models (LLMs) embody substantial economic value and are generally exposed only as black-box APIs, yet adversaries can still exploit their outputs to extract knowledge via distillation. Existing defenses focus exclusively on text-based distillation, leaving the important logit-based distillation largely unexplored. In this work, we analyze this problem and present an effective solution from an information-theoretic perspective. We characterize distillation-relevant information in teacher outputs using the conditional mutual information (CMI) between teacher logits and input queries conditioned on ground-truth labels. This quantity captures contextual information beneficial for model extraction, motivating us to defend distillation via CMI minimization. Guided by our theoretical analysis, we propose learning a transformation matrix that purifies the original outputs to enhance distillation resistance. We further derive a CMI-inspired anti-distillation objective to optimize this transformation, which effectively removes distillation-relevant information while preserving output utility. Extensive experiments across multiple LLMs and strong distillation algorithms demonstrate that the proposed method significantly degrades distillation performance while preserving task accuracy, effectively protecting models' intellectual property.

</details>


### [153] [Verified Critical Step Optimization for LLM Agents](https://arxiv.org/abs/2602.03412)
*Mukai Li,Qingcheng Zeng,Tianqing Fang,Zhenwen Liang,Linfeng Song,Qi Liu,Haitao Mi,Dong Yu*

Main category: cs.CL

TL;DR: CSO方法通过聚焦于经过验证的关键步骤进行偏好学习，有效解决长时程任务中奖励分配问题，相比传统方法在性能和效率上均有显著提升


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型代理在处理复杂长时程任务时面临的奖励分配挑战：结果级奖励无法精确归因中间步骤，估计的步骤级奖励存在系统噪声，蒙特卡洛采样方法计算成本过高

Method: Critical Step Optimization (CSO)方法：从失败轨迹开始，使用过程奖励模型识别候选关键步骤，利用专家模型提出高质量替代方案，通过策略模型继续执行直至任务完成，仅使用成功纠正结果的替代方案作为DPO训练数据

Result: 在GAIA-Text-103和XBench-DeepSearch上分别实现了37%和26%的相对改进，显著优于其他后训练方法，同时仅需对16%的轨迹步骤进行监督

Conclusion: 选择性验证学习在代理后训练中具有显著效果，CSO方法通过关注关键决策点提供了细粒度、可验证的监督，同时避免了轨迹级粗糙性和步骤级噪声

Abstract: As large language model agents tackle increasingly complex long-horizon tasks, effective post-training becomes critical. Prior work faces fundamental challenges: outcome-only rewards fail to precisely attribute credit to intermediate steps, estimated step-level rewards introduce systematic noise, and Monte Carlo sampling approaches for step reward estimation incur prohibitive computational cost. Inspired by findings that only a small fraction of high-entropy tokens drive effective RL for reasoning, we propose Critical Step Optimization (CSO), which focuses preference learning on verified critical steps, decision points where alternate actions demonstrably flip task outcomes from failure to success. Crucially, our method starts from failed policy trajectories rather than expert demonstrations, directly targeting the policy model's weaknesses. We use a process reward model (PRM) to identify candidate critical steps, leverage expert models to propose high-quality alternatives, then continue execution from these alternatives using the policy model itself until task completion. Only alternatives that the policy successfully executes to correct outcomes are verified and used as DPO training data, ensuring both quality and policy reachability. This yields fine-grained, verifiable supervision at critical decisions while avoiding trajectory-level coarseness and step-level noise. Experiments on GAIA-Text-103 and XBench-DeepSearch show that CSO achieves 37% and 26% relative improvement over the SFT baseline and substantially outperforms other post-training methods, while requiring supervision at only 16% of trajectory steps. This demonstrates the effectiveness of selective verification-based learning for agent post-training.

</details>


### [154] [FactNet: A Billion-Scale Knowledge Graph for Multilingual Factual Grounding](https://arxiv.org/abs/2602.03417)
*Yingli Shen,Wen Lai,Jie Zhou,Xueren Zhang,Yudong Wang,Kangyang Luo,Shuo Wang,Ge Gao,Alexander Fraser,Maosong Sun*

Main category: cs.CL

TL;DR: FactNet是一个大规模开源知识资源，整合了17亿原子断言和30.1亿可审计证据指针，基于316个维基百科版本构建，提供高精度可追溯的知识基础。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs存在的事实幻觉和缺乏可追溯来源的问题，弥合结构化知识库与基于文本的接地资源之间的差距。

Method: 采用严格确定性的构建流程，从316个维基百科版本中提取原子断言和证据指针，确保每个证据单元都能以字节级精度恢复。

Result: 经过广泛审计确认达到92.1%的高接地精度，即使在长尾语言中也表现良好。建立了FactNet-Bench评估套件，支持知识图谱补全、问答和事实核查任务。

Conclusion: FactNet为社区提供了可重现的基础资源，可用于训练和评估可信赖、可验证的多语言系统。

Abstract: While LLMs exhibit remarkable fluency, their utility is often compromised by factual hallucinations and a lack of traceable provenance. Existing resources for grounding mitigate this but typically enforce a dichotomy: they offer either structured knowledge without textual context (e.g., knowledge bases) or grounded text with limited scale and linguistic coverage. To bridge this gap, we introduce FactNet, a massive, open-source resource designed to unify 1.7 billion atomic assertions with 3.01 billion auditable evidence pointers derived exclusively from 316 Wikipedia editions. Unlike recent synthetic approaches, FactNet employs a strictly deterministic construction pipeline, ensuring that every evidence unit is recoverable with byte-level precision. Extensive auditing confirms a high grounding precision of 92.1%, even in long-tail languages. Furthermore, we establish FactNet-Bench, a comprehensive evaluation suite for Knowledge Graph Completion, Question Answering, and Fact Checking. FactNet provides the community with a foundational, reproducible resource for training and evaluating trustworthy, verifiable multilingual systems.

</details>


### [155] [A-RAG: Scaling Agentic Retrieval-Augmented Generation via Hierarchical Retrieval Interfaces](https://arxiv.org/abs/2602.03442)
*Mingxuan Du,Benfeng Xu,Chiwei Zhu,Shaohan Wang,Pengyu Wang,Xiaorui Wang,Zhendong Mao*

Main category: cs.CL

TL;DR: A-RAG是一个代理式RAG框架，通过向模型暴露分层检索接口，让模型参与检索决策，实现了比传统RAG方法更好的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统无法充分利用前沿语言模型的推理和长程工具使用能力，要么采用单次检索拼接方式，要么预定义工作流程，都不允许模型参与检索决策。

Method: 提出A-RAG框架，提供三种检索工具：关键词搜索、语义搜索和块读取，使代理能够自适应地在多个粒度上搜索和检索信息。

Result: 在多个开放域QA基准测试中，A-RAG始终优于现有方法，检索token数量相当或更少，有效利用了模型能力并动态适应不同RAG任务。

Conclusion: A-RAG成功展示了让模型参与检索决策的价值，系统研究了模型规模和测试时计算量的扩展性，为未来研究提供了代码和评估套件。

Abstract: Frontier language models have demonstrated strong reasoning and long-horizon tool-use capabilities. However, existing RAG systems fail to leverage these capabilities. They still rely on two paradigms: (1) designing an algorithm that retrieves passages in a single shot and concatenates them into the model's input, or (2) predefining a workflow and prompting the model to execute it step-by-step. Neither paradigm allows the model to participate in retrieval decisions, preventing efficient scaling with model improvements. In this paper, we introduce A-RAG, an Agentic RAG framework that exposes hierarchical retrieval interfaces directly to the model. A-RAG provides three retrieval tools: keyword search, semantic search, and chunk read, enabling the agent to adaptively search and retrieve information across multiple granularities. Experiments on multiple open-domain QA benchmarks show that A-RAG consistently outperforms existing approaches with comparable or lower retrieved tokens, demonstrating that A-RAG effectively leverages model capabilities and dynamically adapts to different RAG tasks. We further systematically study how A-RAG scales with model size and test-time compute. We will release our code and evaluation suite to facilitate future research. Code and evaluation suite are available at https://github.com/Ayanami0730/arag.

</details>


### [156] [Preferences for Idiomatic Language are Acquired Slowly -- and Forgotten Quickly: A Case Study on Swedish](https://arxiv.org/abs/2602.03484)
*Jenny Kunz*

Main category: cs.CL

TL;DR: 研究探讨语言模型在预训练和英语到瑞典语适应过程中对习语性和语言可接受性的偏好发展。通过训练瑞典语模型和微调英语预训练模型，使用最小对比对评估模型偏好。发现习语能力发展较慢，大规模模型持续改善，但机器翻译指令调优会削弱习语偏好。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型在习语性和语言可接受性方面的偏好发展模式，特别是在多语言迁移学习场景下，了解模型如何获取和处理语言中的习语特性。

Method: 1) 从头训练瑞典语模型和微调英语预训练模型；2) 使用最小对比对探测模型偏好；3) 创建两个新数据集：习语与变体对比、习语瑞典语与翻译体对比；4) 在不同检查点评估模型性能。

Result: 习语能力比其他语言能力（语法和词汇正确性）发展更慢；大规模模型（8B）在习语相关任务上持续改进；机器翻译指令调优会快速削弱模型对习语语言的偏好。

Conclusion: 习语习得是语言模型发展的后期能力，当前多语言迁移学习方法（特别是使用机器翻译数据）可能损害模型的习语表达能力，需要开发更好的方法来保持语言的地道性。

Abstract: In this study, we investigate how language models develop preferences for \textit{idiomatic} as compared to \textit{linguistically acceptable} Swedish, both during pretraining and when adapting a model from English to Swedish. To do so, we train models on Swedish from scratch and by fine-tuning English-pretrained models, probing their preferences at various checkpoints using minimal pairs that differ in linguistic acceptability or idiomaticity. For linguistic acceptability, we adapt existing benchmarks into a minimal-pair format. To assess idiomaticity, we introduce two novel datasets: one contrasting conventionalized idioms with plausible variants, and another contrasting idiomatic Swedish with Translationese. Our findings suggest that idiomatic competence emerges more slowly than other linguistic abilities, including grammatical and lexical correctness. While longer training yields diminishing returns for most tasks, idiom-related performance continues to improve, particularly in the largest model tested (8B). However, instruction tuning on data machine-translated from English -- the common approach for languages with little or no native instruction data -- causes models to rapidly lose their preference for idiomatic language.

</details>


### [157] [Self-Verification Dilemma: Experience-Driven Suppression of Overused Checking in LLM Reasoning](https://arxiv.org/abs/2602.03485)
*Quanyu Long,Kai Jie Jiang,Jianda Chen,Xu Guo,Leilei Gan,Wenya Wang*

Main category: cs.CL

TL;DR: LRMs过度使用确认性自验证步骤，新框架通过历史经验检测并抑制不必要的验证，减少20.3%的token使用同时保持准确性


<details>
  <summary>Details</summary>
Motivation: 发现大型推理模型中大量反思步骤是重复确认中间结果的自我验证，但这些验证大多为确认性而非纠正性，很少真正发现错误，存在使用频率与实际效用不匹配的问题

Method: 提出经验驱动的测试时框架：检测重检查行为激活、查询离线经验池中的历史验证结果、通过高效检索评估验证必要性，当历史经验表明不必要时发送抑制信号让模型继续推理

Result: 在多个模型和基准测试中，该方法减少token使用达20.3%，同时保持准确性，在某些数据集上甚至提高了准确率

Conclusion: 基于历史经验的验证抑制框架有效解决了LRMs中自验证过度使用的问题，实现了计算效率提升而不牺牲性能

Abstract: Large Reasoning Models (LRMs) achieve strong performance by generating long reasoning traces with reflection. Through a large-scale empirical analysis, we find that a substantial fraction of reflective steps consist of self-verification (recheck) that repeatedly confirm intermediate results. These rechecks occur frequently across models and benchmarks, yet the vast majority are confirmatory rather than corrective, rarely identifying errors and altering reasoning outcomes. This reveals a mismatch between how often self-verification is activated and how often it is actually useful. Motivated by this, we propose a novel, experience-driven test-time framework that reduces the overused verification. Our method detects the activation of recheck behavior, consults an offline experience pool of past verification outcomes, and estimates whether a recheck is likely unnecessary via efficient retrieval. When historical experience suggests unnecessary, a suppression signal redirects the model to proceed. Across multiple model and benchmarks, our approach reduces token usage up to 20.3% while maintaining the accuracy, and in some datasets even yields accuracy improvements.

</details>


### [158] [Learning to Reason Faithfully through Step-Level Faithfulness Maximization](https://arxiv.org/abs/2602.03507)
*Runquan Gui,Yafu Li,Xiaoye Qu,Ziyan Liu,Yeqiu Cheng,Yu Cheng*

Main category: cs.CL

TL;DR: FaithRL是一个强化学习框架，通过几何奖励设计和基于忠实度的优势调制机制，直接优化多步推理的忠实度，减少幻觉同时保持答案正确性。


<details>
  <summary>Details</summary>
Motivation: 现有RLVR方法依赖稀疏结果奖励，缺乏对中间步骤的监督，导致过度自信和虚假推理，增加幻觉问题。

Method: 提出忠实度最大化目标，设计几何奖励函数和忠实度感知优势调制机制，对不支持步骤进行惩罚同时保留有效部分推导。

Result: 在多种骨干模型和基准测试中，FaithRL持续降低幻觉率，保持（并经常提升）答案正确性，提高逐步推理忠实度和泛化鲁棒性。

Conclusion: FaithRL通过直接优化推理忠实度，有效解决了RLVR中的幻觉问题，为提升语言模型推理可靠性提供了有效框架。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has markedly improved the performance of Large Language Models (LLMs) on tasks requiring multi-step reasoning. However, most RLVR pipelines rely on sparse outcome-based rewards, providing little supervision over intermediate steps and thus encouraging over-confidence and spurious reasoning, which in turn increases hallucinations. To address this, we propose FaithRL, a general reinforcement learning framework that directly optimizes reasoning faithfulness. We formalize a faithfulness-maximization objective and theoretically show that optimizing it mitigates over-confidence. To instantiate this objective, we introduce a geometric reward design and a faithfulness-aware advantage modulation mechanism that assigns step-level credit by penalizing unsupported steps while preserving valid partial derivations. Across diverse backbones and benchmarks, FaithRL consistently reduces hallucination rates while maintaining (and often improving) answer correctness. Further analysis confirms that FaithRL increases step-wise reasoning faithfulness and generalizes robustly. Our code is available at https://github.com/aintdoin/FaithRL.

</details>


### [159] [Can Large Language Models Generalize Procedures Across Representations?](https://arxiv.org/abs/2602.03542)
*Fangru Lin,Valentin Hofmann,Xingchen Wan,Weixing Wang,Zifeng Ding,Anthony G. Cohn,Janet B. Pierrehumbert*

Main category: cs.CL

TL;DR: 论文研究了LLM在不同表示形式（代码、图、自然语言）间的泛化能力，发现仅训练符号数据或自然语言数据存在局限性，提出两阶段数据课程方法显著提升跨表示泛化性能，1.5B参数模型可接近GPT-4o在自然语言规划任务上的零样本表现。


<details>
  <summary>Details</summary>
Motivation: 现实世界任务常以自然语言指定，但LLM主要在符号表示（代码、图）上训练测试，需要研究LLM在不同表示形式间的泛化能力差距。

Method: 提出两阶段数据课程方法：先训练符号数据（代码/图），再训练自然语言数据，通过生成类比机制促进跨表示泛化。

Result: 课程训练显著提升模型性能，1.5B Qwen模型在自然语言规划任务上接近GPT-4o的零样本表现，证明方法有效。

Conclusion: 两阶段数据课程能有效解决LLM跨表示泛化问题，将生成类比作为核心机制，为多模态学习提供新方向。

Abstract: Large language models (LLMs) are trained and tested extensively on symbolic representations such as code and graphs, yet real-world user tasks are often specified in natural language. To what extent can LLMs generalize across these representations? Here, we approach this question by studying isomorphic tasks involving procedures represented in code, graphs, and natural language (e.g., scheduling steps in planning). We find that training LLMs with popular post-training methods on graphs or code data alone does not reliably generalize to corresponding natural language tasks, while training solely on natural language can lead to inefficient performance gains. To address this gap, we propose a two-stage data curriculum that first trains on symbolic, then natural language data. The curriculum substantially improves model performance across model families and tasks. Remarkably, a 1.5B Qwen model trained by our method can closely match zero-shot GPT-4o in naturalistic planning. Finally, our analysis suggests that successful cross-representation generalization can be interpreted as a form of generative analogy, which our curriculum effectively encourages.

</details>


### [160] [SEAD: Self-Evolving Agent for Multi-Turn Service Dialogue](https://arxiv.org/abs/2602.03548)
*Yuqin Dai,Ning Gao,Wei Zhang,Jie Wang,Zichen Luo,Jinpeng Wang,Yujie Wang,Ruiyuan Wu,Chaozheng Wang*

Main category: cs.CL

TL;DR: SEAD框架通过解耦用户建模为Profile Controller和User Role-play Model两个组件，无需大规模人工标注即可训练服务对话代理，显著提升任务完成率和对话效率。


<details>
  <summary>Details</summary>
Motivation: 当前方法在服务对话中表现不佳，主要原因是依赖噪声大、质量低的人类对话数据，以及难以模拟真实的目标导向用户行为。

Method: 提出SEAD框架，将用户建模分解为：1) Profile Controller生成多样化用户状态以管理训练课程；2) User Role-play Model专注于真实角色扮演，确保环境提供自适应训练场景而非不公平对抗。

Result: SEAD显著超越开源基础模型和闭源商业模型，任务完成率提高17.6%，对话效率提升11.1%。

Conclusion: SEAD框架有效解决了服务对话中的数据稀缺和用户行为模拟难题，为无需大规模人工标注的对话代理训练提供了有效解决方案。

Abstract: Large Language Models have demonstrated remarkable capabilities in open-domain dialogues. However, current methods exhibit suboptimal performance in service dialogues, as they rely on noisy, low-quality human conversation data. This limitation arises from data scarcity and the difficulty of simulating authentic, goal-oriented user behaviors. To address these issues, we propose SEAD (Self-Evolving Agent for Service Dialogue), a framework that enables agents to learn effective strategies without large-scale human annotations. SEAD decouples user modeling into two components: a Profile Controller that generates diverse user states to manage training curriculum, and a User Role-play Model that focuses on realistic role-playing. This design ensures the environment provides adaptive training scenarios rather than acting as an unfair adversary. Experiments demonstrate that SEAD significantly outperforms Open-source Foundation Models and Closed-source Commercial Models, improving task completion rate by 17.6% and dialogue efficiency by 11.1%. Code is available at: https://github.com/Da1yuqin/SEAD.

</details>


### [161] [Assessing the Impact of Typological Features on Multilingual Machine Translation in the Age of Large Language Models](https://arxiv.org/abs/2602.03551)
*Vitalii Hirak,Jaap Jumelet,Arianna Bisazza*

Main category: cs.CL

TL;DR: 分析显示目标语言类型学特征显著影响多语言翻译模型质量，即使控制数据资源和文字系统等因素后依然如此。某些类型学特征的语言能从更广泛的输出空间搜索中获益，建议采用替代解码策略。


<details>
  <summary>Details</summary>
Motivation: 尽管多语言建模取得重大进展，但不同语言间仍存在显著质量差异。除了训练资源不均的明显影响外，类型学特性也被认为是决定语言建模内在难度的因素，但现有证据主要基于小型单语模型或从头训练的双语翻译模型。

Method: 分析两个大型预训练多语言翻译模型NLLB-200（编码器-解码器结构）和Tower+（仅解码器结构），基于FLORES+评估基准中的212种语言，控制数据资源和文字系统等简单因素，研究目标语言类型学对翻译质量的影响。

Result: 发现目标语言类型学显著影响两种模型的翻译质量。具有特定类型学特性的语言能从更广泛的输出空间搜索中获益，表明这些语言可能受益于标准从左到右束搜索之外的替代解码策略。

Conclusion: 语言类型学特征是影响多语言翻译模型性能的重要因素，为改进解码策略提供了新方向。研究发布了212种语言的细粒度类型学属性数据集，促进该领域进一步研究。

Abstract: Despite major advances in multilingual modeling, large quality disparities persist across languages. Besides the obvious impact of uneven training resources, typological properties have also been proposed to determine the intrinsic difficulty of modeling a language. The existing evidence, however, is mostly based on small monolingual language models or bilingual translation models trained from scratch. We expand on this line of work by analyzing two large pre-trained multilingual translation models, NLLB-200 and Tower+, which are state-of-the-art representatives of encoder-decoder and decoder-only machine translation, respectively. Based on a broad set of languages, we find that target language typology drives translation quality of both models, even after controlling for more trivial factors, such as data resourcedness and writing script. Additionally, languages with certain typological properties benefit more from a wider search of the output space, suggesting that such languages could profit from alternative decoding strategies beyond the standard left-to-right beam search. To facilitate further research in this area, we release a set of fine-grained typological properties for 212 languages of the FLORES+ MT evaluation benchmark.

</details>


### [162] [HySparse: A Hybrid Sparse Attention Architecture with Oracle Token Selection and KV Cache Sharing](https://arxiv.org/abs/2602.03560)
*Yizhao Gao,Jianyu Wei,Qihao Zhang,Yu Cheng,Shimao Chen,Zhengju Tang,Zihan Jiang,Yifan Song,Hailin Zhang,Liang Zhao,Bo Yang,Gang Wang,Shijie Cao,Fuli Luo*

Main category: cs.CL

TL;DR: HySparse是一种混合稀疏注意力架构，通过在每层全注意力层后插入多个稀疏注意力层，利用前层全注意力信息精确选择重要token并重用KV缓存，显著降低计算和内存开销同时提升性能


<details>
  <summary>Details</summary>
Motivation: 解决现有稀疏注意力方法的两个根本限制：1）需要额外代理预测token重要性增加复杂度；2）减少计算但不节省KV缓存内存

Method: 设计混合架构，让稀疏层直接从前面全注意力层获取token选择和KV缓存，全注意力层作为精确的oracle指导稀疏层

Result: 在7B密集和80B MoE模型上均优于全注意力和混合SWA基线，80B MoE模型仅需5层全注意力即可实现近10倍KV缓存节省和性能提升

Conclusion: HySparse通过全注意力层指导稀疏层的设计理念，有效平衡了计算效率、内存节省和模型性能，为大规模语言模型提供了实用的高效注意力解决方案

Abstract: This work introduces Hybrid Sparse Attention (HySparse), a new architecture that interleaves each full attention layer with several sparse attention layers. While conceptually simple, HySparse strategically derives each sparse layer's token selection and KV caches directly from the preceding full attention layer. This architecture resolves two fundamental limitations of prior sparse attention methods. First, conventional approaches typically rely on additional proxies to predict token importance, introducing extra complexity and potentially suboptimal performance. In contrast, HySparse uses the full attention layer as a precise oracle to identify important tokens. Second, existing sparse attention designs often reduce computation without saving KV cache. HySparse enables sparse attention layers to reuse the full attention KV cache, thereby reducing both computation and memory. We evaluate HySparse on both 7B dense and 80B MoE models. Across all settings, HySparse consistently outperforms both full attention and hybrid SWA baselines. Notably, in the 80B MoE model with 49 total layers, only 5 layers employ full attention, yet HySparse achieves substantial performance gains while reducing KV cache storage by nearly 10x.

</details>


### [163] [ACL: Aligned Contrastive Learning Improves BERT and Multi-exit BERT Fine-tuning](https://arxiv.org/abs/2602.03563)
*Wei Zhu*

Main category: cs.CL

TL;DR: 提出对齐对比学习(ACL)框架，解决监督学习中交叉熵损失与对比学习目标冲突的问题，通过标签嵌入对齐和梯度优化策略提升模型性能，特别是在多出口BERT模型中显著改善质量-速度权衡。


<details>
  <summary>Details</summary>
Motivation: 监督学习中的对比学习研究较少，实验发现交叉熵损失与对比学习目标存在冲突，阻碍了对比学习在监督设置中的应用。

Method: 提出ACL框架：1) ACL-Embed将标签嵌入作为额外增强样本进行对比学习对齐；2) ACL-Grad在目标冲突时舍弃ACL-Embed项；3) ACL-CL让教师出口指导浅层学生出口优化。

Result: 在GLUE基准测试中：ACL-BERT优于或与CE、CE+SCL相当；ACL-CL显著超越基线方法，为低延迟应用提供更好的质量-速度权衡。

Conclusion: ACL框架有效解决了监督学习中对比学习与交叉熵损失的冲突问题，特别是在多出口BERT模型中实现了显著的性能提升和更好的推理效率。

Abstract: Despite its success in self-supervised learning, contrastive learning is less studied in the supervised setting. In this work, we first use a set of pilot experiments to show that in the supervised setting, the cross-entropy loss objective (CE) and the contrastive learning objective often conflict with each other, thus hindering the applications of CL in supervised settings. To resolve this problem, we introduce a novel \underline{A}ligned \underline{C}ontrastive \underline{L}earning (ACL) framework. First, ACL-Embed regards label embeddings as extra augmented samples with different labels and employs contrastive learning to align the label embeddings with its samples' representations. Second, to facilitate the optimization of ACL-Embed objective combined with the CE loss, we propose ACL-Grad, which will discard the ACL-Embed term if the two objectives are in conflict. To further enhance the performances of intermediate exits of multi-exit BERT, we further propose cross-layer ACL (ACL-CL), which is to ask the teacher exit to guide the optimization of student shallow exits. Extensive experiments on the GLUE benchmark results in the following takeaways: (a) ACL-BRT outperforms or performs comparably with CE and CE+SCL on the GLUE tasks; (b) ACL, especially CL-ACL, significantly surpasses the baseline methods on the fine-tuning of multi-exit BERT, thus providing better quality-speed tradeoffs for low-latency applications.

</details>


### [164] [Use Graph When It Needs: Efficiently and Adaptively Integrating Retrieval-Augmented Generation with Graphs](https://arxiv.org/abs/2602.03578)
*Su Dong,Qinggang Zhang,Yilin Xiao,Shengyuan Chen,Chuang Zhou,Xiao Huang*

Main category: cs.CL

TL;DR: EA-GraphRAG：基于语法感知的复杂度分析，动态选择RAG或GraphRAG处理查询的自适应框架，显著提升准确率并降低延迟


<details>
  <summary>Details</summary>
Motivation: 传统GraphRAG对所有查询采用统一处理方式，导致简单查询性能下降和延迟过高，需要根据查询复杂度进行自适应选择

Method: 提出三阶段框架：语法特征构造器解析查询结构特征，轻量级复杂度评分器计算连续复杂度分数，基于分数的路由策略选择RAG或GraphRAG处理

Result: 在包含单跳和多跳QA的基准测试中，EA-GraphRAG显著提高了准确率，降低了延迟，在混合查询场景下达到最先进性能

Conclusion: 通过语法感知的复杂度分析和自适应路由机制，EA-GraphRAG有效解决了GraphRAG在现实场景中的性能问题，实现了高效的知识增强生成

Abstract: Large language models (LLMs) often struggle with knowledge-intensive tasks due to hallucinations and outdated parametric knowledge. While Retrieval-Augmented Generation (RAG) addresses this by integrating external corpora, its effectiveness is limited by fragmented information in unstructured domain documents. Graph-augmented RAG (GraphRAG) emerged to enhance contextual reasoning through structured knowledge graphs, yet paradoxically underperforms vanilla RAG in real-world scenarios, exhibiting significant accuracy drops and prohibitive latency despite gains on complex queries. We identify the rigid application of GraphRAG to all queries, regardless of complexity, as the root cause. To resolve this, we propose an efficient and adaptive GraphRAG framework called EA-GraphRAG that dynamically integrates RAG and GraphRAG paradigms through syntax-aware complexity analysis. Our approach introduces: (i) a syntactic feature constructor that parses each query and extracts a set of structural features; (ii) a lightweight complexity scorer that maps these features to a continuous complexity score; and (iii) a score-driven routing policy that selects dense RAG for low-score queries, invokes graph-based retrieval for high-score queries, and applies complexity-aware reciprocal rank fusion to handle borderline cases. Extensive experiments on a comprehensive benchmark, consisting of two single-hop and two multi-hop QA benchmarks, demonstrate that our EA-GraphRAG significantly improves accuracy, reduces latency, and achieves state-of-the-art performance in handling mixed scenarios involving both simple and complex queries.

</details>


### [165] [$V_0$: A Generalist Value Model for Any Policy at State Zero](https://arxiv.org/abs/2602.03584)
*Yi-Kai Zhang,Zhiyuan Yao,Hongyan Hao,Yueqing Sun,Qi Gu,Hui Su,Xunliang Cai,De-Chuan Zhan,Han-Jia Ye*

Main category: cs.CL

TL;DR: 提出了V₀通用价值模型，通过将策略动态能力作为显式上下文输入来估计任意模型在未见提示上的期望性能，无需参数更新，解决了传统价值模型需要同步训练的问题，在GRPO训练中实现高效采样预算分配，在部署中作为路由调度器。


<details>
  <summary>Details</summary>
Motivation: 传统Actor-Critic方法中价值模型需要与策略模型同步训练，计算开销大；GRPO方法虽消除价值模型但需要大量采样来维持基线估计稳定性。需要一种无需参数更新就能准确估计策略性能的方法。

Method: 提出V₀通用价值模型，将策略动态能力作为显式上下文输入，利用指令-性能对历史记录动态分析模型能力，专注于初始状态（State Zero）的价值估计，作为资源调度器和路由器的核心组件。

Result: 实证结果表明V₀显著优于启发式预算分配方法，在LLM路由任务中实现了性能与成本的帕累托最优权衡。

Conclusion: V₀模型通过重新构建价值估计范式，成功解决了传统价值模型训练开销大的问题，为策略优化和模型部署提供了高效的价值估计解决方案。

Abstract: Policy gradient methods rely on a baseline to measure the relative advantage of an action, ensuring the model reinforces behaviors that outperform its current average capability. In the training of Large Language Models (LLMs) using Actor-Critic methods (e.g., PPO), this baseline is typically estimated by a Value Model (Critic) often as large as the policy model itself. However, as the policy continuously evolves, the value model requires expensive, synchronous incremental training to accurately track the shifting capabilities of the policy. To avoid this overhead, Group Relative Policy Optimization (GRPO) eliminates the coupled value model by using the average reward of a group of rollouts as the baseline; yet, this approach necessitates extensive sampling to maintain estimation stability. In this paper, we propose $V_0$, a Generalist Value Model capable of estimating the expected performance of any model on unseen prompts without requiring parameter updates. We reframe value estimation by treating the policy's dynamic capability as an explicit context input; specifically, we leverage a history of instruction-performance pairs to dynamically profile the model, departing from the traditional paradigm that relies on parameter fitting to perceive capability shifts. Focusing on value estimation at State Zero (i.e., the initial prompt, hence $V_0$), our model serves as a critical resource scheduler. During GRPO training, $V_0$ predicts success rates prior to rollout, allowing for efficient sampling budget allocation; during deployment, it functions as a router, dispatching instructions to the most cost-effective and suitable model. Empirical results demonstrate that $V_0$ significantly outperforms heuristic budget allocation and achieves a Pareto-optimal trade-off between performance and cost in LLM routing tasks.

</details>


### [166] [CL-bench: A Benchmark for Context Learning](https://arxiv.org/abs/2602.03587)
*Shihan Dou,Ming Zhang,Zhangyue Yin,Chenhao Huang,Yujiong Shen,Junzhe Wang,Jiayi Chen,Yuchen Ni,Junjie Ye,Cheng Zhang,Huaibing Xie,Jianglu Hu,Shaolei Wang,Weichao Wang,Yanling Xiao,Yiting Liu,Zenan Xu,Zhen Guo,Pluto Zhou,Tao Gui,Zuxuan Wu,Xipeng Qiu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Di Wang,Shunyu Yao*

Main category: cs.CL

TL;DR: CL-bench是一个评估语言模型上下文学习能力的基准测试，包含500个复杂上下文、1899个任务和31607个验证标准，评估显示当前最先进模型平均只能解决17.2%的任务，表明上下文学习能力仍是重要瓶颈


<details>
  <summary>Details</summary>
Motivation: 现实世界任务比预训练知识更复杂且高度依赖上下文，需要模型从特定任务上下文中学习新知识并进行推理，这种人类天生具备的上下文学习能力在现有语言模型中被忽视

Method: 构建CL-bench基准测试，由领域专家设计复杂上下文和任务，要求模型从上下文中学习新领域知识、规则系统、复杂程序和经验数据推导的规律，这些内容在预训练中不存在

Result: 评估10个前沿语言模型发现平均只能解决17.2%的任务，表现最好的GPT-5.1也只能解决23.7%，表明当前模型尚未实现有效的上下文学习

Conclusion: 上下文学习是语言模型处理现实世界复杂任务的关键能力，CL-bench为构建具备这种基础能力的模型提供了重要基准，将推动语言模型在真实场景中的智能部署

Abstract: Current language models (LMs) excel at reasoning over prompts using pre-trained knowledge. However, real-world tasks are far more complex and context-dependent: models must learn from task-specific context and leverage new knowledge beyond what is learned during pre-training to reason and resolve tasks. We term this capability context learning, a crucial ability that humans naturally possess but has been largely overlooked. To this end, we introduce CL-bench, a real-world benchmark consisting of 500 complex contexts, 1,899 tasks, and 31,607 verification rubrics, all crafted by experienced domain experts. Each task is designed such that the new content required to resolve it is contained within the corresponding context. Resolving tasks in CL-bench requires models to learn from the context, ranging from new domain-specific knowledge, rule systems, and complex procedures to laws derived from empirical data, all of which are absent from pre-training. This goes far beyond long-context tasks that primarily test retrieval or reading comprehension, and in-context learning tasks, where models learn simple task patterns via instructions and demonstrations. Our evaluations of ten frontier LMs find that models solve only 17.2% of tasks on average. Even the best-performing model, GPT-5.1, solves only 23.7%, revealing that LMs have yet to achieve effective context learning, which poses a critical bottleneck for tackling real-world, complex context-dependent tasks. CL-bench represents a step towards building LMs with this fundamental capability, making them more intelligent and advancing their deployment in real-world scenarios.

</details>


### [167] [Efficient Algorithms for Partial Constraint Satisfaction Problems over Control-flow Graphs](https://arxiv.org/abs/2602.03588)
*Xuran Cai,Amir Goharshady*

Main category: cs.CL

TL;DR: 本文提出了一个针对控制流图(CFG)上部分约束满足问题(PCSP)的通用算法，基于SPL分解实现O(|G|·|D|^6)时间复杂度，对固定域D提供线性时间解，统一了寄存器分配和LOSPRE等编译器优化任务的处理方法。


<details>
  <summary>Details</summary>
Motivation: 控制流图上的PCSP问题能够统一建模多种经典编译器优化任务（如寄存器分配、LOSPRE、bank选择指令优化），但需要高效的求解算法。结构化程序的控制流图具有稀疏和可分解特性，特别是SPL分解结构可被利用。

Method: 基于SPL（Series-Parallel-Loop）分解技术，开发了针对SPL图的通用PCSP算法。算法利用控制流图的结构特性进行分解处理，实现了高效的计算复杂度。

Result: 算法时间复杂度为O(|G|·|D|^6)，对固定域D提供线性时间解。在最优bank选择任务上的实验结果显示，运行时间比现有最优方法快4倍。

Conclusion: 提出的SPL-based PCSP算法为控制流图上的多种编译器优化问题提供了统一高效的解决方案，通过利用图的结构特性显著提升了计算效率，是之前寄存器分配和LOSPRE方法的泛化和统一。

Abstract: In this work, we focus on the Partial Constraint Satisfaction Problem (PCSP) over control-flow graphs (CFGs) of programs. PCSP serves as a generalization of the well-known Constraint Satisfaction Problem (CSP). In the CSP framework, we define a set of variables, a set of constraints, and a finite domain $D$ that encompasses all possible values for each variable. The objective is to assign a value to each variable in such a way that all constraints are satisfied. In the graph variant of CSP, an underlying graph is considered and we have one variable corresponding to each vertex of the graph and one or several constraints corresponding to each edge. In PCSPs, we allow for certain constraints to be violated at a specified cost, aiming to find a solution that minimizes the total cost. Numerous classical compiler optimization tasks can be framed as PCSPs over control-flow graphs. Examples include Register Allocation, Lifetime-optimal Speculative Partial Redundancy Elimination (LOSPRE), and Optimal Placement of Bank Selection Instructions. On the other hand, it is well-known that control-flow graphs of structured programs are sparse and decomposable in a variety of ways. In this work, we rely on the Series-Parallel-Loop (SPL) decompositions as introduced by~\cite{RegisterAllocation}. Our main contribution is a general algorithm for PCSPs over SPL graphs with a time complexity of \(O(|G| \cdot |D|^6)\), where \(|G|\) represents the size of the control-flow graph. Note that for any fixed domain $D,$ this yields a linear-time solution. Our algorithm can be seen as a generalization and unification of previous SPL-based approaches for register allocation and LOSPRE. In addition, we provide experimental results over another classical PCSP task, i.e. Optimal Bank Selection, achieving runtimes four times better than the previous state of the art.

</details>


### [168] [Controlling Output Rankings in Generative Engines for LLM-based Search](https://arxiv.org/abs/2602.03608)
*Haibo Jin,Ruoxi Chen,Peiyan Zhang,Yifeng Luo,Huimin Zeng,Man Luo,Haohan Wang*

Main category: cs.CL

TL;DR: CORE是一种控制LLM搜索引擎输出排名的优化方法，通过在检索内容后附加策略性设计的优化内容来影响产品推荐排名，显著提升目标产品在推荐列表中的位置。


<details>
  <summary>Details</summary>
Motivation: 随着基于LLM的搜索引擎兴起，产品推荐直接呈现给用户而非传统搜索结果，但LLM的初始检索顺序会限制小型企业和独立创作者的可见性，需要解决这一公平性问题。

Method: 提出CORE方法，针对搜索引擎返回的内容进行优化，通过附加字符串型、推理型和评论型三种优化内容来引导输出排名。使用ProductBench基准（15个品类，每个品类200个产品）进行评估。

Result: 在四种具备搜索能力的LLM（GPT-4o、Gemini-2.5、Claude-4、Grok-3）上实验显示，CORE在Top-5、Top-3和Top-1的平均推广成功率分别达到91.4%、86.6%和80.3%，优于现有排名操纵方法。

Conclusion: CORE有效解决了LLM搜索引擎中的排名偏见问题，能够成功提升目标产品的可见性，同时保持优化内容的流畅性，为促进数字市场公平竞争提供了技术方案。

Abstract: The way customers search for and choose products is changing with the rise of large language models (LLMs). LLM-based search, or generative engines, provides direct product recommendations to users, rather than traditional online search results that require users to explore options themselves. However, these recommendations are strongly influenced by the initial retrieval order of LLMs, which disadvantages small businesses and independent creators by limiting their visibility.
  In this work, we propose CORE, an optimization method that \textbf{C}ontrols \textbf{O}utput \textbf{R}ankings in g\textbf{E}nerative Engines for LLM-based search. Since the LLM's interactions with the search engine are black-box, CORE targets the content returned by search engines as the primary means of influencing output rankings. Specifically, CORE optimizes retrieved content by appending strategically designed optimization content to steer the ranking of outputs. We introduce three types of optimization content: string-based, reasoning-based, and review-based, demonstrating their effectiveness in shaping output rankings. To evaluate CORE in realistic settings, we introduce ProductBench, a large-scale benchmark with 15 product categories and 200 products per category, where each product is associated with its top-10 recommendations collected from Amazon's search interface.
  Extensive experiments on four LLMs with search capabilities (GPT-4o, Gemini-2.5, Claude-4, and Grok-3) demonstrate that CORE achieves an average Promotion Success Rate of \textbf{91.4\% @Top-5}, \textbf{86.6\% @Top-3}, and \textbf{80.3\% @Top-1}, across 15 product categories, outperforming existing ranking manipulation methods while preserving the fluency of optimized content.

</details>


### [169] [Learning Query-Specific Rubrics from Human Preferences for DeepResearch Report Generation](https://arxiv.org/abs/2602.03619)
*Changze Lv,Jie Zhou,Wentao Zhao,Jingwen Xu,Zisu Huang,Muzhao Tian,Shihan Dou,Tao Gui,Le Tian,Xiao Zhou,Xiaoqing Zheng,Xuanjing Huang,Jie Zhou*

Main category: cs.CL

TL;DR: 提出一种基于人类偏好对齐的查询特定评分标准生成管道，结合强化学习和多智能体马尔可夫状态工作流，显著提升DeepResearch报告生成系统的性能


<details>
  <summary>Details</summary>
Motivation: 当前DeepResearch报告训练评估缺乏可验证奖励信号，现有评分标准方法要么粒度粗糙，要么依赖人工构建难以扩展

Method: 构建人类偏好标注数据集，通过结合人类偏好监督和LLM评分评估的混合奖励进行强化学习训练，并引入多智能体马尔可夫状态工作流处理长程推理

Result: 生成的评分标准比现有方法更具区分度和人类对齐性，在DeepResearch Bench上超越所有开源基线，达到与领先闭源模型相当的性能

Conclusion: 该方法为DeepResearch报告生成提供了可扩展且有效的评估解决方案，显著提升了系统性能

Abstract: Nowadays, training and evaluating DeepResearch-generated reports remain challenging due to the lack of verifiable reward signals. Accordingly, rubric-based evaluation has become a common practice. However, existing approaches either rely on coarse, pre-defined rubrics that lack sufficient granularity, or depend on manually constructed query-specific rubrics that are costly and difficult to scale. In this paper, we propose a pipeline to train human-preference-aligned query-specific rubric generators tailored for DeepResearch report generation. We first construct a dataset of DeepResearch-style queries annotated with human preferences over paired reports, and train rubric generators via reinforcement learning with a hybrid reward combining human preference supervision and LLM-based rubric evaluation. To better handle long-horizon reasoning, we further introduce a Multi-agent Markov-state (MaMs) workflow for report generation. We empirically show that our proposed rubric generators deliver more discriminative and better human-aligned supervision than existing rubric design strategies. Moreover, when integrated into the MaMs training framework, DeepResearch systems equipped with our rubric generators consistently outperform all open-source baselines on the DeepResearch Bench and achieve performance comparable to that of leading closed-source models.

</details>


### [170] [BIRDTurk: Adaptation of the BIRD Text-to-SQL Dataset to Turkish](https://arxiv.org/abs/2602.03633)
*Burak Aktaş,Mehmet Can Baytekin,Süha Kağan Köse,Ömer İlbilgi,Elif Özge Yılmaz,Çağrı Toraman,Bilge Kaan Görür*

Main category: cs.CL

TL;DR: BIRDTurk是首个土耳其语Text-to-SQL基准测试，通过受控翻译流程创建，保持SQL逻辑结构不变。评估显示土耳其语导致性能下降，但智能体推理展现更强跨语言鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探索形态丰富、低资源语言（土耳其语）在Text-to-SQL系统中的表现，填补现有研究空白。

Method: 采用受控翻译流程构建BIRDTurk基准，通过中心极限定理确定样本量验证翻译质量（98.15%准确率），评估推理提示、智能体多阶段推理和监督微调方法。

Result: 土耳其语导致一致性性能下降，主要源于结构语言差异和LLM预训练中的代表性不足；智能体推理展示更强跨语言鲁棒性；监督微调对标准多语言基线具有挑战性但在现代指令调优模型中有效。

Conclusion: BIRDTurk为跨语言Text-to-SQL评估提供了受控测试环境，揭示了语言特性和预训练数据代表性对性能的重要影响，智能体方法在跨语言场景中表现更稳健。

Abstract: Text-to-SQL systems have achieved strong performance on English benchmarks, yet their behavior in morphologically rich, low-resource languages remains largely unexplored. We introduce BIRDTurk, the first Turkish adaptation of the BIRD benchmark, constructed through a controlled translation pipeline that adapts schema identifiers to Turkish while strictly preserving the logical structure and execution semantics of SQL queries and databases. Translation quality is validated on a sample size determined by the Central Limit Theorem to ensure 95% confidence, achieving 98.15% accuracy on human-evaluated samples. Using BIRDTurk, we evaluate inference-based prompting, agentic multi-stage reasoning, and supervised fine-tuning. Our results reveal that Turkish introduces consistent performance degradation, driven by both structural linguistic divergence and underrepresentation in LLM pretraining, while agentic reasoning demonstrates stronger cross-lingual robustness. Supervised fine-tuning remains challenging for standard multilingual baselines but scales effectively with modern instruction-tuned models. BIRDTurk provides a controlled testbed for cross-lingual Text-to-SQL evaluation under realistic database conditions. We release the training and development splits to support future research.

</details>


### [171] [TRE: Encouraging Exploration in the Trust Region](https://arxiv.org/abs/2602.03635)
*Chao Huang,Yujing Lu,Quangang Li,Shenghe Wang,Yan Wang,Yueyang Zhang,Long Xia,Jiashu Zhao,Zhiyuan Sun,Daiting Shi,Tingwen Liu*

Main category: cs.CL

TL;DR: 提出了Trust Region Entropy (TRE)方法，通过限制在信任区域内进行探索，解决了LLM中标准熵正则化失效的问题，在数学推理、组合搜索和偏好对齐任务中表现优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 标准熵正则化在LLM中效果不佳甚至降低性能，归因于大规模词汇和长生成序列带来的累积尾部风险，导致概率质量被分散到无效标记而非聚焦于合理候选。

Method: 提出Trust Region Entropy (TRE)，在模型信任区域内严格鼓励探索，避免将概率质量过度分散到无效词汇尾部。

Result: 在MATH数学推理、Countdown组合搜索和HH偏好对齐任务的广泛实验中，TRE始终优于普通PPO、标准熵正则化和其他探索基线方法。

Conclusion: TRE方法有效解决了LLM中熵正则化失效的问题，通过在信任区域内进行探索来保持推理连贯性并提升性能。

Abstract: Entropy regularization is a standard technique in reinforcement learning (RL) to enhance exploration, yet it yields negligible effects or even degrades performance in Large Language Models (LLMs). We attribute this failure to the cumulative tail risk inherent to LLMs with massive vocabularies and long generation horizons. In such environments, standard global entropy maximization indiscriminately dilutes probability mass into the vast tail of invalid tokens rather than focusing on plausible candidates, thereby disrupting coherent reasoning. To address this, we propose Trust Region Entropy (TRE), a method that encourages exploration strictly within the model's trust region. Extensive experiments across mathematical reasoning (MATH), combinatorial search (Countdown), and preference alignment (HH) tasks demonstrate that TRE consistently outperforms vanilla PPO, standard entropy regularization, and other exploration baselines. Our code is available at https://github.com/WhyChaos/TRE-Encouraging-Exploration-in-the-Trust-Region.

</details>


### [172] [RAGTurk: Best Practices for Retrieval Augmented Generation in Turkish](https://arxiv.org/abs/2602.03652)
*Süha Kağan Köse,Mehmet Can Baytekin,Burak Aktaş,Bilge Kaan Görür,Evren Ayberk Munis,Deniz Yılmaz,Muhammed Yusuf Kartal,Çağrı Toraman*

Main category: cs.CL

TL;DR: 构建了首个土耳其语RAG数据集，系统评估了RAG流程各阶段性能，发现HyDE方法准确率最高达85%，同时提出了成本更低但性能相当的帕累托最优配置方案


<details>
  <summary>Details</summary>
Motivation: 现有RAG设计指南主要针对英语，缺乏对土耳其语等形态丰富语言的研究，限制了这些语言的应用效果

Method: 基于土耳其维基百科和CulturaX构建问答对和段落块数据集，在无任务特定微调情况下，对RAG流程的7个阶段（查询转换、重排序到答案精炼）进行基准测试

Result: 复杂方法HyDE准确率最高（85%），显著高于基线（78.70%）；帕累托最优配置（交叉编码器重排序+上下文增强）达到84.60%准确率且成本更低；发现过度堆叠生成模块会因扭曲形态线索而降低性能

Conclusion: 针对形态丰富语言的RAG系统需要特别考虑形态学特性，简单查询澄清配合鲁棒重排序是有效解决方案，为土耳其语等语言的RAG应用提供了实践指导

Abstract: Retrieval-Augmented Generation (RAG) enhances LLM factuality, yet design guidance remains English-centric, limiting insights for morphologically rich languages like Turkish. We address this by constructing a comprehensive Turkish RAG dataset derived from Turkish Wikipedia and CulturaX, comprising question-answer pairs and relevant passage chunks. We benchmark seven stages of the RAG pipeline, from query transformation and reranking to answer refinement, without task-specific fine-tuning. Our results show that complex methods like HyDE maximize accuracy (85%) that is considerably higher than the baseline (78.70%). Also a Pareto-optimal configuration using Cross-encoder Reranking and Context Augmentation achieves comparable performance (84.60%) with much lower cost. We further demonstrate that over-stacking generative modules can degrade performance by distorting morphological cues, whereas simple query clarification with robust reranking offers an effective solution.

</details>


### [173] [Instruction Anchors: Dissecting the Causal Dynamics of Modality Arbitration](https://arxiv.org/abs/2602.03677)
*Yu Zhang,Mufan Xu,Xuefeng Bai,Kehai chen,Pengfei Zhang,Yang Xiang,Min Zhang*

Main category: cs.CL

TL;DR: 本文通过信息流视角研究多模态大语言模型的模态跟随机制，发现指令token作为结构锚点进行模态仲裁，浅层注意力层进行非选择性信息传输，深层注意力层在指令意图指导下解决模态竞争，MLP层则表现出语义惯性。识别出驱动仲裁的稀疏注意力头，因果干预显示操纵5%的关键头可显著改变模态跟随率。


<details>
  <summary>Details</summary>
Motivation: 模态跟随能力对多模态大语言模型的安全性和可靠性至关重要，但其决策机制尚未被充分理解，需要深入研究其工作机制以提高模型透明度。

Method: 采用信息流分析视角，通过注意力机制和MLP层的功能分析，结合因果干预实验（阻塞和放大关键注意力头）来探究模态仲裁机制。

Result: 发现指令token作为结构锚点，浅层注意力层路由多模态线索，深层注意力层解决模态竞争，MLP层起对抗作用。识别出稀疏的专用注意力头，操纵5%的关键头可使模态跟随率降低60%或提高60%。

Conclusion: 该研究为模型透明度提供了重要进展，并为多模态大语言模型中多模态信息的协调提供了原则性框架，有助于提高模型的安全性和可靠性。

Abstract: Modality following serves as the capacity of multimodal large language models (MLLMs) to selectively utilize multimodal contexts based on user instructions. It is fundamental to ensuring safety and reliability in real-world deployments. However, the underlying mechanisms governing this decision-making process remain poorly understood. In this paper, we investigate its working mechanism through an information flow lens. Our findings reveal that instruction tokens function as structural anchors for modality arbitration: Shallow attention layers perform non-selective information transfer, routing multimodal cues to these anchors as a latent buffer; Modality competition is resolved within deep attention layers guided by the instruction intent, while MLP layers exhibit semantic inertia, acting as an adversarial force. Furthermore, we identify a sparse set of specialized attention heads that drive this arbitration. Causal interventions demonstrate that manipulating a mere $5\%$ of these critical heads can decrease the modality-following ratio by $60\%$ through blocking, or increase it by $60\%$ through targeted amplification of failed samples. Our work provides a substantial step toward model transparency and offers a principled framework for the orchestration of multimodal information in MLLMs.

</details>


### [174] [Neural Attention Search Linear: Towards Adaptive Token-Level Hybrid Attention Models](https://arxiv.org/abs/2602.03681)
*Difan Deng,Andreas Bentzen Winje,Lukas Fehring,Marius Lindauer*

Main category: cs.CL

TL;DR: NAtS-L是一个混合注意力框架，在同一个层中对不同token同时应用线性注意力和softmax注意力，自动决定哪些token适合线性处理（短期影响），哪些需要softmax注意力（长期检索），通过搜索最优组合实现高效且表达能力强的token级混合架构。


<details>
  <summary>Details</summary>
Motivation: 解决softmax transformer在长上下文场景中的二次计算复杂度问题，同时克服线性注意力模型因隐藏状态大小限制而表达能力有限的问题。

Method: 提出神经注意力搜索线性框架(NAtS-L)，在同一层中为不同token分别应用线性注意力和softmax注意力操作，通过搜索最优的Gated DeltaNet和softmax注意力组合，自动识别适合线性编码的token（短期影响）和需要保留的token（长期检索）。

Result: NAtS-L提供了一个强大且高效的token级混合架构，能够有效降低计算复杂度同时保持表达能力。

Conclusion: 该框架成功解决了传统混合方法中softmax注意力层仍然是效率瓶颈的问题，通过token级别的智能分配实现了计算效率和模型表达能力的平衡。

Abstract: The quadratic computational complexity of softmax transformers has become a bottleneck in long-context scenarios. In contrast, linear attention model families provide a promising direction towards a more efficient sequential model. These linear attention models compress past KV values into a single hidden state, thereby efficiently reducing complexity during both training and inference. However, their expressivity remains limited by the size of their hidden state. Previous work proposed interleaving softmax and linear attention layers to reduce computational complexity while preserving expressivity. Nevertheless, the efficiency of these models remains bottlenecked by their softmax attention layers. In this paper, we propose Neural Attention Search Linear (NAtS-L), a framework that applies both linear attention and softmax attention operations within the same layer on different tokens. NAtS-L automatically determines whether a token can be handled by a linear attention model, i.e., tokens that have only short-term impact and can be encoded into fixed-size hidden states, or require softmax attention, i.e., tokens that contain information related to long-term retrieval and need to be preserved for future queries. By searching for optimal Gated DeltaNet and softmax attention combinations across tokens, we show that NAtS-L provides a strong yet efficient token-level hybrid architecture.

</details>


### [175] [Rethinking the Reranker: Boundary-Aware Evidence Selection for Robust Retrieval-Augmented Generation](https://arxiv.org/abs/2602.03689)
*Jiashuo Sun,Pengcheng Jiang,Saizhuo Wang,Jiajun Fan,Heng Wang,Siru Ouyang,Ming Zhong,Yizhu Jiao,Chengsong Huang,Xueqiang Xu,Pengrui Han,Peiran Li,Jiaxin Huang,Ge Liu,Heng Ji,Jiawei Han*

Main category: cs.CL

TL;DR: BAR-RAG提出了一种边界感知的证据选择方法，通过强化学习训练选择器来找到生成器的"最佳证据区间"，并在诱导的证据分布下微调生成器，显著提升了噪声检索条件下的RAG系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在现实检索噪声下表现脆弱，即使相关证据出现在top-K结果中。原因是检索器和重排器仅优化相关性，选择的证据要么过于简单（直接包含答案），要么缺乏关键信息，未考虑证据对生成器的适用性。

Method: 1. 将重排器重构为边界感知证据选择器，寻找生成器的Goldilocks Zone（既不过于简单也不无法回答的证据）；2. 使用强化学习和生成器反馈训练选择器；3. 采用两阶段流水线，在诱导的证据分布下微调生成器以减少训练和推理间的分布不匹配。

Result: 在知识密集型问答基准测试中，BAR-RAG在噪声检索条件下持续提升端到端性能，相比强基线RAG和重排方法平均提升10.3%，并显著提高了鲁棒性。

Conclusion: BAR-RAG通过关注生成器的证据适用性而非单纯相关性，有效解决了RAG系统在噪声检索环境下的脆弱性问题，为构建更鲁棒的检索增强生成系统提供了新思路。

Abstract: Retrieval-Augmented Generation (RAG) systems remain brittle under realistic retrieval noise, even when the required evidence appears in the top-K results. A key reason is that retrievers and rerankers optimize solely for relevance, often selecting either trivial, answer-revealing passages or evidence that lacks the critical information required to answer the question, without considering whether the evidence is suitable for the generator. We propose BAR-RAG, which reframes the reranker as a boundary-aware evidence selector that targets the generator's Goldilocks Zone -- evidence that is neither trivially easy nor fundamentally unanswerable for the generator, but is challenging yet sufficient for inference and thus provides the strongest learning signal. BAR-RAG trains the selector with reinforcement learning using generator feedback, and adopts a two-stage pipeline that fine-tunes the generator under the induced evidence distribution to mitigate the distribution mismatch between training and inference. Experiments on knowledge-intensive question answering benchmarks show that BAR-RAG consistently improves end-to-end performance under noisy retrieval, achieving an average gain of 10.3 percent over strong RAG and reranking baselines while substantially improving robustness. Code is publicly avaliable at https://github.com/GasolSun36/BAR-RAG.

</details>


### [176] [OCRTurk: A Comprehensive OCR Benchmark for Turkish](https://arxiv.org/abs/2602.03693)
*Deniz Yılmaz,Evren Ayberk Munis,Çağrı Toraman,Süha Kağan Köse,Burak Aktaş,Mehmet Can Baytekin,Bilge Kaan Görür*

Main category: cs.CL

TL;DR: OCR Turk是一个针对土耳其语文档解析的基准测试，包含180份多类别文档和三个难度级别，评估显示PaddleOCR在多数指标上表现最佳，但幻灯片文档最具挑战性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要针对高资源语言，对土耳其语等低资源语言覆盖有限，且缺乏反映真实场景和文档多样性的标准化基准。

Method: 构建包含180份土耳其语文档的OCR Turk基准，涵盖学术论文、学位论文、幻灯片和非学术文章，使用元素级指标评估7个OCR模型。

Result: PaddleOCR在三个难度级别上总体表现最佳，在多数元素级指标领先（除图表外），在非学术文档上表现良好，幻灯片文档最具挑战性。

Conclusion: OCR Turk填补了土耳其语文档解析基准的空白，为评估模型在低资源语言环境下的可靠性提供了标准化工具，揭示了不同文档类型的性能差异。

Abstract: Document parsing is now widely used in applications, such as large-scale document digitization, retrieval-augmented generation, and domain-specific pipelines in healthcare and education. Benchmarking these models is crucial for assessing their reliability and practical robustness. Existing benchmarks mostly target high-resource languages and provide limited coverage for low-resource settings, such as Turkish. Moreover, existing studies on Turkish document parsing lack a standardized benchmark that reflects real-world scenarios and document diversity. To address this gap, we introduce OCRTurk, a Turkish document parsing benchmark covering multiple layout elements and document categories at three difficulty levels. OCRTurk consists of 180 Turkish documents drawn from academic articles, theses, slide decks, and non-academic articles. We evaluate seven OCR models on OCRTurk using element-wise metrics. Across difficulty levels, PaddleOCR achieves the strongest overall results, leading most element-wise metrics except figures and attaining high Normalized Edit Distance scores in easy, medium, and hard subsets. We also observe performance variation by document type. Models perform well on non-academic documents, while slideshows become the most challenging.

</details>


### [177] [Cognitively Diverse Multiple-Choice Question Generation: A Hybrid Multi-Agent Framework with Large Language Models](https://arxiv.org/abs/2602.03704)
*Yu Tian,Linh Huynh,Katerina Christhilf,Shubham Chakraborty,Micah Watanabe,Tracy Arner,Danielle McNamara*

Main category: cs.CL

TL;DR: ReQUESTA是一个混合多智能体框架，通过分解多选题生成任务，结合基于规则的组件和LLM智能体，系统性地生成针对文本理解、推理和主旨理解等认知需求的多样化多选题，相比单次提示方法在难度、区分度和质量上表现更优。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型使自动多选题生成变得可行，但可靠地生成满足特定认知需求的题目仍具挑战性。需要解决控制生成内容认知复杂度和质量的问题。

Method: 提出ReQUESTA混合框架，将多选题编写分解为专门子任务，协调LLM驱动的智能体与基于规则的组件，支持规划、受控生成、迭代评估和后处理。在学术说明文阅读理解研究中与GPT-5零样本基线进行比较。

Result: ReQUESTA生成的题目更困难、更具区分度，与阅读理解表现更一致。专家评估显示其更符合核心概念，干扰项的语言一致性和语义合理性更优，特别是在推理题方面。

Conclusion: 混合智能体编排能系统性地提高基于LLM生成的可靠性和可控性，工作流设计是超越单次提示的结构化生成关键因素。

Abstract: Recent advances in large language models (LLMs) have made automated multiple-choice question (MCQ) generation increasingly feasible; however, reliably producing items that satisfy controlled cognitive demands remains a challenge. To address this gap, we introduce ReQUESTA, a hybrid, multi-agent framework for generating cognitively diverse MCQs that systematically target text-based, inferential, and main idea comprehension. ReQUESTA decomposes MCQ authoring into specialized subtasks and coordinates LLM-powered agents with rule-based components to support planning, controlled generation, iterative evaluation, and post-processing. We evaluated the framework in a large-scale reading comprehension study using academic expository texts, comparing ReQUESTA-generated MCQs with those produced by a single-pass GPT-5 zero-shot baseline. Psychometric analyses of learner responses assessed item difficulty and discrimination, while expert raters evaluated question quality across multiple dimensions, including topic relevance and distractor quality. Results showed that ReQUESTA-generated items were consistently more challenging, more discriminative, and more strongly aligned with overall reading comprehension performance. Expert evaluations further indicated stronger alignment with central concepts and superior distractor linguistic consistency and semantic plausibility, particularly for inferential questions. These findings demonstrate that hybrid, agentic orchestration can systematically improve the reliability and controllability of LLM-based generation, highlighting workflow design as a key lever for structured artifact generation beyond single-pass prompting.

</details>


### [178] [OmniRAG-Agent: Agentic Omnimodal Reasoning for Low-Resource Long Audio-Video Question Answering](https://arxiv.org/abs/2602.03707)
*Yifan Zhu,Xinyu Mu,Tao Feng,Zhonghong Ou,Yuning Gong,Haoran Luo*

Main category: cs.CL

TL;DR: OmniRAG-Agent是一个用于低资源长音频视频问答的智能体方法，通过图像-音频检索增强生成模块和智能体循环，结合组相对策略优化，显著提升了长时跨模态问答性能。


<details>
  <summary>Details</summary>
Motivation: 解决长时跨模态问答中存在的计算成本高、细粒度检索能力弱、主动规划能力有限以及缺乏端到端优化等问题

Method: 构建图像-音频检索增强生成模块，让多模态大模型从外部库中检索相关帧和音频片段；采用智能体循环进行规划、工具调用和证据融合；应用组相对策略优化联合提升工具使用和答案质量

Result: 在OmniVideoBench、WorldSense和Daily-Omni数据集上，OmniRAG-Agent在低资源设置下持续优于先前方法，消融实验验证了各组件有效性

Conclusion: 该方法有效解决了长时跨模态问答的关键挑战，为低资源环境下的多模态推理提供了有效的端到端解决方案

Abstract: Long-horizon omnimodal question answering answers questions by reasoning over text, images, audio, and video. Despite recent progress on OmniLLMs, low-resource long audio-video QA still suffers from costly dense encoding, weak fine-grained retrieval, limited proactive planning, and no clear end-to-end optimization.To address these issues, we propose OmniRAG-Agent, an agentic omnimodal QA method for budgeted long audio-video reasoning. It builds an image-audio retrieval-augmented generation module that lets an OmniLLM fetch short, relevant frames and audio snippets from external banks. Moreover, it uses an agent loop that plans, calls tools across turns, and merges retrieved evidence to answer complex queries. Furthermore, we apply group relative policy optimization to jointly improve tool use and answer quality over time. Experiments on OmniVideoBench, WorldSense, and Daily-Omni show that OmniRAG-Agent consistently outperforms prior methods under low-resource settings and achieves strong results, with ablations validating each component.

</details>


### [179] [Beyond Tokens: Semantic-Aware Speculative Decoding for Efficient Inference by Probing Internal States](https://arxiv.org/abs/2602.03708)
*Ximing Dong,Shaowei Wang,Dayi Lin,Boyuan Chen,Ahmed E. Hassan*

Main category: cs.CL

TL;DR: SemanticSpec是一种语义感知的推测解码框架，通过验证整个语义序列而非单个token来加速大语言模型推理，解决了传统token级推测解码忽略语义等价性导致效率低下的问题。


<details>
  <summary>Details</summary>
Motivation: 大语言模型特别是大推理模型在自回归解码过程中存在高推理延迟问题，传统推测解码方法在token级别操作，忽略了语义等价性（不同token序列表达相同含义），导致拒绝效率低下。

Method: 提出SemanticSpec框架，采用语义序列验证机制，通过探测模型内部隐藏状态来评估生成特定含义序列的似然概率，实现语义级别的并行解码验证。

Result: 在四个基准测试中，SemanticSpec在DeepSeekR1-32B上实现最高2.7倍加速，在QwQ-32B上实现2.1倍加速，在效率和效果上均优于token级和序列级基线方法。

Conclusion: 语义感知的推测解码方法能有效提升大语言模型的推理效率，通过关注语义等价性而非token级匹配，显著减少了不必要的拒绝，为高效推理提供了新的技术路径。

Abstract: Large Language Models (LLMs) achieve strong performance across many tasks but suffer from high inference latency due to autoregressive decoding. The issue is exacerbated in Large Reasoning Models (LRMs), which generate lengthy chains of thought. While speculative decoding accelerates inference by drafting and verifying multiple tokens in parallel, existing methods operate at the token level and ignore semantic equivalence (i.e., different token sequences expressing the same meaning), leading to inefficient rejections. We propose SemanticSpec, a semantic-aware speculative decoding framework that verifies entire semantic sequences instead of tokens. SemanticSpec introduces a semantic probability estimation mechanism that probes the model's internal hidden states to assess the likelihood of generating sequences with specific meanings.Experiments on four benchmarks show that SemanticSpec achieves up to 2.7x speedup on DeepSeekR1-32B and 2.1x on QwQ-32B, consistently outperforming token-level and sequence-level baselines in both efficiency and effectiveness.

</details>


### [180] [No Shortcuts to Culture: Indonesian Multi-hop Question Answering for Complex Cultural Understanding](https://arxiv.org/abs/2602.03709)
*Vynska Amalia Permadi,Xingwei Tan,Nafise Sadat Moosavi,Nikos Aletras*

Main category: cs.CL

TL;DR: ID-MoCQA是一个针对印尼文化理解的大规模多跳问答数据集，通过系统化转换单跳问题为多跳推理链来评估大语言模型的文化推理能力


<details>
  <summary>Details</summary>
Motivation: 现有文化问答基准大多依赖单跳问题，模型可能利用浅层线索而非真正进行文化推理，需要更复杂的多跳推理评估框架

Method: 提出新框架将单跳文化问题系统转化为六种线索类型的多跳推理链，采用专家评审和LLM作为评判的多阶段验证流程确保数据质量

Result: 评估显示最先进模型在文化推理方面存在显著差距，特别是在需要细微推理的任务中表现不佳

Conclusion: ID-MoCQA为推进大语言模型文化能力提供了一个具有挑战性且必要的基准测试工具

Abstract: Understanding culture requires reasoning across context, tradition, and implicit social knowledge, far beyond recalling isolated facts. Yet most culturally focused question answering (QA) benchmarks rely on single-hop questions, which may allow models to exploit shallow cues rather than demonstrate genuine cultural reasoning. In this work, we introduce ID-MoCQA, the first large-scale multi-hop QA dataset for assessing the cultural understanding of large language models (LLMs), grounded in Indonesian traditions and available in both English and Indonesian. We present a new framework that systematically transforms single-hop cultural questions into multi-hop reasoning chains spanning six clue types (e.g., commonsense, temporal, geographical). Our multi-stage validation pipeline, combining expert review and LLM-as-a-judge filtering, ensures high-quality question-answer pairs. Our evaluation across state-of-the-art models reveals substantial gaps in cultural reasoning, particularly in tasks requiring nuanced inference. ID-MoCQA provides a challenging and essential benchmark for advancing the cultural competency of LLMs.

</details>


### [181] [Training Multi-Turn Search Agent via Contrastive Dynamic Branch Sampling](https://arxiv.org/abs/2602.03719)
*Yubao Zhao,Weiquan Huang,Sudong Wang,Ruochen Zhao,Chen Chen,Yao Shu,Chengwei Qin*

Main category: cs.CL

TL;DR: BranPO是一种无需价值函数的方法，通过截断轨迹尾部并重采样替代延续来构建对比后缀，减少长视野强化学习中的信用分配模糊性，在长视野任务中显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于树的强化学习方法在长视野设置中存在高方差和计算效率低的问题，研究发现性能差异主要源于轨迹尾部的决策问题。

Method: 提出Branching Relative Policy Optimization (BranPO)：1) 截断轨迹尾部并重采样构建对比后缀；2) 引入难度感知分支采样自适应调整分支频率；3) 使用冗余步骤掩码抑制无信息动作。

Result: 在多个问答基准测试中，BranPO始终优于强基线方法，在长视野任务中获得显著准确率提升，且不增加总体训练预算。

Conclusion: BranPO通过尾部对比学习有效解决了长视野强化学习中的信用分配问题，为无密集奖励的步级监督提供了有效解决方案。

Abstract: Agentic reinforcement learning has enabled large language models to perform complex multi-turn planning and tool use. However, learning in long-horizon settings remains challenging due to sparse, trajectory-level outcome rewards. While prior tree-based methods attempt to mitigate this issue, they often suffer from high variance and computational inefficiency. Through empirical analysis of search agents, We identify a common pattern: performance diverges mainly due to decisions near the tail. Motivated by this observation, we propose Branching Relative Policy Optimization (BranPO), a value-free method that provides step-level contrastive supervision without dense rewards. BranPO truncates trajectories near the tail and resamples alternative continuations to construct contrastive suffixes over shared prefixes, reducing credit ambiguity in long-horizon rollouts. To further boost efficiency and stabilize training, we introduce difficulty-aware branch sampling to adapt branching frequency across tasks, and redundant step masking to suppress uninformative actions. Extensive experiments on various question answering benchmarks demonstrate that BranPO consistently outperforms strong baselines, achieving significant accuracy gains on long-horizon tasks without increasing the overall training budget. Our code is available at \href{https://github.com/YubaoZhao/BranPO}{code}.

</details>


### [182] [CUBO: Self-Contained Retrieval-Augmented Generation on Consumer Laptops 10 GB Corpora, 16 GB RAM, Single-Device Deployment](https://arxiv.org/abs/2602.03731)
*Paolo Astrino*

Main category: cs.CL

TL;DR: CUBO是一个面向消费级笔记本电脑的RAG平台，通过流式摄取、分层混合检索和硬件感知编排，在16GB内存限制下实现高效文档检索，同时满足GDPR合规要求。


<details>
  <summary>Details</summary>
Motivation: 解决组织处理敏感文档时的两难困境：云端AI存在GDPR违规风险，而本地系统通常需要18-32GB内存，现有方案无法在消费级硬件上同时满足性能和合规要求。

Method: 开发CUBO系统，集成流式摄取（O(1)缓冲区开销）、分层混合检索和硬件感知编排技术，在15.5GB内存限制内实现高效检索。

Result: 在BEIR基准测试中实现Recall@10为0.48-0.97，检索延迟p50为185ms，在C1,300笔记本电脑上运行，完全本地处理确保GDPR合规。

Conclusion: CUBO证明了在消费级硬件上实现高性能RAG系统的可行性，为中小型专业档案提供了实用的本地部署解决方案，代码已开源。

Abstract: Organizations handling sensitive documents face a tension: cloud-based AI risks GDPR violations, while local systems typically require 18-32 GB RAM. This paper presents CUBO, a systems-oriented RAG platform for consumer laptops with 16 GB shared memory. CUBO's novelty lies in engineering integration of streaming ingestion (O(1) buffer overhead), tiered hybrid retrieval, and hardware-aware orchestration that enables competitive Recall@10 (0.48-0.97 across BEIR domains) within a hard 15.5 GB RAM ceiling. The 37,000-line codebase achieves retrieval latencies of 185 ms (p50) on C1,300 laptops while maintaining data minimization through local-only processing aligned with GDPR Art. 5(1)(c). Evaluation on BEIR benchmarks validates practical deployability for small-to-medium professional archives. The codebase is publicly available at https://github.com/PaoloAstrino/CUBO.

</details>


### [183] [Context Compression via Explicit Information Transmission](https://arxiv.org/abs/2602.03784)
*Jiangnan Ye,Hanqi Yan,Zhenyi Shen,Heng Chang,Ye Mao,Yulan He*

Main category: cs.CL

TL;DR: ComprExIT提出了一种新的软上下文压缩框架，通过显式信息传输在冻结的LLM隐藏状态上进行压缩，解决了现有方法中的渐进覆盖和容量分配不协调问题，在多个QA基准测试中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 长上下文推理成本高昂，现有压缩方法存在渐进表示覆盖和令牌间压缩容量分配不协调两个结构性问题。

Method: 提出ComprExIT框架，采用深度方向传输选择性地将多层信息传输到令牌锚点，宽度方向传输通过全局优化的传输计划将锚点聚合到少量槽位，实现解耦压缩。

Result: 在六个问答基准测试中，ComprExIT始终优于最先进的上下文压缩方法，仅增加约1%的额外参数。

Conclusion: 显式和协调的信息传输能够实现更有效和鲁棒的长上下文压缩。

Abstract: Long-context inference with Large Language Models (LLMs) is costly due to quadratic attention and growing key-value caches, motivating context compression. In this work, we study soft context compression, where a long context is condensed into a small set of continuous representations. Existing methods typically re-purpose the LLM itself as a trainable compressor, relying on layer-by-layer self-attention to iteratively aggregate information. We argue that this paradigm suffers from two structural limitations: (i) progressive representation overwriting across layers (ii) uncoordinated allocation of compression capacity across tokens. We propose ComprExIT (Context Compression via Explicit Information Transmission), a lightweight framework that formulates soft compression into a new paradigm: explicit information transmission over frozen LLM hidden states. This decouples compression from the model's internal self-attention dynamics. ComprExIT performs (i) depth-wise transmission to selectively transmit multi-layer information into token anchors, mitigating progressive overwriting, and (ii) width-wise transmission to aggregate anchors into a small number of slots via a globally optimized transmission plan, ensuring coordinated allocation of information. Across six question-answering benchmarks, ComprExIT consistently outperforms state-of-the-art context compression methods while introducing only ~1% additional parameters, demonstrating that explicit and coordinated information transmission enables more effective and robust long-context compression.

</details>


### [184] [They Said Memes Were Harmless-We Found the Ones That Hurt: Decoding Jokes, Symbols, and Cultural References](https://arxiv.org/abs/2602.03822)
*Sahil Tripathi,Gautam Siddharth Kashyap,Mehwish Nasim,Jian Yang,Jiechao Gao,Usman Naseem*

Main category: cs.CL

TL;DR: CROSS-ALIGN+是一个三阶段框架，通过结构化知识增强、参数高效适配器和级联解释生成，解决表情包社交滥用检测中的文化盲区、边界模糊和可解释性不足问题，在多个基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有表情包滥用检测方法存在三个主要局限：文化盲区（忽略文化符号上下文）、边界模糊（难以区分讽刺和滥用）、缺乏可解释性（模型推理不透明）。

Method: 三阶段框架：1) 使用ConceptNet、Wikidata和Hatebase的结构化知识增强多模态表示；2) 通过LoRA适配器锐化决策边界；3) 生成级联解释提高可解释性。

Result: 在五个基准测试和八个大型视觉语言模型上，CROSS-ALIGN+相对F1分数提升高达17%，持续超越最先进方法。

Conclusion: 该框架系统性地解决了表情包滥用检测的关键挑战，在性能和可解释性方面均有显著提升，为多模态内容安全提供了有效解决方案。

Abstract: Meme-based social abuse detection is challenging because harmful intent often relies on implicit cultural symbolism and subtle cross-modal incongruence. Prior approaches, from fusion-based methods to in-context learning with Large Vision-Language Models (LVLMs), have made progress but remain limited by three factors: i) cultural blindness (missing symbolic context), ii) boundary ambiguity (satire vs. abuse confusion), and iii) lack of interpretability (opaque model reasoning). We introduce CROSS-ALIGN+, a three-stage framework that systematically addresses these limitations: (1) Stage I mitigates cultural blindness by enriching multimodal representations with structured knowledge from ConceptNet, Wikidata, and Hatebase; (2) Stage II reduces boundary ambiguity through parameter-efficient LoRA adapters that sharpen decision boundaries; and (3) Stage III enhances interpretability by generating cascaded explanations. Extensive experiments on five benchmarks and eight LVLMs demonstrate that CROSS-ALIGN+ consistently outperforms state-of-the-art methods, achieving up to 17% relative F1 improvement while providing interpretable justifications for each decision.

</details>


### [185] [Accelerating Scientific Research with Gemini: Case Studies and Common Techniques](https://arxiv.org/abs/2602.03837)
*David P. Woodruff,Vincent Cohen-Addad,Lalit Jain,Jieming Mao,Song Zuo,MohammadHossein Bateni,Simina Branzei,Michael P. Brenner,Lin Chen,Ying Feng,Lance Fortnow,Gang Fu,Ziyi Guan,Zahra Hadizadeh,Mohammad T. Hajiaghayi,Mahdi JafariRaviz,Adel Javanmard,Karthik C. S.,Ken-ichi Kawarabayashi,Ravi Kumar,Silvio Lattanzi,Euiwoong Lee,Yi Li,Ioannis Panageas,Dimitris Paparas,Benjamin Przybocki,Bernardo Subercaseaux,Ola Svensson,Shayan Taherijam,Xuan Wu,Eylon Yogev,Morteza Zadimoghaddam,Samson Zhou,Vahab Mirrokni*

Main category: cs.CL

TL;DR: 论文展示如何通过与Gemini等先进AI模型合作解决理论计算机科学等多个领域的开放问题、反驳猜想和生成新证明，并总结了有效人机协作的技术方法。


<details>
  <summary>Details</summary>
Motivation: 探索大型语言模型在协助专家级数学发现方面的潜力，特别是在理论研究和创造性科学发现中的合作伙伴角色。

Method: 采用案例研究方法，通过迭代精炼、问题分解和跨学科知识转移等技术，结合对话式交互和神经符号循环等创新方法进行人机协作。

Result: 成功展示了AI模型在解决开放问题、发现证明缺陷和验证复杂推导方面的能力，证明了其作为科学研究创造性合作伙伴的潜力。

Conclusion: AI不仅可以作为自动化工具，更可以成为科学发现创造性过程中的多功能真实合作伙伴，为人机协作研究提供了新的方法论和可能性。

Abstract: Recent advances in large language models (LLMs) have opened new avenues for accelerating scientific research. While models are increasingly capable of assisting with routine tasks, their ability to contribute to novel, expert-level mathematical discovery is less understood. We present a collection of case studies demonstrating how researchers have successfully collaborated with advanced AI models, specifically Google's Gemini-based models (in particular Gemini Deep Think and its advanced variants), to solve open problems, refute conjectures, and generate new proofs across diverse areas in theoretical computer science, as well as other areas such as economics, optimization, and physics. Based on these experiences, we extract common techniques for effective human-AI collaboration in theoretical research, such as iterative refinement, problem decomposition, and cross-disciplinary knowledge transfer. While the majority of our results stem from this interactive, conversational methodology, we also highlight specific instances that push beyond standard chat interfaces. These include deploying the model as a rigorous adversarial reviewer to detect subtle flaws in existing proofs, and embedding it within a "neuro-symbolic" loop that autonomously writes and executes code to verify complex derivations. Together, these examples highlight the potential of AI not just as a tool for automation, but as a versatile, genuine partner in the creative process of scientific discovery.

</details>


### [186] [Parallel-Probe: Towards Efficient Parallel Thinking via 2D Probing](https://arxiv.org/abs/2602.03845)
*Tong Zheng,Chengsong Huang,Runpeng Dai,Yun He,Rui Liu,Xin Ni,Huiwen Bao,Kaishen Wang,Hongtu Zhu,Jiaxin Huang,Furong Huang,Heng Huang*

Main category: cs.CL

TL;DR: Parallel-Probe：一种无需训练的控制器，通过2D探测接口暴露并行思维的宽度-深度动态，采用基于共识的提前停止和基于偏差的分支剪枝来优化并行推理效率，在保持准确性的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有并行推理方法依赖局部轨迹信号，缺乏利用并行分支间全局动态的原则性机制，导致计算负担较重。

Method: 引入2D探测接口定期获取所有分支的中间答案，分析宽度-深度分配动态，并开发Parallel-Probe控制器，使用共识提前停止控制推理深度，偏差剪枝动态调整宽度。

Result: 在三个基准测试和多个模型上的实验表明，相比标准多数投票，Parallel-Probe将顺序token减少35.8%，总token成本降低25.8%以上，同时保持竞争力准确性。

Conclusion: 2D探测揭示了并行思维的关键动态特征，Parallel-Probe通过利用这些特征实现了更优的测试时缩放帕累托前沿，为高效并行推理提供了有效解决方案。

Abstract: Parallel thinking has emerged as a promising paradigm for reasoning, yet it imposes significant computational burdens. Existing efficiency methods primarily rely on local, per-trajectory signals and lack principled mechanisms to exploit global dynamics across parallel branches. We introduce 2D probing, an interface that exposes the width-depth dynamics of parallel thinking by periodically eliciting intermediate answers from all branches. Our analysis reveals three key insights: non-monotonic scaling across width-depth allocations, heterogeneous reasoning branch lengths, and early stabilization of global consensus. Guided by these insights, we introduce $\textbf{Parallel-Probe}$, a training-free controller designed to optimize online parallel thinking. Parallel-Probe employs consensus-based early stopping to regulate reasoning depth and deviation-based branch pruning to dynamically adjust width. Extensive experiments across three benchmarks and multiple models demonstrate that Parallel-Probe establishes a superior Pareto frontier for test-time scaling. Compared to standard majority voting, it reduces sequential tokens by up to $\textbf{35.8}$% and total token cost by over $\textbf{25.8}$% while maintaining competitive accuracy.

</details>
